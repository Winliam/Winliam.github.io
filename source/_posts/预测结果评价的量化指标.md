---
title: 预测结果评价的量化指标
math: true
categories:
  - - 工作技能
    - 神经网络
date: 2020-04-01 10:59:22
tags:
  - ROC曲线
  - PR曲线
  - mAP
  - mmAP
  - recall
  - precision
  - AUC
---
## 基本概念
### 二分类情形下的P/N/T/F概念
1. Positive/Negative：样本空间的原始分类;
2. True/False，预测结果与样本原始属性的偏差情况，即P->P/N->N为T，P->N/N->P为F;因此，T和F需要再细分为：
 - TP：P->P(正类被预测为正类，真正类)
 - TN：N->N(负类被预测为负类，真负类)
 - FP：N->P(负类被预测为正类，假正类)
 - FN：P->N(正类被预测为负类，假负类）

### 多分类情形下的P/N/T/F概念
多分类时需要针对单独每一个类别进行分析，然后再综合分析。比如，对于一个三分类情形，先分析类别A，则A类为Positive，B类和C类为Negative。然后得到A的混淆矩阵：

|原始\预测 |a |非a|
|:-:|:-:|:-:|
|**A** |$TP_A$ |$FN_A$ |
|**非A** |$FP_A$ |$TN_A$| 
## 变量命名(personal)
若以X为样本中X类数量，M为样本总数，x为预测结果中的X类数量，T为正确预测数量，F为错误预测数量，综上有：
- $M = A+B+C = a+b+c = T + F$（不解释）
- $T = TP_A+TP_B+TP_C$（不解释）
- $F = FP_A+FP_B+FP_C = FN_A+FN_B+FN_C$（不解释） 
- $A = TP_A+FN_A$（样本中的A类数量=真A类数量+假非A类数量）
- $a = TP_A+FP_A$（预测中的A类数量=真A类数量+假A类数量）

综合来看还是比较复杂的，实操时最好先把混淆矩阵算出来，然后再进行下面基本指标和高级指标的计算。

## 基本指标 
- **accuracy**: 模型做正确预测的能力 
  $$\frac{T}{M}$$ 
- **recall/hit-rate/TruePositiveRate/sensitivity**: 原始样本中的A类有多少被正确预测出来 
  $$\frac{TP_A}{A}$$
- **precision**: 找到的A类中有多少是真正的A类 
  $$\frac{TP_A}{a}$$ 
- **fall-out/FalsePositiveRate**: 原始样本中的非A类有多少被错误地预测成了A类 
  $$\frac{FN_A}{B+C}$$
- **F1 score**: precision和recall的调和平均数
  $$\frac{2}{\frac{1}{precision}+\frac{1}{recall}}$$

综上可以看出，除了accuracy之外，其他4个指标都与类别强相关，这意味着对于每一类别都有这4个指标。那么如何综合不同类别的基本指标，从而得到对于一个模型而言的全局指标呢？常用以下三种方式：
1. Macro-Average : 求各个类别指标的算数平均值作为全局指标。举个例子
$$
presicion = \frac{precision_A+precision_B+precision_C}{3}
 = \frac{1}{3}(\frac{TP_A}{a}+\frac{TP_B}{b}+\frac{TP_C}{c})
$$
2. Micro-Average : 看下面例子就明白，此时全局precision和recall是相同的。
$$
precision = \frac{TP_A+TP_B+TP_C}{a+b+c} = \frac{TP_A+TP_B+TP_C}{M}
$$
3. Weighted-Average : 求各个类别指标的加权平均值作为全局指标，权重为该类别在样本空间中的比例。
$$
precision = precision_A * \frac{A}{M} + precision_B * \frac{B}{M} +precision_C * \frac{C}{M}
$$

## 高级指标
### **ROC曲线**
  - 横轴为FPR，样本中非A类多少被错误预测成了A类
  - 纵轴为TPR，样本中A类多少被正确预测成了A类（也就是recalll）
  - 0-1之间选择不同的分类阈值，从而得到同一分类器的不同subversion，因此ROC曲线上一个点(x,y)的含义为：对于某个特定的分类阈值，有y%的A类被成功预测成了A类，但代价是x%的非A类也被预测成了A类。
  - 我们肯定希望x越小越好，y越大越好（所有的飞机都被找到，大雁及其他鸟类还不被当成飞机），从图形上来看就是尽量靠近左上角。
  - **ROC-AUC值**，ROC曲线对x轴的积分，对于同样的x值，y值越大，面积越大，越符合我们的期望，也就是分类效果越好。

### **P-R曲线**
  - 横轴为recall（真A类占全体样本A类的比例）
  - 纵轴为precision（真A类占全体预测A类的比例）
  - 0-1之间选择不同的分类阈值，从而得到同一分类器的不同subversion，因此P-R曲线上一个点(x,y)的含义为：对于某个特定的分类阈值，有x%的A类被成功预测成了A类(被召回)，并且这些真A类占a的比例为y%。
  - 我们希望x和y都越大越好，因为这意味着所有的飞机都被找到的同时，被认为是飞机的还真就都是飞机。从图形上来看就是尽量靠近右上角。
  - **PR-AUC值**，即所谓的**AP**值，P-R曲线对x轴的积分，也是越大越好。
  - **mAP**，计算出所有类别的**AP**值，然后计算算数平均数，即为整个模型的mAP值。

## 其他话题
### mAP计算步骤
1. 取得模型预测结果，一般为一个prediction score
2. 选取一个threshold，将prediction score转化为PNTF
3. 依次统计每个类别的混淆矩阵
4. 根据每个类别的混淆矩阵计算出对应的precision和recall
5. 更换threshold，重复2-4
6. 所有的threshold完成后，即可得到每个类别各自的PR曲线，求AUC面积得到各个类别的AP值
7. 求所有类别AP值的算数平均数，即可得到mAP

### 目标检测中的mAP计算
目标检测中不仅要对比原始标签和预测结果标签的偏离情况，还要计算Bounding Box的IOU值。在预测前后标签相同的前提下，将IOU值代替分类任务中的prediction score来进行后续计算。


### **ROC曲线和PR曲线对比**
  1. 选定一个分类阈值，那么此时的recall是相同的，那么对于达到这个recall效果:
    - ROC曲线中衡量的是FPR（FP/N），也就是样本中的这么多大雁有多少被错当成了飞机
    - PR曲线中衡量的是precision，也就是预测中的这么多飞机有多少真的是飞机（或者说有多少其实是大雁）
  2. 如果非A类样本增加：
    - 预测结果中，由于分类模型没有变，所以将B/C类错误地预测为A类的数量和B/C类正确地预测为B/C必然会同时增加，因此FPR的分子分母同时变大，总体变化不会很大
    - 预测结果中，真A类数量不会变化，但是假A类数量必然增加，precision总体会变小
  3. 如果A类样本增加：
    - B/C类数量不会发生变化，假A类数量也不会发生变化，因此FPR不变 假A类数量不变，真A类数量必然增加，precision总体会变大
    - 综上所述，我们说，样本的分布情况会影响PR曲线形状，但（基本）不会影响ROC曲线形状；也因此，样本分布极不均匀时，优先选择PR曲线评估分类模型的性能（ROC曲线特喵的不受样本分布影响啊）
    - 归根结底，还是因为precision这个指标受样本分布影响太大，如果样本中A类占巨大多数，那么对A类进行预测的precision很容易显得很高，vice versa。


## 参考链接
[1] https://zhuanlan.zhihu.com/p/147663370
[2] https://blog.paperspace.com/mean-average-precision/
