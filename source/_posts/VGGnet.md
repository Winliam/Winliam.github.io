---
title: VGGnet
math: true
categories:
  - - 工作技能
    - 神经网络
    - 经典网络
tags:
  - 深度学习
  - 神经网络
  - 卷积神经网络
  - CNN
  - 经典网络
  - VGGnet
  - 感受野
date: 2020-04-20 23:00:15
---

## 背景简介
牛津VGG团队2014年提出，ImageNet分类任务第二名，定位任务第一名。结构简单，配置丰富，被广泛用作backbone。

## 网络结构
原作有5种配置，分别为11层，13层，16层-1，16层-3，19层。统计层数时不统计池化层和softmax，只统计有weight的网络层。
<div align=center><img title="" src="/img/net/vgg.png" width="80%" height="80%" align=center></div>

## 网络特点
- 所有的卷积核尺寸一致，均采用3x3。
- 引入**感受野（receptive field）**的概念，利用小卷积核的堆叠代替大卷积核，从而减少了参数量。所谓感受野，简单说就是对于某一层的输出的矩阵中的一个元素而言，它对应直接输入层中的那一片区域，就叫做它在那一层的感受野，然后依次向前递归。
  <div align=center><img title="" src="/img/net/rf.png" width="60%" height="60%" align=center></div>
VGG网络对于这个概念，使用了这么一个推论：**相同的感受野得到的特征表达的含义应该是同质的。**因此，在同一个感受野上进行一层大卷积核的卷积操作，和进行多层小卷积核的卷积操作，最终得到的特征应该是同质的。具体操作是，用两层3x3的卷积来表达一层5x5的卷积效果，用三层3x3的卷积来表达一层7x7的卷积效果。由此引入一个计算过程，即如何计算某一层L在其之前某层N上的感受野尺寸。计算公式如下：
 > $$RF_n = (RF_{n+1} - 1) * s + f$$

  该公式其中就是卷积尺寸计算公式的移项，可以理解为已知卷积后的尺寸为1x1，求卷积前的尺寸。并且，不考虑padding，为什么呢？因为考虑padding考虑的是全局尺寸，而感受野讨论的是局部尺寸。

- 参数量减少的原理
 > $$3*3*3 = 27 < 49 = 7*7$$
