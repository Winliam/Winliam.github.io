<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>卡尔曼滤波的矩阵形式</title>
    <link href="/2021/12/05/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E5%AE%9E%E8%B7%B5/"/>
    <url>/2021/12/05/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E5%AE%9E%E8%B7%B5/</url>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p><a href="https://guohongming.xyz/2021/10/22/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E6%A6%82%E8%A6%81/">前面大概说了卡尔曼滤波的原理以及一个简单的demo。</a></p><p>在阅读阿波罗源码，以及其他卡尔曼滤波的教程时发现，往往使用矩阵形式。这里接上篇一起介绍下。</p><h2 id="数学模型"><a href="#数学模型" class="headerlink" title="数学模型"></a>数学模型</h2><ul><li><strong>状态转移方程</strong><script type="math/tex; mode=display">\boldsymbol{x}_k = \boldsymbol{Ax}_{k-1} + \boldsymbol{Bu}_{k-1} + \boldsymbol{w}_k</script>式中：<ul><li>$\boldsymbol{A}$为状态转移矩阵</li><li>$\boldsymbol{B}$为控制矩阵</li><li>$\boldsymbol{u}_{k-1}$为上一时刻的作用于系统的外界控制向量，本文暂时不考虑。</li><li>$\boldsymbol{w}_k$为过程噪声。</li></ul></li><li><strong>观测方程</strong><script type="math/tex; mode=display">\boldsymbol{z}_k = \boldsymbol{Hx}_{k} + \boldsymbol{v}_{k}</script>式中：<ul><li>$\boldsymbol{z}_k$为直接观测值</li><li>$\boldsymbol{H}$为观测矩阵，用来模拟直接观测量和状态量之间的数学关系。有时候需要估计的状态是无法直接被观测到的，所以需要这个公式，这个矩阵</li><li>$\boldsymbol{v}_{k}$为观测噪声</li></ul></li></ul><h2 id="预测过程"><a href="#预测过程" class="headerlink" title="预测过程"></a>预测过程</h2><p>跟之前一样，先将上一时刻得到的最终状态估计值$\boldsymbol{x}_{k-1}$代入状态转移方程，得到当前时刻状态的理论预测值$\hat{\boldsymbol{x}}_k$。即有，</p><script type="math/tex; mode=display">\hat{\boldsymbol{x}}_k = \boldsymbol{Ax}_{k-1}</script><p>类似地，可以得到$\hat{\boldsymbol{x}}_k$的方差$\hat{\boldsymbol{P}}_k$，</p><script type="math/tex; mode=display">\hat{\boldsymbol{P}}_k = \boldsymbol{A}\boldsymbol{P}_{k-1}\boldsymbol{A}^T+\boldsymbol{Q}_k</script><p>其中，$\boldsymbol{Q}_k$为当前时刻过程噪声的协方差矩阵。这两个公式便是矩阵形式的卡尔曼滤波预测过程。</p><h2 id="更新过程"><a href="#更新过程" class="headerlink" title="更新过程"></a>更新过程</h2><p>然后，还是要用当前时刻的观测值$\boldsymbol{z}_k$来校正理论预测值$\hat{\boldsymbol{x}_k}$。</p><p>但是，对于大多数情况，$\boldsymbol{z}_k$和$\hat{\boldsymbol{x}}_k$都不表示相同的状态量（说人话就是，直接观测的量不是需要估计的量，比如引擎内部的温度，由于过高而无法测量，只能测外壁的温度然后估算）。</p><p>这就使得更新过程跟原来不太一样，需要引入观测矩阵$\boldsymbol{H}$进行计算。</p><p>首先，更新（融合）公式如下：</p><script type="math/tex; mode=display">\boldsymbol{x}_k = \hat{\boldsymbol{x}}_{k} + \boldsymbol{K}(\boldsymbol{z}_k - \boldsymbol{H}\hat{\boldsymbol{x}}_{k}) = (\boldsymbol{I} - \boldsymbol{KH})\hat{\boldsymbol{x}}_{k} + \boldsymbol{K}{\boldsymbol{z}}_{k}</script><script type="math/tex; mode=display">\boldsymbol{P}_k = (\boldsymbol{I} - \boldsymbol{KH})\hat{\boldsymbol{P}}_{k}</script><p>式中，只有$\boldsymbol{K}$是未知的（矩阵形式的卡尔曼增益），并且可以看到观测结果的协方差以及噪声都没有直接体现在融合公式中。这是因为这些信息都包含在卡尔曼增益矩阵中，具体有：</p><script type="math/tex; mode=display">\boldsymbol{K} = \hat{\boldsymbol{P}}_{k}\boldsymbol{H}^T\boldsymbol{S}^{-1}</script><p>其中，$\boldsymbol{S}$为$\boldsymbol{z}_k - \boldsymbol{H}\hat{\boldsymbol{x}}_{k}$的协方差矩阵，具体有：</p><script type="math/tex; mode=display">\boldsymbol{S} = \boldsymbol{H}\hat{\boldsymbol{P}}_{k}\boldsymbol{H}^T+\boldsymbol{R}_k</script><p>综合来看，预测过程需要先计算$\boldsymbol{S}$，再计算$\boldsymbol{K}$，然后用观测值$\boldsymbol{z}_k$和$\boldsymbol{K}$参与理论预测值（状态及方差）的校正。</p><h2 id="具体实例"><a href="#具体实例" class="headerlink" title="具体实例"></a>具体实例</h2><p>以阿波罗源码中目标跟踪所采用的“匀速卡尔曼滤波器”为例，应用以上理论。首先确定状态转移方程和观测方程，需要估计的状态向量为二维的坐标及车速，由于是匀速运动模型，所以有：</p><script type="math/tex; mode=display">\left[\begin{array}{c}  x      \\ y      \\ \dot x      \\ \dot y      \\\end{array}\right]_k=\left[\begin{array}{cccc}  1 & 0 &dt &0      \\ 0 & 1 &0 &dt      \\ 0 & 0 &1 &0      \\ 0 & 0 &0 &1      \\\end{array}\right]\left[\begin{array}{c}  x      \\ y      \\ \dot x      \\ \dot y      \\\end{array}\right]_{k-1}</script><p>直接观测状态为二维坐标，因此可以得到观测方程为：</p><script type="math/tex; mode=display">\left[\begin{array}{c}  z_x      \\ z_y      \\\end{array}\right]_k =\left[\begin{array}{cccc}  1 & 0 &0 &0      \\ 0 & 1 &0 &0      \\\end{array}\right]\left[\begin{array}{c}  x      \\ y      \\ \dot x      \\ \dot y      \\\end{array}\right]_{k}</script><p>至此，便得到了状态转移矩阵$\boldsymbol{A}$和观测矩阵$\boldsymbol{H}$。然后在初始化时给定$\boldsymbol{x}_0$和$\boldsymbol{P}_0$，便可完成<strong>预测</strong>、<strong>更新</strong>、<strong>预测</strong>…的迭代过程。</p><blockquote><p>其实还要给定$\boldsymbol{Q}$和$\boldsymbol{R}$，过程噪声视情况而定要不要跟着迭代，阿波罗的做法是对于目标在图像中的中心点不跟着迭代，但是对于目标中心点的3D坐标跟着迭代。测量噪声一般来自于传感器厂家，对于整个卡尔曼滤波过程而言是一个常数，初始化时给定即可，一般不跟着迭代。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>数据融合</category>
      
    </categories>
    
    
    <tags>
      
      <tag>卡尔曼滤波</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>逆透视映射（InversePerspectiveMapping）</title>
    <link href="/2021/11/23/%E9%80%86%E9%80%8F%E8%A7%86%E6%98%A0%E5%B0%84%EF%BC%88InversePerspectiveMapping%EF%BC%89/"/>
    <url>/2021/11/23/%E9%80%86%E9%80%8F%E8%A7%86%E6%98%A0%E5%B0%84%EF%BC%88InversePerspectiveMapping%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>众所周知，真实世界的三维坐标在向相机的成像平面上投影时，会损失深度信息，使得整个过程不可逆。也就是说，已知图像中一个点的坐标$(u,v)$是无法求得该点在真实世界的三维坐标$(X_w, Y_w, Z_w)$的。</p><p>那么，如果额外多给一项信息，即现在关心的所有三维世界的点都是同在一个平面(比如路面上的车道线)上呢？此时图像像素坐标系和世界坐标系之间的坐标转换就变成了可逆关系。</p><p>这种情形下，从像素坐标系坐标得到世界坐标系坐标的做法称作<strong>逆透视映射</strong>。</p><h2 id="应用一：同一物理平面在两幅图像之间的转换"><a href="#应用一：同一物理平面在两幅图像之间的转换" class="headerlink" title="应用一：同一物理平面在两幅图像之间的转换"></a>应用一：同一物理平面在两幅图像之间的转换</h2><p>现有：</p><ul><li>一个物理世界的平面，称作$P$</li><li>两个不同位置的相机，称作$A$和$B$</li><li>$P$在$A$的成像平面上的投影，称作$P_A$，其上一点在$A$的像素坐标系上的坐标记作$(u_A,v_A)$</li><li>$P$在$B$的成像平面上的投影，称作$P_B$，其上一点在$B$的像素坐标系上的坐标记作$(u_B,v_B)$</li></ul><p><div align=center><img title="" src="/img/article/homo1.jpg" width="129%" height="129%" align=center></div><br></p><p>那么，$P_A$和$P_B$之间互为投影变换（单应性变换），这意味着存在一个3x3的可逆矩阵$\boldsymbol{H}$，使得：</p><script type="math/tex; mode=display">\left[\begin{array}{c}  u_A      \\ v_A      \\ 1      \\\end{array}\right] =\boldsymbol{H}\left[\begin{array}{c}  u_B      \\ v_B      \\ 1      \\\end{array}\right]</script><p>矩阵$\boldsymbol{H}$中的9个元素的取值可以通过在两幅图像中取4组不共线的对应点解方程得到，也可以通过两个相机内外参矩阵之间的关系得到。</p><h2 id="应用二：车道线物理坐标的求解"><a href="#应用二：车道线物理坐标的求解" class="headerlink" title="应用二：车道线物理坐标的求解"></a>应用二：车道线物理坐标的求解</h2><p>道路平面上的车道线上的点在世界坐标系中的坐标，与对应点在前视相机像素坐标系中的坐标之间，同样存在上述单应性变换关系。这一点可以从下面的公式推导过程中得到：</p><p><div align=center><img title="" src="/img/article/homo2.png" width="80%" height="80%" align=center></div><br></p><p>首先，图像像素坐标系和世界坐标系之间的坐标转换关系如下：</p><script type="math/tex; mode=display">\left[\begin{array}{c}  u      \\ v      \\ 1      \\\end{array}\right]=\frac{1}{Z_c}\boldsymbol{K}\boldsymbol{E}\left[\begin{array}{c}  X_w      \\ Y_w      \\ Z_w      \\ 1      \\\end{array}\right]=\frac{1}{Z_c}\left[\begin{array}{ccc}  \frac{f}{d_x} & 0 &fu_0   \\ 0 & \frac{f}{d_y} &fv_0   \\ 0 & 0 &1   \\\end{array}\right]\left[\begin{array}{cccc}  r_{11} & r_{12} &r_{12} &t_{1}      \\ r_{21} & r_{22} &r_{23} &t_{2}      \\ r_{31} & r_{32} &r_{33} &t_{3}      \\\end{array}\right]\left[\begin{array}{c}  X_w      \\ Y_w      \\ Z_w      \\ 1      \\\end{array}\right]</script><p>在这个应用场景下有，$Z_w=0$，因此有：</p><script type="math/tex; mode=display">\left[\begin{array}{c}  u      \\ v      \\ 1      \\\end{array}\right]=\frac{1}{r_{31}X_w+r_{32}Y_w+t_3}\left[\begin{array}{ccc}  \frac{f}{d_x} & 0 &fu_0   \\ 0 & \frac{f}{d_y} &fv_0   \\ 0 & 0 &1   \\\end{array}\right]\left[\begin{array}{cccc}  r_{11} & r_{12} &r_{12} &t_{1}      \\ r_{21} & r_{22} &r_{23} &t_{2}      \\ r_{31} & r_{32} &r_{33} &t_{3}      \\\end{array}\right]\left[\begin{array}{c}  X_w      \\ Y_w      \\ 0      \\ 1      \\\end{array}\right]</script><p>合并内外参矩阵得：</p><script type="math/tex; mode=display">\left[\begin{array}{c}  u      \\ v      \\ 1      \\\end{array}\right]=\frac{1}{r_{31}X_w+r_{32}Y_w+t_3}\left[\begin{array}{cccc}  h_{11} & h_{12} &h_{12} &h_{13}      \\ h_{21} & h_{22} &h_{23} &h_{23}      \\ r_{31} & r_{32} &r_{33} &t_{3}      \\\end{array}\right]\left[\begin{array}{c}  X_w      \\ Y_w      \\ 0      \\ 1      \\\end{array}\right]</script><p>注意到，$\boldsymbol{H}$矩阵中的第三列元素其实是无效的，因此有：</p><script type="math/tex; mode=display">\left[\begin{array}{c}  u      \\ v      \\ 1      \\\end{array}\right]=\frac{1}{r_{31}X_w+r_{32}Y_w+t_3}\left[\begin{array}{ccc}  h_{11} & h_{12}  &h_{13}      \\ h_{21} & h_{22}  &h_{23}      \\ r_{31} & r_{32}  &t_{3}      \\\end{array}\right]\left[\begin{array}{c}  X_w      \\ Y_w      \\ 1      \\\end{array}\right]</script><p>上式中，可以看到$\boldsymbol{H}$矩阵的前两列由内参矩阵和旋转矩阵相乘得到，第三列由内参矩阵和平移向量相乘得到。这也是apollo代码中，用conceptual方式求取透视投影矩阵所基于的原理。</p><p>这样，用$\boldsymbol{H}$的逆矩阵与像素坐标点相乘，然后归一化Z坐标，即可得到像素坐标点在世界坐标系中的XY坐标。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://towardsdatascience.com/a-hands-on-application-of-homography-ipm-18d9e47c152f">https://towardsdatascience.com/a-hands-on-application-of-homography-ipm-18d9e47c152f</a></li><li><a href="https://zhuanlan.zhihu.com/p/74597564">https://zhuanlan.zhihu.com/p/74597564</a></li><li><a href="https://leijiezhang001.github.io/lane-det-from-BEV/">https://leijiezhang001.github.io/lane-det-from-BEV/</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>无人驾驶</category>
      
    </categories>
    
    
    <tags>
      
      <tag>车道线检测</tag>
      
      <tag>Inverse Perspective Mapping</tag>
      
      <tag>单应性矩阵</tag>
      
      <tag>homography</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>相机成像原理</title>
    <link href="/2021/11/21/camera%E7%9B%B8%E5%85%B3%E7%9A%84%E5%9D%90%E6%A0%87%E7%B3%BB/"/>
    <url>/2021/11/21/camera%E7%9B%B8%E5%85%B3%E7%9A%84%E5%9D%90%E6%A0%87%E7%B3%BB/</url>
    
    <content type="html"><![CDATA[<h2 id="针孔模型的成像原理"><a href="#针孔模型的成像原理" class="headerlink" title="针孔模型的成像原理"></a>针孔模型的成像原理</h2><p>相机的成像原理可以借助下图所示的针孔模型来加以解释：</p><div align=center><img title="" src="/img/article/pinhole_model.png" width="60%" height="60%" align=center></div><p>假设在一个空间中，只包含光源、树和感光白板三个物体。当光源发出的光打在的树上时，会发生漫反射现象。即，反射光线会以树上任一点为球心射向所有方向。</p><p>此时如果只是简单地在树的前方放置一个感光白板，以白板上的任意一个点A为研究对象，该点将收到来自树上所有反射点的反射光线。这些光线叠加在一起，将使得感光点A无法专一地只体现某一个反射点的特征。宏观来看，感光白板上无法产生任何关于这棵树的有效视觉信息。</p><p>如果在树和感光白板之间加一个针孔板，那么感光点A的光线来源就只有树上的一个反射点了，并且反射点-针孔-感光点三点成一线。这样，宏观来看，感光白板上便产生了一棵树。</p><h2 id="相机坐标系"><a href="#相机坐标系" class="headerlink" title="相机坐标系"></a>相机坐标系</h2><p>盘点上述成像过程中涉及的坐标系，一般有以下4个：</p><ol><li><strong>世界坐标系</strong>，以相机所在的物理世界中的某个点为坐标原点（比如车辆的后轴中心），其中一点记作$(X_w,Y_w,Z_w)^T$；</li><li><strong>相机坐标系</strong>，以光心(针孔)为坐标原点，其中一点记作$(X_c,Y_c,Z_c)^T$；</li><li><strong>图像物理坐标系</strong>，以光心在感光板上的对应位置为坐标原点，其中一点记作$(x,y)^T$；</li><li><strong>图像像素坐标系</strong>，一般以图像的左上角为坐标原点，其中一点记作$(u,v)^T$，并且单位不再是长度，而是像素个数；</li></ol><div align=center><img title="" src="/img/article/camera_coordinate.png" width="90%" height="90%" align=center></div><h2 id="坐标系转换关系"><a href="#坐标系转换关系" class="headerlink" title="坐标系转换关系"></a>坐标系转换关系</h2><p>鉴于“反射点-针孔-感光点三点一线”的几何特征，给定一个世界坐标系中的点$(X_w,Y_w,Z_w)^T$，是可以求得该点在图像像素坐标系中的坐标的。</p><h3 id="1-世界坐标系-相机坐标系"><a href="#1-世界坐标系-相机坐标系" class="headerlink" title="1.世界坐标系-相机坐标系"></a>1.世界坐标系-相机坐标系</h3><p>两个坐标系之间是简单地旋转和平移关系，因此有：</p><script type="math/tex; mode=display">\left[\begin{array}{c}  X_c      \\ Y_c      \\ Z_c      \\\end{array}\right] =\left[\begin{array}{cccc}  r_{11} & r_{12} &r_{12} &t_{1}      \\ r_{21} & r_{22} &r_{23} &t_{2}      \\ r_{31} & r_{32} &r_{33} &t_{3}      \\\end{array}\right]\left[\begin{array}{c}  X_w      \\ Y_w      \\ Z_w      \\ 1      \\\end{array}\right]</script><p>可以看到，式中的转换参数与相机本身的属性并无关系，因此一般将该矩阵称作相机的<strong>外参</strong>。</p><h3 id="2-相机坐标系-图像物理坐标系"><a href="#2-相机坐标系-图像物理坐标系" class="headerlink" title="2.相机坐标系-图像物理坐标系"></a>2.相机坐标系-图像物理坐标系</h3><p>从相机坐标系到图像物理坐标系的转换关键点在于，这是一个3D-2D的转换，并且存在一个由相似三角形产生的缩放关系。因此有：</p><script type="math/tex; mode=display">\left[\begin{array}{c}  x      \\ y      \\ 1      \\\end{array}\right] =\frac{1}{Z_c}\left[\begin{array}{ccc}  f & 0 &0   \\ 0 & f &0   \\ 0 & 0 &1   \\\end{array}\right]\left[\begin{array}{c}  X_c      \\ Y_c      \\ Z_c      \\\end{array}\right]</script><p>其中f为相机焦距，可以看到，这个转换是不可逆的，因此我们称<strong>单目相机损失了深度信息</strong>。</p><h3 id="3-图像物理坐标系-图像像素坐标系"><a href="#3-图像物理坐标系-图像像素坐标系" class="headerlink" title="3.图像物理坐标系-图像像素坐标系"></a>3.图像物理坐标系-图像像素坐标系</h3><p>这是一个2D-2D的转换，而且在同一个平面上，只是坐标原点和坐标的单位需要转换。因此有：</p><script type="math/tex; mode=display">\left[\begin{array}{c}  u      \\ v      \\ 1      \\\end{array}\right] =\left[\begin{array}{ccc}  \frac{1}{d_x} & 0 &u_0   \\ 0 & \frac{1}{d_y} &v_0   \\ 0 & 0 &1   \\\end{array}\right]\left[\begin{array}{c}  x      \\ y      \\ 1      \\\end{array}\right]</script><p>其中，在x方向上，每个像素的尺寸为$d_x$毫米；$u_0$指光心在从左数第$u_0$个像素上。</p><h3 id="4-汇总"><a href="#4-汇总" class="headerlink" title="4.汇总"></a>4.汇总</h3><p>综合来看，先将2和3结合，得到：</p><script type="math/tex; mode=display">\left[\begin{array}{c}  u      \\ v      \\ 1      \\\end{array}\right] =\frac{1}{Z_c}\left[\begin{array}{ccc}  f & 0 &0   \\ 0 & f &0   \\ 0 & 0 &1   \\\end{array}\right]\left[\begin{array}{ccc}  \frac{1}{d_x} & 0 &u_0   \\ 0 & \frac{1}{d_y} &v_0   \\ 0 & 0 &1   \\\end{array}\right]\left[\begin{array}{c}  X_c      \\ Y_c      \\ Z_c      \\\end{array}\right]=\frac{1}{Z_c}\boldsymbol{K}\left[\begin{array}{c}  X_c      \\ Y_c      \\ Z_c      \\\end{array}\right]</script><p>其中$\boldsymbol{K}$中的参数只跟相机属性相关，称作相机的<strong>内参</strong>，是一个3x3的矩阵。</p><p>然后，再加上1中的外参，得到：</p><script type="math/tex; mode=display">\left[\begin{array}{c}  u      \\ v      \\ 1      \\\end{array}\right]=\frac{1}{Z_c}\boldsymbol{K}\left[\begin{array}{cccc}  r_{11} & r_{12} &r_{12} &t_{1}      \\ r_{21} & r_{22} &r_{23} &t_{2}      \\ r_{31} & r_{32} &r_{33} &t_{3}      \\\end{array}\right]\left[\begin{array}{c}  X_w      \\ Y_w      \\ Z_w      \\ 1      \\\end{array}\right]=\frac{1}{Z_c}\boldsymbol{K}\boldsymbol{E}\left[\begin{array}{c}  X_w      \\ Y_w      \\ Z_w      \\ 1      \\\end{array}\right]</script><p>其中$\boldsymbol{E}$为相机外参，是一个3x4矩阵。</p>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
    </categories>
    
    
    <tags>
      
      <tag>camera</tag>
      
      <tag>坐标系</tag>
      
      <tag>针孔模型</tag>
      
      <tag>成像原理</tag>
      
      <tag>内参</tag>
      
      <tag>外参</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TensorRT C++ API使用方法</title>
    <link href="/2021/11/10/TensorRT%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/"/>
    <url>/2021/11/10/TensorRT%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>把深度学习模型用pytorch等框架搭建、训练后，要把模型保存下来，部署到生产环境中服务于实际业务。</p><p>生产环境中运行的深度学习模型有两个特点，一当然是要快，二是只做单帧数据的前向计算（推理）。为了适应这两个特点，引入了TensorRT这个工具。</p><p>简单地，可以将它看作一个类似pytorch的深度学习框架。但是这个框架不提供模型训练相关的脚手架，只提供模型构建、前向计算和模型格式转换的工具。并且得益于NV一些未开源的黑科技，用TensorRT构建出来的模型能够更快地进行前向计算。</p><p><strong>关键概念</strong>：<br><strong>ONNX parser</strong>: Takes a converted PyTorch trained model into the ONNX format as input and populates a network object in TensorRT.<br><strong>Builder</strong>: Takes a network in TensorRT and generates an engine that is optimized for the target platform.<br><strong>Engine</strong>: Takes input data, performs inferences, and emits inference output.<br><strong>Logger</strong>: Associated with the builder and engine to capture errors, warnings, and other information during the build and inference phases.</p><h2 id="使用步骤"><a href="#使用步骤" class="headerlink" title="使用步骤"></a>使用步骤</h2><h3 id="0-头文件与namespace"><a href="#0-头文件与namespace" class="headerlink" title="0. 头文件与namespace"></a>0. 头文件与namespace</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> “NvInfer.h”</span><br><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> nvinfer1;<br></code></pre></td></tr></table></figure><h3 id="1-build阶段"><a href="#1-build阶段" class="headerlink" title="1. build阶段"></a>1. build阶段</h3><h4 id="1-0-创建Logger"><a href="#1-0-创建Logger" class="headerlink" title="1.0 创建Logger"></a>1.0 创建Logger</h4><p>创建builder之前，需要先根据需要继承自己的Logger类。其中主要的任务是override父类中的log方法，定义哪个级别的信息会被log，如何log。<br><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-keyword">class</span> <span class="hljs-symbol">RTLogger</span> : <span class="hljs-symbol">public</span> <span class="hljs-symbol">nvinfer1::<span class="hljs-symbol">ILogger</span></span> &#123;<br>  <span class="hljs-built_in">void</span> log(Severity severity, <span class="hljs-keyword">const</span> char *msg) <span class="hljs-keyword">override</span> &#123;<br>    <span class="hljs-keyword">if</span> (severity != Severity::kINFO)    &#123;<br>      AINFO &lt;&lt; msg;<br>    &#125;<br>  &#125;<br>&#125; rt_gLogger;<br></code></pre></td></tr></table></figure></p><h4 id="1-1-创建builder"><a href="#1-1-创建builder" class="headerlink" title="1.1 创建builder"></a>1.1 创建builder</h4><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">nvinfer1::IBuilder *builder_= nvinfer1::<span class="hljs-built_in">createInferBuilder</span>(rt_gLogger);<br></code></pre></td></tr></table></figure><h4 id="1-2-创建network"><a href="#1-2-创建network" class="headerlink" title="1.2 创建network"></a>1.2 创建network</h4><p>创建network实例的过程其实跟其他框架大同小异，只不过因为受众少，包装地没那么精致而已。</p><h5 id="1-2-1-创建空的network实例"><a href="#1-2-1-创建空的network实例" class="headerlink" title="1.2.1 创建空的network实例"></a>1.2.1 创建空的network实例</h5><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">nvinfer1::INetworkDefinition *network_ = builder_-&gt;<span class="hljs-built_in">createNetwork</span>();<br></code></pre></td></tr></table></figure><h5 id="1-2-2-填充network实例"><a href="#1-2-2-填充network实例" class="headerlink" title="1.2.2 填充network实例"></a>1.2.2 填充network实例</h5><p>上一步创建的network实例是一个空的、不包含网络层的对象，需要在此基础上添加网络层。由于TensorRT作为框架，是不做BP只做前向的，所以在构建网络时要同步给入权重。<br>此时有两种选择来做这件事:</p><ol><li>拿一个现成的模型文件(包含权重)进来，用TensorRT的格式转换工具转换一下；以ONNX的模型文件为例(ONNX模型是包含权重的)：<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">#<span class="hljs-keyword">include</span> “<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">NvOnnxParser</span>.</span></span>h”<br><br>using namespace nvonnxparser;<br><br>IParser*  parser = create<span class="hljs-constructor">Parser(<span class="hljs-operator">*</span><span class="hljs-params">network</span>, <span class="hljs-params">logger</span>)</span>;<br>parser-&gt;parse<span class="hljs-constructor">FromFile(<span class="hljs-params">modelFile</span>, ILogger::Severity::<span class="hljs-params">kWARNING</span>)</span>;<br><span class="hljs-keyword">for</span> (int32_t i = <span class="hljs-number">0</span>; i &lt; parser.get<span class="hljs-constructor">NbErrors()</span>; ++i)&#123;<br>std::cout &lt;&lt; parser-&gt;get<span class="hljs-constructor">Error(<span class="hljs-params">i</span>)</span>-&gt;desc<span class="hljs-literal">()</span> &lt;&lt; std::endl;<br>&#125;<br></code></pre></td></tr></table></figure></li><li>拿一个描述模型结构的配置文件，用TensorRT的模型搭建工具依次添加各种各样的网络层，从无到有地搭建出来。同时，在添加网络时，要提供对应的网络权重。<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">auto data = network_-&gt;add<span class="hljs-constructor">Input(<span class="hljs-params">dims_pair</span>.<span class="hljs-params">first</span>.<span class="hljs-params">c_str</span>()</span>, nvinfer1::DataType::kFLOAT, dims_pair.second);<br>auto convLayer = network-&gt;add<span class="hljs-constructor">Convolution(<span class="hljs-operator">*</span><span class="hljs-params">inTensor</span>, <span class="hljs-params">nbOutputs</span>, <span class="hljs-params">nvinfer1</span>::DimsHW&#123;<span class="hljs-params">kernelH</span>, <span class="hljs-params">kernelW</span>&#125;, <span class="hljs-params">wt</span>, <span class="hljs-params">bias_weight</span>)</span>;<br>auto softmaxLayer = net-&gt;add<span class="hljs-constructor">SoftMax(<span class="hljs-operator">*</span><span class="hljs-params">inputs</span>[0])</span>;<br></code></pre></td></tr></table></figure>至此，填充完网络层和权重参数后，便完成了网络的搭建。</li></ol><h4 id="1-3-创建engine"><a href="#1-3-创建engine" class="headerlink" title="1.3 创建engine"></a>1.3 创建engine</h4><p>完成网络构建之后，其实只是把原有网络模型，以tensorRT的格式重新构建了一下，还没有进行优化加速。所以，现在要把优化前的network转成优化后的engine。</p><p>要做到这件事需要两种信息，一是优化什么，二是怎么优化。前者已经有了，就是network。后者需要构造一个config接口，用这个接口来配置优化项。</p><p>并且，在10.0之后的版本，创建engine之前还要先创建一个序列化模型，可用于保存到磁盘上。真正使用时，先反序列化模型，然后再构造出engine实例。<br><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">IBuilderConfig* config = builder-&gt;create<span class="hljs-constructor">BuilderConfig()</span>;<br>config-&gt;set<span class="hljs-constructor">MaxWorkspaceSize(1U &lt;&lt; 20)</span>;<br><br>IHostMemory*  serializedModel = builder-&gt;build<span class="hljs-constructor">SerializedNetwork(<span class="hljs-operator">*</span><span class="hljs-params">network</span>, <span class="hljs-operator">*</span><span class="hljs-params">config</span>)</span>;<br><br>IRuntime* runtime = create<span class="hljs-constructor">InferRuntime(<span class="hljs-params">logger</span>)</span>;<br>ICudaEngine* engine = runtime-&gt;deserialize<span class="hljs-constructor">CudaEngine(<span class="hljs-params">modelData</span>, <span class="hljs-params">modelSize</span>)</span>;<br></code></pre></td></tr></table></figure></p><h3 id="2-inference阶段"><a href="#2-inference阶段" class="headerlink" title="2. inference阶段"></a>2. inference阶段</h3><p>The engine holds the optimized model, but to perform inference we will need to manage additional state for intermediate activations. This is done via the <code>ExecutionContext</code> interface:<br><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs xl">IE<span class="hljs-function"><span class="hljs-title">xecutionContext</span> *context = engine-&gt;</span>createExecutionContext();<br></code></pre></td></tr></table></figure></p><p>然后，在GPU上为模型的输入和输出各申请一块buffer，<br><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs abnf">int32_t inputIndex = engine-&gt;getBindingIndex(INPUT_NAME)<span class="hljs-comment">;</span><br>int32_t outputIndex = engine-&gt;getBindingIndex(OUTPUT_NAME)<span class="hljs-comment">;</span><br><br>void* buffers[<span class="hljs-number">2</span>]<span class="hljs-comment">;</span><br>buffers[inputIndex] = inputBuffer<span class="hljs-comment">;</span><br>buffers[outputIndex] = outputBuffer<span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure><br>最后，执行推理（一般是GPU与CPU异步，即CPU上的控制流在调用GPU核函数之后并不阻塞）<br><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">context-&gt;enqueue<span class="hljs-constructor">V2(<span class="hljs-params">buffers</span>, <span class="hljs-params">stream</span>, <span class="hljs-params">nullptr</span>)</span>;<br></code></pre></td></tr></table></figure></p><p>由于是异步调用，在推理执行完毕之后一般还要<code>cudaDeviceSynchronize()</code>一下，等待推理过程执行完毕，然后将output结果从GPU上拷贝到CPU上。</p><p>至此，整个推理过程完毕。</p><h2 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h2><ol><li>不同的tensorRT版本API细节有所不同，这里以TensorRT 8.2.0 Early Access (EA)为例</li><li>A CUDA context is automatically created the first time TensorRT makes a call to CUDA, if none exists prior to that point. It is generally preferable to create and configure the CUDA context yourself before the first call to TensoRT.</li><li>Interface classes in the TensorRT™ C++ API begin with the prefix I</li><li>config interface has many properties that you can set in order to control how TensorRT optimizes the network. One important property is the maximum workspace size. Layer implementations often require a temporary workspace, and this parameter limits the maximum size that any layer in the network can use. If insufficient workspace is provided, it is possible that TensorRT will not be able to find an implementation for a layer.</li><li>Serialized engines are not portable across platforms or TensorRT versions. Engines are specific to the exact GPU model they were built on (in addition to the platform and the TensorRT version).</li><li>The serialized engine contains the necessary copies of the weights, the parser, network definition, builder configuration and builder are no longer necessary and may be safely deleted.</li></ol><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#perform_inference_c">官方文档8.2.0 Early Access (EA)</a></li><li><a href="https://stackoverflow.com/questions/19193468/why-do-we-need-cudadevicesynchronize-in-kernels-with-device-printf">https://stackoverflow.com/questions/19193468/why-do-we-need-cudadevicesynchronize-in-kernels-with-device-printf</a></li><li><a href="https://blog.csdn.net/Bruce_0712/article/details/73477126">https://blog.csdn.net/Bruce_0712/article/details/73477126</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TensorRT</tag>
      
      <tag>ONNX</tag>
      
      <tag>inference</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>C++类继承机制中的作用域嵌套问题</title>
    <link href="/2021/11/08/C-%E7%B1%BB%E7%BB%A7%E6%89%BF%E6%9C%BA%E5%88%B6%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8%E5%9F%9F%E5%B5%8C%E5%A5%97%E9%97%AE%E9%A2%98/"/>
    <url>/2021/11/08/C-%E7%B1%BB%E7%BB%A7%E6%89%BF%E6%9C%BA%E5%88%B6%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8%E5%9F%9F%E5%B5%8C%E5%A5%97%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>OOP的三个支撑概念的其中之二，继承和动态绑定，都会带来作用域模糊的问题，这里来梳理以下。</p><h2 id="一般规则"><a href="#一般规则" class="headerlink" title="一般规则"></a>一般规则</h2><p>给定一个类的实例/类的实例的指针/类的实例的引用<code>p</code>，现在要通过<code>p</code>来访问它的对象<code>mem</code>。<code>mem</code>可以是方法也可以是成员，不影响下面的逻辑展开。</p><p>整个调用过程，可以用下面的流程图表示：</p><div align=center><img title="" src="/img/article/cpp_herit.jpg" width="80%" height="80%" align=center></div><p><br>注意几个要点：</p><ol><li>名称的搜索只会向父类递归，不会向子类递归。</li><li>名称查找成功后，直接进行类型检查，不成功直接报错，而不是继续递归查找。</li></ol><h2 id="补充案例"><a href="#补充案例" class="headerlink" title="补充案例"></a>补充案例</h2><h3 id="案例一"><a href="#案例一" class="headerlink" title="案例一"></a>案例一</h3><p>考虑一个三重继承A-&gt;B-&gt;C，当A和C之间的动态绑定发生时，如C没有override这个被A指针调用的虚函数，但是B override了，那么最终被调用的将是B的版本。也就是说动态绑定的优先级是动态类型，然后动态类型的直接基类，然后直接基类的直接基类，依次类推。</p><h3 id="案例二"><a href="#案例二" class="headerlink" title="案例二"></a>案例二</h3><p>考虑在一对虚函数中，子类的虚函数函数体中调用了另外一个成员函数。如果这个成员函数涉及到动态绑定，那么按照案例一中的优先级，寻找最合适的虚函数版本即可。如果不涉及动态绑定，那么应该按照“子类作用域嵌套在父类作用域内”的原则取选取最合适的函数版本。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;iostream&gt;</span></span><br><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">A</span> &#123;</span><br><span class="hljs-keyword">private</span>:<br>    <span class="hljs-keyword">int</span> a = <span class="hljs-number">1</span>;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">f1</span><span class="hljs-params">(<span class="hljs-keyword">int</span> x)</span></span>&#123;<br>        std::cout &lt;&lt; <span class="hljs-string">&quot;this is class A, f1 &quot;</span> &lt;&lt; x &lt;&lt; std::endl;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">void</span> <span class="hljs-title">f2</span><span class="hljs-params">()</span></span>&#123;<br>        std::cout &lt;&lt; <span class="hljs-string">&quot;this is class A, f2&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">B</span> :</span> <span class="hljs-keyword">public</span> A&#123;<br><span class="hljs-keyword">private</span>:<br>    <span class="hljs-keyword">int</span> b = <span class="hljs-number">2</span>;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">f1</span><span class="hljs-params">(<span class="hljs-keyword">int</span> x)</span></span>&#123;<br>        std::cout &lt;&lt; <span class="hljs-string">&quot;this is class B, f1 &quot;</span> &lt;&lt; x &lt;&lt; std::endl;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">f2</span><span class="hljs-params">()</span></span>&#123;<br>        std::cout &lt;&lt; <span class="hljs-string">&quot;this is class B, f2&quot;</span> &lt;&lt; std::endl;<br>        <span class="hljs-built_in">f1</span>(<span class="hljs-number">10</span>);<br>    &#125;<br>&#125;;<br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">C</span> :</span> <span class="hljs-keyword">public</span> B&#123;<br><span class="hljs-keyword">private</span>:<br>    <span class="hljs-keyword">int</span> c = <span class="hljs-number">3</span>;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">f1</span><span class="hljs-params">(<span class="hljs-keyword">int</span> x)</span></span>&#123;<br>        std::cout &lt;&lt; <span class="hljs-string">&quot;this is class C, f1 &quot;</span> &lt;&lt; x &lt;&lt; std::endl;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">f2</span><span class="hljs-params">()</span></span>&#123;<br>        std::cout &lt;&lt; <span class="hljs-string">&quot;this is class C, f2&quot;</span> &lt;&lt; std::endl;<br>        <span class="hljs-built_in">f1</span>(<span class="hljs-number">10</span>);<br>    &#125;<br>&#125;;<br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    A* pa = <span class="hljs-keyword">new</span> C;<br>    pa-&gt;<span class="hljs-built_in">f2</span>();<br>    <span class="hljs-keyword">delete</span> pa;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>C/C++笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>继承</tag>
      
      <tag>动态绑定</tag>
      
      <tag>虚函数</tag>
      
      <tag>作用域</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>coredump文件的使用</title>
    <link href="/2021/11/04/coredump%E6%96%87%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2021/11/04/coredump%E6%96%87%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>程序崩溃之后，一般会生成一个coredump文件。</p><p>跟可重定位目标文件和可执行目标文件一样，这个文件也是一个elf文件，是程序崩溃瞬间进程栈和寄存器状态的快照。</p><p>可以使用gdb加载这个文件，查看崩溃瞬间的程序运行状态。</p><h2 id="coredump开关"><a href="#coredump开关" class="headerlink" title="coredump开关"></a>coredump开关</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#查看允许生成的文件大小上限，coresize=0意味着不允许产生, unlimited表示无限制</span><br><span class="hljs-built_in">ulimit</span> -a<br><br><span class="hljs-comment">#设置权限</span><br><span class="hljs-built_in">ulimit</span> -c unlimited<br></code></pre></td></tr></table></figure><h2 id="coredump文件路径"><a href="#coredump文件路径" class="headerlink" title="coredump文件路径"></a>coredump文件路径</h2><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">#查看路径</span><br>cat <span class="hljs-regexp">/proc/</span>sys<span class="hljs-regexp">/kernel/</span>core_pattern<br><br><span class="hljs-comment">#设置路径</span><br><span class="hljs-comment">##临时修改</span><br>echo ‘<span class="hljs-regexp">/var/</span>log<span class="hljs-regexp">/%e.core.%p’ &gt; /</span>proc<span class="hljs-regexp">/sys/</span>kernel/core_pattern<br><br><span class="hljs-comment">##永久修改</span><br><span class="hljs-regexp">/sbin/</span>sysctl -w kernel.core_pattern=<span class="hljs-regexp">/var/</span>log/%e.core.%p<br></code></pre></td></tr></table></figure><h2 id="gdb加载方式"><a href="#gdb加载方式" class="headerlink" title="gdb加载方式"></a>gdb加载方式</h2><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">gdb [exe] [core_file]<br>gdb mainboard <span class="hljs-regexp">/apollo/</span>data<span class="hljs-regexp">/core/</span>core_mainboard.<span class="hljs-number">5852</span><br></code></pre></td></tr></table></figure><h2 id="gdb常用命令"><a href="#gdb常用命令" class="headerlink" title="gdb常用命令"></a>gdb常用命令</h2><figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs axapta">bt<span class="hljs-meta">#查看调用栈</span><br><span class="hljs-keyword">where</span><span class="hljs-meta">#同上</span><br>frame stk_num<span class="hljs-meta">#切换函数栈</span><br><span class="hljs-keyword">print</span> var_name<span class="hljs-meta">#查看变量值</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>操作系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>coredump</tag>
      
      <tag>gdb</tag>
      
      <tag>debug</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>protobuf基础用法</title>
    <link href="/2021/10/31/protobuf%E5%9F%BA%E7%A4%8E%E7%94%A8%E6%B3%95/"/>
    <url>/2021/10/31/protobuf%E5%9F%BA%E7%A4%8E%E7%94%A8%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>自动驾驶框架常用protobuf作为节点之间通讯的工具，出现频率很高，了解一下基本情况。</p><p>我们知道，<strong>数据只要出内存就要进行序列化，进内存就要进行反序列化</strong>。</p><p>这是因为，所有数据在内存中存放的形式都是一串0/1。比如，我们定义一个结构体，然后对其实例化，我们就在内存中的某个位置写入了这串0/1序列。当我们想把这一个结构体所表示的“信息”给到另外一个用户时，应该怎么做呢？</p><p>我们可以把这一串0/1序列从内存中写到硬盘上，形成一个文件，然后把这个文件发送给其他用户。由内存中的0/1序列（或者说一个结构体实例）得到这个文件的过程，就是序列化过程。</p><p>用户在拿到这一文件后想使用其中包含的信息，就必须先将其恢复为结构体，才能方便地进行操作。由二进制序列（或者说拿到的这个文件）得到结构体实例的过程，就是反序列化过程。</p><p>那么protobuf做了什么呢？首先，它允许我们以最简的方式定义待传递的信息结构（<code>.proto文件</code>），然后使用<code>protoc</code>程序处理<code>.proto</code>文件，自动生成C++结构体，并配套一系列操作这个结构体的方法（API）。</p><p>所以说，protobuf的使用围绕三个核心要素:</p><ul><li><code>.proto</code>文件</li><li>compiler</li><li>API</li></ul><h2 id="proto文件"><a href="#proto文件" class="headerlink" title=".proto文件"></a><code>.proto</code>文件</h2><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs protobuf"><span class="hljs-comment">// protobuf有2和3两个版本，语法不同，所以要声明版本</span><br>syntax = <span class="hljs-string">&quot;proto3&quot;</span>;<br><span class="hljs-comment">// package名称经过compile之后成为生成类所在的namespace</span><br><span class="hljs-keyword">package</span> tutorial;<br><span class="hljs-keyword">import</span> <span class="hljs-string">&quot;google/protobuf/timestamp.proto&quot;</span>;<br><br><span class="hljs-comment">// 一个message生成一个类</span><br><span class="hljs-class"><span class="hljs-keyword">message</span> <span class="hljs-title">Person</span> </span>&#123;<br>  <span class="hljs-built_in">string</span> name = <span class="hljs-number">1</span>;<br>  <span class="hljs-built_in">int32</span> id = <span class="hljs-number">2</span>; <br>  <span class="hljs-built_in">string</span> email = <span class="hljs-number">3</span>;<br><br>  <span class="hljs-class"><span class="hljs-keyword">enum</span> <span class="hljs-title">PhoneType</span> </span>&#123;<br>    MOBILE = <span class="hljs-number">0</span>;<br>    HOME = <span class="hljs-number">1</span>;<br>    WORK = <span class="hljs-number">2</span>;<br>  &#125;<br><br>  <span class="hljs-class"><span class="hljs-keyword">message</span> <span class="hljs-title">PhoneNumber</span> </span>&#123;<br>    <span class="hljs-built_in">string</span> number = <span class="hljs-number">1</span>;<br>    PhoneType type = <span class="hljs-number">2</span>;<br>  &#125;<br><br>  <span class="hljs-comment">// message元素的四个组成部分, modifier type name = uniq_tag，modifier默认为optional</span><br>  <span class="hljs-keyword">repeated</span> PhoneNumber phones = <span class="hljs-number">4</span>;<br><br>  google.protobuf.Timestamp last_updated = <span class="hljs-number">5</span>;<br>&#125;<br><br><span class="hljs-class"><span class="hljs-keyword">message</span> <span class="hljs-title">AddressBook</span> </span>&#123;<br>  <span class="hljs-keyword">repeated</span> Person people = <span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="compile"><a href="#compile" class="headerlink" title="compile"></a>compile</h2><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-comment"># 编译.proto文件，生成类的头文件和源文件</span><br>protoc protoc --cpp_out=. <span class="hljs-keyword">addressbook.proto</span><br><span class="hljs-keyword"></span><br><span class="hljs-comment">#在应用中使用生成类</span><br>c++ -std=c++<span class="hljs-number">11</span> <span class="hljs-keyword">add_person.cc </span><span class="hljs-keyword">addressbook.pb.cc </span>-o <span class="hljs-keyword">add_person_cpp </span>`pkg-<span class="hljs-built_in">config</span> --cflags --libs protobuf`<br></code></pre></td></tr></table></figure><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><h3 id="序列化API"><a href="#序列化API" class="headerlink" title="序列化API"></a>序列化API</h3><ul><li><code>bool SerializeToString(string* output) const;</code></li><li><code>bool SerializeToOstream(ostream* output) const;</code><br>一个生成类的实例调用这两种方法，将会把自身的内容以二进制串的形式写入string或ostream中，如<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">fstream <span class="hljs-title">output</span><span class="hljs-params">(argv[<span class="hljs-number">1</span>], ios::out | ios::trunc | ios::binary)</span></span>;<br><span class="hljs-keyword">if</span> (!address_book.<span class="hljs-built_in">SerializeToOstream</span>(&amp;output)) &#123;<br>    cerr &lt;&lt; <span class="hljs-string">&quot;Failed to write address book.&quot;</span> &lt;&lt; endl;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>&#125;<br></code></pre></td></tr></table></figure></li></ul><h3 id="反序列化API"><a href="#反序列化API" class="headerlink" title="反序列化API"></a>反序列化API</h3><ul><li><code>bool ParseFromString(const string&amp; data);</code></li><li><code>bool ParseFromIstream(istream* input);</code><br>从一个istream或string读取一个二进制串，然后这个生成类的实例中的内容便得到了填充。如，<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs css">tutorial::AddressBook address_book;<br>fstream <span class="hljs-selector-tag">input</span>(argv<span class="hljs-selector-attr">[1]</span>, ios::in | ios::binary);<br>if (!address_book<span class="hljs-selector-class">.ParseFromIstream</span>(&amp;<span class="hljs-selector-tag">input</span>)) &#123;<br>    cerr &lt;&lt; &quot;Failed <span class="hljs-selector-tag">to</span> parse <span class="hljs-selector-tag">address</span> book.&quot; &lt;&lt; endl;<br>    return -<span class="hljs-number">1</span>;<br>&#125;<br>    &#125;<br></code></pre></td></tr></table></figure></li></ul><h3 id="元素获取与操作API"><a href="#元素获取与操作API" class="headerlink" title="元素获取与操作API"></a>元素获取与操作API</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// id</span><br><span class="hljs-function"><span class="hljs-keyword">inline</span> <span class="hljs-keyword">bool</span> <span class="hljs-title">has_id</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span></span>;<br><span class="hljs-function"><span class="hljs-keyword">inline</span> <span class="hljs-keyword">void</span> <span class="hljs-title">clear_id</span><span class="hljs-params">()</span></span>;<br><span class="hljs-function"><span class="hljs-keyword">inline</span> <span class="hljs-keyword">void</span> <span class="hljs-title">set_id</span><span class="hljs-params">(<span class="hljs-keyword">int32_t</span> value)</span></span>;<br></code></pre></td></tr></table></figure><h3 id="通用API"><a href="#通用API" class="headerlink" title="通用API"></a>通用API</h3><ul><li><code>bool IsInitialized() const;</code>: checks if all the required fields have been set.</li><li><code>void Clear();</code>: clears all the elements back to the empty state.</li><li><code>void CopyFrom(const Person&amp; from);</code>: overwrites the message with the given message’s values.</li></ul><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li><a href="https://developers.google.com/protocol-buffers/docs/cpptutorial">https://developers.google.com/protocol-buffers/docs/cpptutorial</a></li><li><a href="https://stackoverflow.com/questions/26826421/protocol-buffers-unique-numbered-tag-clarification">https://stackoverflow.com/questions/26826421/protocol-buffers-unique-numbered-tag-clarification</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>C/C++笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>protobuf</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>卡尔曼滤波概要</title>
    <link href="/2021/10/22/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E6%A6%82%E8%A6%81/"/>
    <url>/2021/10/22/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E6%A6%82%E8%A6%81/</url>
    
    <content type="html"><![CDATA[<h2 id="做啥用的"><a href="#做啥用的" class="headerlink" title="做啥用的"></a>做啥用的</h2><p>我们想知道<strong>一个系统</strong>在<strong>某个时刻</strong>的真实状态，手段往往有多种，比如最常见的两种：</p><ol><li>用合适的传感器测量出来；</li><li>根据上一时刻的状态用数学模型推算出来；</li></ol><p>那么，应该相信哪一种办法得到的值呢？</p><h2 id="怎么做的"><a href="#怎么做的" class="headerlink" title="怎么做的"></a>怎么做的</h2><p>先把上述概念实例化一下，对于一个小车，我们想知道它在当前时刻$t$距离障碍物的真实距离$x_t$。我们用两种办法：</p><ol><li>测距雷达测得的<strong>测量值</strong>$m_t$</li><li>根据<strong>上一时刻的车速</strong>$v_{t-1}$和<strong>上一时刻的最终估计值</strong>$p_{t-1}$得到的<strong>预测值</strong>$n_t$，即有<script type="math/tex; mode=display">n_t = p_{t-1}-v_{t-1}</script></li></ol><p>然后，想办法平衡$m_t$和$n_t$，得到本时刻的<strong>最终估计值</strong>$p_t$。卡尔曼的做法是，将所有变量都视作一个正态的概率分布，而不是一个简单的标量值。即有</p><ol><li>自变量$v_{t-1}$    -&gt;     $v_{t-1}(\mu _v,\sigma _v)$，数据来自于传感器，可以认为均值和方差已知。</li><li>自变量$m_{t}$    -&gt;     $m_{t}(\mu _m,\sigma _m)$，数据来自于传感器，可以认为均值和方差已知。</li><li>中间变量$n_{t}$    -&gt;     $n_{t}(\mu _n,\sigma _n)$</li><li>结果变量$p$    -&gt;     $p(\mu _p,\sigma _p)$</li></ol><p>然后，按照经典方式，分两步计算来得到$p_t$</p><h3 id="Step1-预测"><a href="#Step1-预测" class="headerlink" title="Step1 预测"></a>Step1 预测</h3><p>首先因为</p><script type="math/tex; mode=display">n_t = p_{t-1}-v_{t-1}</script><p>所以，可以得到$n_t$的均值和方差分别为</p><script type="math/tex; mode=display">\mu_t^n = \mu_{t-1}^p - \mu_{t-1}^v</script><script type="math/tex; mode=display">\sigma_t^n = \sigma_{t-1}^p + \sigma_{t-1}^v</script><h3 id="Step2-融合-更新-校正"><a href="#Step2-融合-更新-校正" class="headerlink" title="Step2 融合/更新/校正"></a>Step2 融合/更新/校正</h3><p>平衡$m_t$和$n_t$这两个概率分布的方式是概率的乘法，即有</p><script type="math/tex; mode=display">\mu_t^p = \frac{\mu_t^n \sigma_t^m + \mu_t^m \sigma_t^n }{\sigma_t^m + \sigma_t^n }</script><script type="math/tex; mode=display">\sigma_t^p = \frac{\sigma_t^m \sigma_t^n }{\sigma_t^m + \sigma_t^n }</script><p>由于正态分布在变量取均值是概率最大，所以$\mu_t^p$即为$t$时刻的最终估计值$p_t$。而$\sigma_t^p$则用于计算下时刻的最终估计值。</p><h2 id="代码实例"><a href="#代码实例" class="headerlink" title="代码实例"></a>代码实例</h2><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-built_in">import</span> numpy as np<br><span class="hljs-built_in">import</span> matplotlib.pyplot as plt<br><br><span class="hljs-attr">t</span> = np.linspace(<span class="hljs-number">1</span>, <span class="hljs-number">100</span>, <span class="hljs-number">100</span>)  <span class="hljs-comment"># 在1~100s内采样100次</span><br><span class="hljs-attr">a</span> = <span class="hljs-number">0.5</span>  <span class="hljs-comment"># 加速度值</span><br><span class="hljs-attr">position</span> = (a * t ** <span class="hljs-number">2</span>) / <span class="hljs-number">2</span><br><br><span class="hljs-attr">position_noise</span> = position + np.random.normal(<span class="hljs-number">0</span>, <span class="hljs-number">120</span>, <span class="hljs-attr">size=(t.shape[0]))</span>  <span class="hljs-comment"># 模拟生成GPS位置测量数据（带噪声）</span><br><br>plt.plot(t, position, <span class="hljs-attr">label=&#x27;truth</span> position&#x27;)<br>plt.plot(t, position_noise, <span class="hljs-attr">label=&#x27;only</span> use measured position&#x27;)<br><br><span class="hljs-comment"># ---------------卡尔曼滤波----------------</span><br><span class="hljs-comment"># 初始的估计导弹的位置就直接用GPS测量的位置</span><br><span class="hljs-attr">predicts</span> = [position_noise[<span class="hljs-number">0</span>]]<br><span class="hljs-attr">position_predict</span> = predicts[<span class="hljs-number">0</span>]<br><br><span class="hljs-attr">predict_var</span> = <span class="hljs-number">0</span><br><span class="hljs-attr">odo_var</span> = <span class="hljs-number">120</span> ** <span class="hljs-number">2</span>  <span class="hljs-comment"># 这是我们自己设定的位置测量仪器的方差，越大则测量值占比越低</span><br><span class="hljs-attr">v_std</span> = <span class="hljs-number">50</span>  <span class="hljs-comment"># 测量仪器的方差（这个方差在现实生活中是需要我们进行传感器标定才能算出来的，可搜Allan方差标定）</span><br>for i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, t.shape[<span class="hljs-number">0</span>]):<br>    <span class="hljs-attr">dv</span> = (position[i] - position[i - <span class="hljs-number">1</span>]) + np.random.normal(<span class="hljs-number">0</span>, <span class="hljs-number">50</span>)  <span class="hljs-comment"># 模拟从IMU读取出的速度</span><br>    <span class="hljs-attr">position_predict</span> = position_predict + dv  <span class="hljs-comment"># 利用上个时刻的位置和速度预测当前位置</span><br>    predict_var += v_std ** <span class="hljs-number">2</span>  <span class="hljs-comment"># 更新预测数据的方差</span><br>    <span class="hljs-comment"># 下面是Kalman滤波</span><br>    <span class="hljs-attr">position_predict</span> = position_predict * odo_var / (predict_var + odo_var) + position_noise[i] * predict_var / (<br>                predict_var + odo_var)<br>    <span class="hljs-attr">predict_var</span> = (predict_var * odo_var) / (predict_var + odo_var) ** <span class="hljs-number">2</span><br>    predicts.append(position_predict)<br><br>plt.plot(t, predicts, <span class="hljs-attr">label=&#x27;kalman</span> filtered position&#x27;)<br><br>plt.legend()<br>plt.show()<br></code></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/77327349">https://zhuanlan.zhihu.com/p/77327349</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>数据融合</category>
      
    </categories>
    
    
    <tags>
      
      <tag>卡尔曼滤波</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>困难样本与FocalLoss</title>
    <link href="/2021/10/13/%E5%9B%B0%E9%9A%BE%E6%A0%B7%E6%9C%AC%E4%B8%8EFocalLoss/"/>
    <url>/2021/10/13/%E5%9B%B0%E9%9A%BE%E6%A0%B7%E6%9C%AC%E4%B8%8EFocalLoss/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>one-stage的目标检测算法，一般都存在正负样本数量不均衡的问题。</p><p>回忆一下，正样本指的是，对于一个anchor(记作A)，为其寻找最佳GTbox，也就是与其IOU最大的GTbox(记作B)。然后，计算A和B的IOU，如果超过某个阈值，则认为A和B之间的匹配关系为一个正样本(也就是说正负描述的都是一个match)，并将B的label赋予A。否则，视作负样本，A的label为背景。而且由于负样本没有对应的GTbox，所以一般不参与定位损失的计算，是否参与分类损失则没有定论。</p><h2 id="困难样本"><a href="#困难样本" class="headerlink" title="困难样本"></a>困难样本</h2><p>之前提到的SSD缓解正负样本不平衡所使用的方法是，按照造成的损失大小对负样本排降序，然后取topK计入最终的损失。其中，K是正样本数量的3倍。</p><p>这是一种Hard Negative挖掘的方法。那么这里Hard的含义是什么呢？直观描述就是在分类损失的计算中，那些预测分数很高的logit，竟然不是GT one-hot向量hot的位置；或者那些预测很低的logit，竟然不是GT one-hot向量中不hot的位置。</p><div align=center><img title="" src="/img/article/hard_match.png" width="80%" height="80%" align=center></div><p><br>显然，困难样本无论是用交叉熵还是二值交叉熵计算时，都会产生更大损失，应该更充分地被纳入损失计算，这也是SSD上述做法的内在逻辑。</p><h2 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h2><p>Focal Loss则提出了一种更加系统化的解决方案，先看普通的二值交叉熵损失计算公式：</p><script type="math/tex; mode=display">L = -{\rm ln}\hat{p} \;\;\;\;\;\; {\rm if \;}p = 1</script><script type="math/tex; mode=display">L = -{\rm ln}(1-\hat{p}) \;\;\;\;\;\; {\rm if \;}p = 0</script><p>Focal Loss对其做了这样一种加工，变为</p><script type="math/tex; mode=display">L = \alpha(1-\hat{p})^\gamma \cdot -{\rm ln}\hat{p} \;\;\;\;\;\; {\rm if \;}p = 1</script><script type="math/tex; mode=display">L = (1-\alpha)\hat{p}^\gamma \cdot -{\rm ln}(1-\hat{p}) \;\;\;\;\;\; {\rm if \;}p = 0</script><p>也就是在每一项上乘以一个增益，进一步放大困难样本本来就比较大的损失，从而加速模型的收敛。</p><p>例如当GT值$p=1$时，显然预测值$\hat{p}$越小，这个match越困难。此时相应地，$(1-\hat{p})^\gamma$也越大，L被放大。当GT值$p=0$时则相反，预测值$\hat{p}$越大越困难，此时$\hat{p}^\gamma$也相应地越大，L被放大。</p><p>而$\alpha$则用于平衡这两种情况对损失贡献的权重。</p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>使用Focal Loss机制时要小心错误标注样本，因为这些错误标注的GT值会被Focal Loss机制当做困难样本，进一步放大其影响。</p>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>损失函数</tag>
      
      <tag>Focal Loss</tag>
      
      <tag>困难样本</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>定位误差常用的损失函数</title>
    <link href="/2021/10/12/%E5%AE%9A%E4%BD%8D%E8%AF%AF%E5%B7%AE%E5%B8%B8%E7%94%A8%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    <url>/2021/10/12/%E5%AE%9A%E4%BD%8D%E8%AF%AF%E5%B7%AE%E5%B8%B8%E7%94%A8%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在目标检测任务中，为了更好的量化定位损失，各路大神想了很多办法。从最开始的针对xywh的均方误差，到IOU损失，再到后续的GIOU损失、DIOU损失、CIOU损失，越来越复杂。其中均方误差比较简单，不再介绍。重点讲一下IOU系列。</p><div align=center><img title="" src="/img/article/iou.png" width="80%" height="80%" align=center></div><h2 id="IOU损失"><a href="#IOU损失" class="headerlink" title="IOU损失"></a>IOU损失</h2><p>这里牵涉到两个概念，“IOU”和“IOU损失”，对于前者，已经很熟悉了，不再赘述。而对于后者，则是简单地令</p><script type="math/tex; mode=display">IOU loss = - \ln(\frac{I}{U})</script><p>这样，IOU越接近于1，损失越接近于0。并且相比于均方误差没有尺度大小影响wh损失的现象。但美中不足的是，当I=0，即两个框不相交时无法正确计算。</p><h2 id="GeneralizedIOU损失"><a href="#GeneralizedIOU损失" class="headerlink" title="GeneralizedIOU损失"></a>GeneralizedIOU损失</h2><script type="math/tex; mode=display">GIOU = \frac{I}{U} - \frac{D_1 + D_2}{S}</script><script type="math/tex; mode=display">GIOU loss = 1 - GIOU</script><p>IOU越大，损失越小。D1和D2占S的比例越大，IOU越大。</p><h2 id="DistanceIOU损失"><a href="#DistanceIOU损失" class="headerlink" title="DistanceIOU损失"></a>DistanceIOU损失</h2><script type="math/tex; mode=display">DIOU = \frac{I}{U} - \frac{d^2}{c^2}</script><script type="math/tex; mode=display">DIOU loss = 1 - DIOU</script><p>IOU越大，损失越小。d越小，两个框的中心越接近，损失越小。</p><h2 id="CompleteIOU损失"><a href="#CompleteIOU损失" class="headerlink" title="CompleteIOU损失"></a>CompleteIOU损失</h2><p>作者说，一个好的定位误差量化指标应该兼顾：<strong>重叠面积</strong>、<strong>中心点距离</strong>、<strong>长宽比</strong>。前两者在DIOU中都已经考虑了，因此CIOU又增加了长宽比这一因素，也就是说两个框的形状哪怕不全等，也应该尽可能相似。</p><script type="math/tex; mode=display">CIOU = \frac{I}{U} - \frac{d^2}{c^2} - \alpha v</script><script type="math/tex; mode=display">v = \frac{4}{\pi ^2}({\rm arctan} \frac{w_1}{h_1} - {\rm arctan} \frac{w_2}{h_2})^2</script><script type="math/tex; mode=display">\alpha = \frac{v}{(1-IOU)+v}</script><script type="math/tex; mode=display">CIOU loss = 1 - CIOU</script><p>$\alpha v$暂时看不懂是啥原理，暂时知道是在比较两个框的相似程度就够了，而且越小越相似。</p>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>损失函数</tag>
      
      <tag>IOU</tag>
      
      <tag>GIOU</tag>
      
      <tag>DIOU</tag>
      
      <tag>CIOU</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于交叉熵的易混淆概念</title>
    <link href="/2021/10/12/%E5%85%B3%E4%BA%8E%E4%BA%A4%E5%8F%89%E7%86%B5%E7%9A%84%E6%98%93%E6%B7%B7%E6%B7%86%E6%A6%82%E5%BF%B5/"/>
    <url>/2021/10/12/%E5%85%B3%E4%BA%8E%E4%BA%A4%E5%8F%89%E7%86%B5%E7%9A%84%E6%98%93%E6%B7%B7%E6%B7%86%E6%A6%82%E5%BF%B5/</url>
    
    <content type="html"><![CDATA[<h2 id="0-前言"><a href="#0-前言" class="headerlink" title="0. 前言"></a>0. 前言</h2><p>交叉熵，二值交叉熵，softmax，sigmoid等概念经常一起出现，这里结合pytorch的具体实现来捋清楚这几个概念。</p><h2 id="1-概念"><a href="#1-概念" class="headerlink" title="1. 概念"></a>1. 概念</h2><h3 id="1-1-交叉熵"><a href="#1-1-交叉熵" class="headerlink" title="1.1 交叉熵"></a>1.1 交叉熵</h3><p>交叉熵用于描述两个概率分布的差异，也就是说处理的都是0-1之间的数值。</p><script type="math/tex; mode=display">H(p,q) = -\sum p(x)\log q(x)</script><p>在实际应用中，一般用于计算分类损失。并且，为了避免对0取对数，会将GT的one-hot向量作为$p$，预测结果作为$q$。</p><h3 id="1-2-二值交叉熵"><a href="#1-2-二值交叉熵" class="headerlink" title="1.2 二值交叉熵"></a>1.2 二值交叉熵</h3><p>二值交叉熵就是上述交叉熵公式在$x$只有两个取值时的特例。</p><script type="math/tex; mode=display">H(p,q) = -[p \log q + (1-p) \log (1-q)]</script><h3 id="1-3-sigmoid函数"><a href="#1-3-sigmoid函数" class="headerlink" title="1.3 sigmoid函数"></a>1.3 sigmoid函数</h3><p>一般模型直接输出的结果向量不保证其中的标量元素的数值（pytorch等官方术语称logits）在0-1之间，因此要用到sigmoid这种值域在0-1之间的激活函数将<strong>每一个logit单独</strong>作映射，然后再进行交叉熵计算。</p><div align=center><img title="" src="/img/article/sigmoid.png" width="50%" height="50%" align=center></div><h3 id="1-4-softmax函数"><a href="#1-4-softmax函数" class="headerlink" title="1.4 softmax函数"></a>1.4 softmax函数</h3><p>跟sigmoid一样，也是一个logit归一化的工具，但是需要所有logits一起做联合映射，而不是独立映射。</p><script type="math/tex; mode=display">\sigma (\boldsymbol{\rm x}) = \frac{\rm exp(\boldsymbol{x})} {\boldsymbol{1}^T \rm exp(\boldsymbol{x})}</script><h2 id="2-pytorch实现"><a href="#2-pytorch实现" class="headerlink" title="2. pytorch实现"></a>2. pytorch实现</h2><p>pytorch中的nn模块和nn.funtional模块中都有交叉熵损失的实现，这里只介绍nn下的3个模块。</p><h3 id="2-1-nn-CrossEntropyLoss"><a href="#2-1-nn-CrossEntropyLoss" class="headerlink" title="2.1 nn.CrossEntropyLoss"></a>2.1 <code>nn.CrossEntropyLoss</code></h3><p>主要的入参有input(N, C)和target(N,)两个，N是结果向量有几个，C是类别数量。</p><p>input的每一行都是一个结果向量，包含C个类别的各自的logit，这是因为这个模块内部集成了softmax函数，在进行损失计算之前会先对input做0-1的映射。</p><p>target每一行是一个真实标签序号，值在[0, C-1]之间。在进行算是计算之前会将target的每一行拓展成一个one-hot向量，hot的位置就是这个真实标签序号。</p><p>然后用1.1中的公式逐行计算这N个结果向量与N个one-hot向量的交叉熵，最后求和或求算数平均值（默认求均值）。</p><h3 id="2-2-nn-BCEWithLogitsLoss"><a href="#2-2-nn-BCEWithLogitsLoss" class="headerlink" title="2.2 nn.BCEWithLogitsLoss"></a>2.2 <code>nn.BCEWithLogitsLoss</code></h3><p>主要的入参还是input(N, C)和target(N, C)两个，但是target的形状不同，其每一行都直接是GT的one-hot向量。</p><p>也同样集成了sigmoid函数，计算损失之前会先对input做0-1的映射。</p><p>然后逐行选中一个C维的结果行向量和一个C维的GT one-hot行向量，按照1.2中的公式计算得到C个标量，求均值即可得到这一行的loss。</p><p>最后求各行的loss均值即可得到最终的loss。</p><h3 id="2-3-nn-BCELoss"><a href="#2-3-nn-BCELoss" class="headerlink" title="2.3 nn.BCELoss"></a>2.3 <code>nn.BCELoss</code></h3><p>未集成sigmoid的二值交叉熵计算模块，有要求入参input的标量元素值在0-1之间，所以一般不使用，直接使用2.2。</p><h2 id="3-附录"><a href="#3-附录" class="headerlink" title="3. 附录"></a>3. 附录</h2><div align=center><img title="" src="/img/article/cross_entropy.png" width="80%" height="80%" align=center></div><p><br></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs stylus">import torch<span class="hljs-selector-class">.nn</span> as nn<br>import torch<br><br>logits = torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[[2, -3, 0.8, 1.2]</span>, <span class="hljs-selector-attr">[1.5, -0.1, 0.9, -1.3]</span>])<br><br>sigmoid = torch<span class="hljs-selector-class">.sigmoid</span>(logits)<br>softmax = torch<span class="hljs-selector-class">.softmax</span>(logits, <span class="hljs-number">1</span>)<br><br>GT4bce = torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[[0, 0, 1, 0]</span>, <span class="hljs-selector-attr">[0, 1, 0, 0]</span>], dtype=torch.<span class="hljs-attribute">float</span>)<br>GT4ce = torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[2, 1]</span>)<br><br>ce = nn<span class="hljs-selector-class">.CrossEntropyLoss</span>(reduction=<span class="hljs-string">&#x27;sum&#x27;</span>)<br>ce_loss = ce(logits, GT4ce)<br><br>bce = nn<span class="hljs-selector-class">.BCEWithLogitsLoss</span>(reduction=<span class="hljs-string">&#x27;sum&#x27;</span>)<br>bce_loss = bce(logits, GT4bce)<br><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">&quot;CE loss is &#123;&#125; \nBCE loss is &#123;&#125;&quot;</span>.format(ce_loss, bce_loss)</span></span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
      <tag>交叉熵</tag>
      
      <tag>二值交叉熵</tag>
      
      <tag>损失函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>YOLO源码分析（零） —— 理论基础</title>
    <link href="/2021/09/27/YOLO%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-0/"/>
    <url>/2021/09/27/YOLO%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-0/</url>
    
    <content type="html"><![CDATA[<h2 id="0-前言"><a href="#0-前言" class="headerlink" title="0. 前言"></a>0. 前言</h2><p>One-Stage目标检测的另一代表，特点是GridCell的切分以及与之配套的GT框和anchor的匹配机制。</p><p>现在看下来YOLO的故事是，YOLOv1先定下基础，然后后面的版本用各种各样的trick改善v1的效果。因此，要首先搞清楚v1都干了些啥，然后再依次搞清楚后续各个补丁的含义。</p><p>而且由于YOLOv1的检测效果相对而言并不是很好，目前应用的至少是v3起步，所以对于v1和v2只在理论层面分析一下，源码的分析直接从v3开始。</p><h2 id="1-YOLOv1解析"><a href="#1-YOLOv1解析" class="headerlink" title="1. YOLOv1解析"></a>1. YOLOv1解析</h2><h3 id="1-1-模型结构"><a href="#1-1-模型结构" class="headerlink" title="1.1 模型结构"></a>1.1 模型结构</h3><div align=center><img title="" src="/img/article/yolov1.png" width="80%" height="80%" align=center></div><p>看上面这个模型结构图可知，第一代YOLO的特点就是“简单+粗暴”，从image输入到detection输出，全过程看起来就跟一个分类网络模型没有任何区别。只不过是将分类网络最终输出的21维列向量（以PascalVOC）扩充为下面这个30维列向量（以7x7切分cell，每个cell 2个final_box为例）：</p><div align=center><img title="" src="/img/article/yolo_output.png" width="100%" height="100%" align=center></div><p><br>这样的模型输出向量有7x7个，也就是模型结构图中最后的那个30x7x7的tensor，刚好对应原图7x7个cell。对其中的一个按深度方向的行向量而言，有</p><ul><li>20位作为每个类别的score</li><li>$(4+1)\times2 =10$位作为两个框的信息，4对应角点坐标，1对应YOLO独有的“框的置信度”，后面会详细展开。</li></ul><h3 id="1-2-损失函数"><a href="#1-2-损失函数" class="headerlink" title="1.2 损失函数"></a>1.2 损失函数</h3><p>个人感觉YOLOv1的一切秘密其实都藏在它的损失函数中，先看公式：</p><script type="math/tex; mode=display">L1 = \lambda_{coord} \sum_{i=0}^{S^2}\sum_{j=0}^{B} 1_{ij}^{obj} [(x_i-\hat{x}_i)^2+(y_i-\hat{y}_i)^2]</script><script type="math/tex; mode=display">L2 = \lambda_{coord} \sum_{i=0}^{S^2}\sum_{j=0}^{B} 1_{ij}^{obj} [(\sqrt{w_i}-\sqrt{\hat{w}_i})^2+(\sqrt{h_i}-\sqrt{\hat{h}_i})^2]</script><script type="math/tex; mode=display">L3 = \sum_{i=0}^{S^2}\sum_{j=0}^{B} 1_{ij}^{obj} (C_i-\hat{C}_i)^2</script><script type="math/tex; mode=display">L4 = \lambda_{noobj} \sum_{i=0}^{S^2}\sum_{j=0}^{B} 1_{ij}^{noobj} (C_i-\hat{C}_i)^2</script><script type="math/tex; mode=display">L5 = \sum_{i=0}^{S^2} 1_{i}^{obj} \sum_{i \in classes} (p_i(c)-\hat{p}_i(c))^2</script><script type="math/tex; mode=display">L = L_1 + L_2 + L_3 + L_4 + L_5</script><p>非老手的话一眼看过去是有点懵逼的，不过一项一项捋一下也不算难。</p><p>首先以L1为例，可以看出这一项是用来计算预测框的中心点坐标与GT框中心点坐标之间的偏离程度，不带帽的量是GT，戴帽的是预测。式中的均方根误差，不难理解。$\lambda<em>{coord}$是权重系数，也不难理解。唯一的难点在于如何理解$\sum</em>{i=0}^{S^2}\sum<em>{j=0}^{B} 1</em>{ij}^{obj}$？</p><p>第一个问题：从累加符号的上标可以看出i是在遍历这7x7个GridCell，j是在遍历一个GridCell中的B个预测框，这样用i和j去遍历所有预测框是一个很直观的事情。但是，如何确定一个预测值对应的GT值是哪个呢（换句话说，$x_i$是谁）？这是从图像分类任务进阶到目标检测任务所要面对的核心问题，FasterRCNN和SSD用的都是AssignGTbox2Anchor机制，而YOLO的答案不一样，其特点也正在于此。</p><p>YOLO的具体做法是，当遍历到第$i$个GridCell的第$j$个预测框时，一一查看所有的GT框，将中心坐标在当前GridCell中的挑选出来。此时有三种情况：</p><ul><li>所有GT框的中心点都不在当前GridCell内，那么pass，接着计算第$i+1$个GridCell。</li><li>刚好有1个GT框的中心点在当前GridCell内，那么这个GT框的参数就是我们在找的$x_i, y_i, w_i, h_i$。</li><li>有不止一个GT框的中心点在当前GridCell内，那么随机选取一个GT框。</li></ul><p>综上，对于L1而言，每一个GridCell最多只有一个GT值有效，这也是为什么$x_i$的下标只有i。那为什么预测量<script type="math/tex">\hat{x}_i</script>的下标也只有$i$没有$j$呢？因为对于一个GridCell，跟GT框一样，预测框也只选取一个去计算损失。但不是随机选取，而是选取这个B个预测框中$\hat{C}$值最大的那个。</p><p>L2同理，唯一不同的是多了根号。这是考虑IOU相等的两对GT框和预测框，一对尺寸很大，一对尺寸很小，那么此时因为IOU相同，应该认为两对的匹配程度是一样好的。但是，去计算L2损失时显然尺寸大的这一对预测框和GT框之间宽度和高度的差值更大，这是不合理的。因此YOLO的作者加了个根号用来缓解这一问题。</p><p>然后L3也类似，不过要说明下“框的置信度”的真值$C_i$从何而来。它是对于这一个GridCell被选中的一对GT框和预测框的IOU值。</p><p>L4跟L3完全一样，只不过计入损失的GridCell的选取规则刚好反过来，这里是没有目标才计入损失。</p><p>L5有点不一样，这里计算的是类别损失，所以不再遍历B个预测框。真实值$p_i$是一个one-hot向量，预测值$\hat{p}_i$就是那个20位的score向量。</p><blockquote><p>个人感觉何必那么麻烦，直接先说好，对于一个30维的预测结果，只有confidence最大的那个框有效，其他框权当做没有不就完了。</p></blockquote><h3 id="1-3-一点体会"><a href="#1-3-一点体会" class="headerlink" title="1.3 一点体会"></a>1.3 一点体会</h3><p>这三种主流目标检测模型基本流程其实都可以总结为：</p><p><strong>在输入图像上选取一个区域，将这个区域的图像数据扔到一个CNN网络中加工出来一个detection结构，然后将这个detection结构解释为预测框的信息</strong>。</p><p>对于第一点，选取子图：</p><ul><li>FasterRCNN比较讲究，专门搞一个RPN模型去确定应该截取哪些区域，可以说是“一图一策”；</li><li>YOLOv1粗暴一点，直接将原图切成7x7份，然后将每一个子图扔到CNN中加工，然后借用<a href="https://guohongming.xyz/2021/07/15/CNN%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/">滑动窗口的卷积实现原理</a>直接将整张图扔进去，同时得到49个子图产生的detection结构。</li><li>SSD和YOLOv1一样，在原图上划分8732个子区域，然后利用<a href="https://guohongming.xyz/2021/07/15/CNN%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/">滑动窗口的卷积实现原理</a>得到8732个子图产生的detection结构。</li></ul><p>然后关键来了，那就是三种算法中一份子图产生的detection结构是怎样的？</p><ul><li>YOLOv1的上面已经画出来了，是一个30维的向量，是最简单的一个，但这也意味着这部分子图上的原始数据最终只产生了一个预测框。mark，YOLO针对一个detection结构生成20个还是1个框有待确认</li><li>SSD的在<a href="https://guohongming.xyz/2021/09/23/SSD%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-0/">之前</a>也画出来过，是1个4维的box_reg向量和1个21维的objectness向量。这意味着原图上一个anchor圈住的原始数据最终产生了1个框，然后这个框可以被21个类别复用，所以还是相当于21个框。另外，SSD的这么多anchor之间有很严重的范围相互覆盖，这意味着对于300x300原图上的某一个小区域来讲，其实是被重复利用了很多次。而YOLO各个子图之间是没有交集的，所以原始数据利用率就差一些。</li><li>FasterRCNN的最复杂，是1个84维的box_reg向量和1个21维的objectness向量，也就是产生21个位置不同的框。也就是说用一个proposal内的原始数据产生了21个预测框，数据利用率相对而言是最高的。</li></ul><h2 id="2-YOLOv2解析"><a href="#2-YOLOv2解析" class="headerlink" title="2. YOLOv2解析"></a>2. YOLOv2解析</h2><p>YOLOv2是在v1的基础上打补丁，一个一个地理解下这些补丁即可。</p><h3 id="2-1-模型结构升级"><a href="#2-1-模型结构升级" class="headerlink" title="2.1 模型结构升级"></a>2.1 模型结构升级</h3><p>最显著的升级当然是模型的结构，包括更换backbone，增加BN层，多尺度融合等。</p><p>首先，v2的backbone由v1中一个GoogleNet的简化版，改变为Darknet系列，这里以Darknet19为例。</p><div align=center><img title="" src="/img/article/yolov2.png" width="50%" height="50%" align=center></div><p>上图为Darknet19作为分类网络时的完整结构。作为目标检测网络则去掉上图最下方分界线下面的部分，然后增加亿点点细节，得到：</p><div align=center><img title="" src="/img/article/yolov2_model.png" width="100%" height="100%" align=center></div><h3 id="2-2-增加anchor"><a href="#2-2-增加anchor" class="headerlink" title="2.2 增加anchor"></a>2.2 增加anchor</h3><p>鉴于v1表现不佳的现象主要集中于定位误差，因此v2也不得不采用了anchor概念。而且其对于anchor的用法也有一些特色，需要注意有：</p><ol><li>每个GridCell分配5个不同尺寸和比例的anchor，中心点都设定在GridCell左上角，就是说现在的一个GridCell的原始数据现在可以产生5个结果向量。</li><li>5个anchor的尺寸和比例通过K-means方法对训练集中的GT框尺寸进行聚类得到。</li><li>结果向量中的xywh现在自然也成了参数，需要联合anchor坐标进行decode才能得到预测框的位置。而且其decode公式也有点意思，具体如下：<script type="math/tex; mode=display">b_x = \sigma(t_x) + A_x</script><script type="math/tex; mode=display">b_y = \sigma(t_y) + A_y</script><script type="math/tex; mode=display">b_w = A_w e^{t_w}</script><script type="math/tex; mode=display">b_h = A_h e^{t_h}</script><script type="math/tex; mode=display">\hat{C} = \sigma(t_o)</script>其中，$b$为最终检测框的位置参数，$\hat{C}$为检测框的置信度，$t$为结果向量中的元素，$A$为anchor的位置参数。$\sigma$为sigmoid函数，用来将预测框的最终位置限制在自己的GridCell内。</li></ol><h3 id="2-3-其他改进项"><a href="#2-3-其他改进项" class="headerlink" title="2.3 其他改进项"></a>2.3 其他改进项</h3><ol><li>训练分类器网络时采用448x448的高分辨率数据，以往都是采用224x224；</li><li>训练目标检测网络时，每10个batch就在{320, 352, … , 608}的范围内随机选取一个尺寸对原始数据进行缩放，然后输入到网络中；</li></ol><div align=center><img title="" src="/img/article/yolov2_perf.png" width="70%" height="70%" align=center></div><h2 id="3-YOLOv3解析"><a href="#3-YOLOv3解析" class="headerlink" title="3. YOLOv3解析"></a>3. YOLOv3解析</h2><p>YOLOv3继续打补丁，不过这次不仅更换了网络结构，连损失函数也变了。另外，预测框与GT框的匹配办法也升级了，不过这个工作应该在v2就已经做了，只不过v2的原论文没有提及，真要想搞清楚v2预测框与GT框的匹配方式，还是要阅读v2的源码，不过感觉没必要。</p><p>所以v3的升级也分为模型升级，匹配方式，损失函数等3个方面来说明：</p><h3 id="3-1-模型结构升级"><a href="#3-1-模型结构升级" class="headerlink" title="3.1 模型结构升级"></a>3.1 模型结构升级</h3><p>backone引入了ResNet中的残差结构，形成Darknet53，具体结构如下表所示，</p><div align=center><img title="" src="/img/article/yolov3_backbone.png" width="90%" height="90%" align=center></div><p>然后增加FPN等亿点点细节，得到目标检测网络：</p><blockquote><p>output3对应32x32的GridCell切分方式，用于检测小目标；output1对应8x8的切分方式，用于检测大目标。</p></blockquote><div align=center><img title="" src="/img/article/yolov3_arch.png" width="100%" height="100%" align=center></div><h3 id="3-2-损失函数与GT-amp-预测匹配方式"><a href="#3-2-损失函数与GT-amp-预测匹配方式" class="headerlink" title="3.2 损失函数与GT&amp;预测匹配方式"></a>3.2 损失函数与GT&amp;预测匹配方式</h3><p>要计算损失函数，首先要解决GT信息与预测信息的匹配问题。YOLOv1的匹配方式上文已经说明了，YOLOv2的匹配方式原论文中没有明讲，但鉴于v2中一个GridCell已经预测不止一个结果向量，所以可以推断v2和v3一样，已经做了匹配方式的升级。具体是怎么做的呢？</p><p>其实还是借鉴了FasterRCNN和SSD等主流目标检测模型的做法，在一个GridCell内计算所有anchor框（而不是decode之后的预测框哦）和GT框的IOU混淆矩阵，然后利用这个混淆矩阵为每一个GTbox分配一个anchor。这一点跟FasterRCNN和SSD是不同的，虽然匹配的标准都是取最大IOU，但这两者都是AssignGTbox2Anchor，而这里是AssignAnchor2GTbox。</p><p>进一步地，如果一个anchor对于任意一个GTbox都没能取得最大IOU，那么此时根据这个anchor所能取得的最大IOU分两种情况：</p><ol><li>所能取得的最大IOU小于0.5，那么这个anchor的结果向量不参与定位误差和分类误差的计算，但是参与“框的置信度”误差计算。</li><li>如果大于0.5，那么这个anchor的结果向量不参与任何误差的计算。</li></ol><p>确立了匹配规则之后，即可开始计算损失。YOLOv3的损失和v1相比也略有不同，总体还是分为三部分：定位损失（对应上文的L1+L2），置信度损失(对应上文的L3+L4)，分类损失(对应上文的L5)。</p><h4 id="3-2-1-定位损失"><a href="#3-2-1-定位损失" class="headerlink" title="3.2.1 定位损失"></a>3.2.1 定位损失</h4><p>定位损失无非xywh四项，只不过由于v3中引入了取消了wh的根号，全部采用平方误差和的形式。</p><script type="math/tex; mode=display">L_1 = \frac{1}{N_p} \sum^{N_p} \sum_{m \in \{x,y,w,h \}} (P_m - G_m)^2</script><p>其中，</p><script type="math/tex; mode=display">P_x = \sigma(t_x)</script><script type="math/tex; mode=display">G_x = g_x - A_x</script><p>也就是说中心点坐标的误差计算，并没有对GT框的xy信息完全decode，这是因为计算sigmoid的反函数有点麻烦，并且没有必要。</p><p>wh项的比对则是按照上述YOLO的encode公式对GT框的wh信息进行完全decode，然后对比decode之后的box_reg参数。即，</p><script type="math/tex; mode=display">P_w = t_w</script><script type="math/tex; mode=display">G_w = \ln(\frac{g_w}{A_w})</script><p>这样，遍历每一对GT框和anchor框求得平方误差和，最后求算数平均值即可。</p><h4 id="3-2-2-置信度损失"><a href="#3-2-2-置信度损失" class="headerlink" title="3.2.2 置信度损失"></a>3.2.2 置信度损失</h4><p>v3置信度损失的计算方法由均方差调整为了交叉熵，并且有一些细节需要额外注意。</p><script type="math/tex; mode=display">L_2 = \frac{1}{N} \sum^{N} -[C\ln(\hat C) + (1-C)\ln(1 - \hat C)]</script><p>可以看到这里并不只统计正样本的置信度误差(跟v1一样，v1中也是有L3和L4两部分)，这是因为按照本小节开头所描述的匹配规则，没有匹配到GTbox并且没有被丢弃的anchor的结果向量也要参与置信度损失计算。</p><p>那么问题来了，这个时候都没有配对成功，GT信息从何而来呢？原论文中的做法是令此时的GT置信度$C$为0，并且顺带着把配对成功的GT的置信度设定为1，不再计算预测框和GT框的IOU了。</p><p>也就是说对于一个未被丢弃的anchor，当它匹配上GT时，它产生的损失是$-\ln(\sigma(t_o))$，这样预测置信度越小，损失越大，这是我们希望看到的，因为此时你都匹配上GT框了，置信度还这么低是不对的。</p><p>相反，当一个未被丢弃的anchor没有匹配上GT时，它产生的损失是$-\ln(1-\sigma(t_o))$，这样预测置信度越小，损失也越小，这也是我们希望看到的，因为此时这个框的预测很失败，我们当然希望它的置信度相应地很小。</p><blockquote><p>也有很多YOLOv3的实现不是简单将GT置信度设置为0和1，而是一如既往的求IOU，<a href="https://stats.stackexchange.com/questions/373266/yolo-v3-loss-function">据说</a>也是有效的。</p></blockquote><h4 id="3-2-3-分类损失"><a href="#3-2-3-分类损失" class="headerlink" title="3.2.3 分类损失"></a>3.2.3 分类损失</h4><p>v3的分类损失同样由均方差调整为了交叉熵，而且是二值交叉熵：</p><script type="math/tex; mode=display">L_3 = \frac{1}{N_p} \sum^{N_p} \sum_i^{Class_num} -[p_i \ln \hat{p}_i + (1-p_i) \ln (1-\hat{p}_i)]</script><p>其中，$p$是GT值，是一个one-hot向量。$\hat{p}$是结果向量中的那20位类别分数经过sigmoid之后的值。</p>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
      <category>目标检测</category>
      
      <category>YOLO</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>神经网络</tag>
      
      <tag>卷积神经网络</tag>
      
      <tag>CNN</tag>
      
      <tag>目标检测</tag>
      
      <tag>YOLO</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SSD源码分析 —— 整体框架</title>
    <link href="/2021/09/23/SSD%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-0/"/>
    <url>/2021/09/23/SSD%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-0/</url>
    
    <content type="html"><![CDATA[<h2 id="0-前言"><a href="#0-前言" class="headerlink" title="0. 前言"></a>0. 前言</h2><p>最近忙着搞超声波，SSD的源码分析拖得有点久了。不过鉴于SSD的模型结构比较简单，而且较为复杂的gtbox匹配、损失计算等机制在Faster RCNN业已理解，所以前后也没用多长时间。</p><p>首先，还是算法的总体流程图，可以看出比Faster RCNN那是简单太多了。</p><div align=center><img title="" src="/img/article/ssd_overview.png" width="90%" height="90%" align=center></div><p><br>第一步还是从dataset中加载图像，然后经过图像预处理，再通过以ResNet50为蓝本的feature extractor处理，结果再送到5个additional layer中，最终连同feature extractor的输出合计得到6个feature map，每个feature map再各自通过一个predictor进而得到预测结果(box_reg和objectness)。</p><p>其中box_reg为相对于anchor的边界框回归参数，objectness经过softmax之后就是对应类别的置信度。如果是训练模式，就用这两个信息去求模型损失；如果是预测模式则对所有的边界框进行筛选得到最终的预测结果。</p><p>其中anchor还是老样子，从6个feature map每一个的HW cell上面长出来2-3个，不同feature map上anchor的scale和ratio都不同，以达到金字塔的效果。</p><h2 id="1-从dataset加载图像"><a href="#1-从dataset加载图像" class="headerlink" title="1. 从dataset加载图像"></a>1. 从dataset加载图像</h2><p>首先要从把标注好的图像文件以及标注xml文件读取进来，经过一系列图像预处理操作转化为tensor格式，大致流程跟<a href="https://guohongming.xyz/2021/09/01/Faster-RCNN%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-0/">之前</a>Faster RCNN差不多。</p><p>但是，FasterRCNN的图像预处理有两次：</p><ul><li>第一次是在创建dataset类实例的时候，就是说从dataset类<code>__getitem__</code>方法返回的图像数据先经过了一次transform。这一次主要是to_tensor和随机水平翻转（预测模式无）。</li><li>然后在送入模型之前又通过单独的GeneralizedRCNNTransform类，再transform一次。这一次的细节看<a href="https://guohongming.xyz/2021/08/15/Faster-RCNN%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-1/">这里</a></li></ul><p>回到SSD，预处理只有一次，全部集中在dataset类中实现，而且花样比较多(加*项为训练模式独有)：</p><h3 id="1-1-SSDcrop"><a href="#1-1-SSDcrop" class="headerlink" title="1.1 SSDcrop*"></a>1.1 SSDcrop*</h3><p>顾名思义，这是SSD的特点之一。目的是为了在一张原始图片上截取一个子区域作为模型的输入，而不是整图送进去。而且很明显，不是在原图上随便截就可以，截出来的子区域要符合一定条件：</p><ol><li>HW比例不能太夸张，要在1:2以内；</li><li>跟所有GTbox的IOU都要在一个合理范围内，这个合理范围在[0.1, inf], [0.3, inf], [0.5, inf], [0.7, inf], [0.9, inf], [-inf, inf]中随机选取。</li><li>至少有一个GTbox的中心点在这个子区域内。</li></ol><p>得到一个满足全部3个条件的子区域后，进行下一步。这意味着，对于一个epoch，这张图片只有一个子区域得到了有效使用，而且下一个epoch对于这张图片很有可能又换了一个子区域。</p><p><strong>相同，又不完全相同；重复，又不完全重复。艺术啊！</strong></p><p><strong>本阶段数据转化结果:</strong></p><ul><li><strong>image</strong>: jpg(375x500) -&gt; jpg(252x438)<blockquote><p>这一步的目的目测是为了扩充训练集的样本数量，但是这样不保持原图比例的裁剪然后再缩放，相比于预测时只是缩放不裁剪，真的可以吗？而且预测时这种不考虑原图HW大小和比例，直接硬缩放为300x300，直觉上也感觉不太对。mark</p></blockquote></li></ul><h3 id="1-2-Resize"><a href="#1-2-Resize" class="headerlink" title="1.2 Resize"></a>1.2 Resize</h3><p>简单粗暴调用官方库<code>torchvision.transforms.Resize()</code>，利用双线性插值原理将裁剪后的图像/原始图像，缩放到300x300。</p><p><strong>本阶段数据转化结果:</strong></p><ul><li><strong>image</strong>: jpg(252x438) -&gt; jpg(300x300)<blockquote><p>SSD使用了一个简单而高效的机制来处理图像缩放过程中的GTbox坐标变化，就是将GTbox的坐标以图像比例坐标的方式存储，这样不管图像缩放多少，用这个比例坐标乘以新的尺寸即可得到正确的GTbox坐标。</p></blockquote></li></ul><h3 id="1-3-ColorJitter"><a href="#1-3-ColorJitter" class="headerlink" title="1.3 ColorJitter*"></a>1.3 ColorJitter*</h3><p>调用官方库<code>torchvision.transforms.ColorJitter()</code>，在HSV空间将图像数据随机抖动一下。</p><p><strong>本阶段数据转化结果:略</strong></p><h3 id="1-4-ToTensor"><a href="#1-4-ToTensor" class="headerlink" title="1.4 ToTensor"></a>1.4 ToTensor</h3><p>PIL image格式转成tensor，换言之，之前的操作都是以PIL image格式进行的。</p><p><strong>本阶段数据转化结果:</strong></p><ul><li><strong>image</strong>: jpg(300x300) -&gt; tensor(3x300x300)</li></ul><h3 id="1-5-RandomHorizontalFlip"><a href="#1-5-RandomHorizontalFlip" class="headerlink" title="1.5 RandomHorizontalFlip*"></a>1.5 RandomHorizontalFlip*</h3><p>随机水平翻转，不解释了。</p><p><strong>本阶段数据转化结果:略</strong></p><h3 id="1-6-Normalization"><a href="#1-6-Normalization" class="headerlink" title="1.6 Normalization"></a>1.6 Normalization</h3><p>数据归一化，三通道的均值和方差还是取自ImageNet，<code>mean = [0.485, 0.456, 0.406]</code>，<code>std = [0.229, 0.224, 0.225]</code>。</p><p><strong>本阶段数据转化结果:略</strong></p><h3 id="1-7-AssignGTbox2Anchor"><a href="#1-7-AssignGTbox2Anchor" class="headerlink" title="1.7 AssignGTbox2Anchor*"></a>1.7 AssignGTbox2Anchor*</h3><p>又来了，Anchor与GTbox匹配的概念并不新奇，但这个实现方式却是SSD的鲜明特点。</p><p>为什么？因为在SSD的One-Stage理念下，不存在proposal概念，或者说anchor就是最终的proposal，而这个proposal又是预先按照既定参数生成的，不是来源于图像数据本身的。也就是说，对于SSD而言从一开始就知道proposal框的坐标，因此在预处理的时候就把Anchor与GTbox的匹配给做了。</p><p>这一步实际产生的效果是，按照anchor的排列顺序产生与之匹配的GTbox的序列以及label的序列，用以替换target中来自xml文件中的box和label信息。这样在后面计算损失时用到GT信息时，可以直接decode target中的box得到GT_box_reg，然后直接与预测的box_reg进行smooth L1损失计算。</p><p><strong>本阶段数据转化结果:</strong></p><ul><li><p><strong>image</strong>: 无变化</p></li><li><p><strong>GTbox</strong>: tensor(1x4) -&gt; tensor(8732x4)</p></li></ul><h2 id="2-FeatureExtractor"><a href="#2-FeatureExtractor" class="headerlink" title="2. FeatureExtractor"></a>2. FeatureExtractor</h2><p>其实还是一个Backbone的概念，目的是为了从原始图像中提取出Feature map。这里还是以<a href="https://guohongming.xyz/2021/08/08/ResNet/">ResNet50</a>为例，取其第一个卷积层conv1以及后续的3组Residual结构作为Backbone。</p><p>其中值得注意的是，第3组Residual结构conv4_x不是照搬过来的，而是将其这一组的6个Residual结构中的第一个的步距由2调整为1。原理这一个Residual结构因为身处组内第一的位置，因此要承担调整HW尺寸不断折半的任务，但是这里调整了stride，不用折半了。</p><div align=center><img title="" src="/img/article/resnet50_ssd.png" width="80%" height="80%" align=center></div><p><br><strong>本阶段数据转化结果:</strong></p><ul><li><strong>image</strong>: tensor(3x300x300) -&gt; tensor(64x150x150) -&gt; tensor(256x75x75) -&gt; tensor(512x38x38) -&gt; tensor(1024x38x38)</li></ul><blockquote><p>如果不调整conv4_x，那么最后一个tensor应该是1024x38x38x19</p></blockquote><h2 id="3-AdditionalLayer"><a href="#3-AdditionalLayer" class="headerlink" title="3. AdditionalLayer"></a>3. AdditionalLayer</h2><p>为了在不同尺度上得到更加准确的预测结果，这里又额外构造了5个AdditionalLayer结构，在Backbone输出的基础上继续进行卷积运算。</p><p>每一个AdditionalLayer结构都是由两个串联的ConvBNRelu单元组成，不断的缩小feature map的HW尺寸，以使得越往后的HW cell对应更大的原图感受野。</p><div align=center><img title="" src="/img/article/ssd_additional.png" width="100%" height="100%" align=center></div><p><br><strong>本阶段数据转化结果: 详见上图</strong></p><h2 id="4-AnchorGenerator"><a href="#4-AnchorGenerator" class="headerlink" title="4. AnchorGenerator"></a>4. AnchorGenerator</h2><p>未在总流程图体现的一点是AnchorGenerator，因为anchor是基于规则生成的。老样子，还是为每一个feature map上的每一个HW cell生成一套anchor，并且总体上还是遵循在不同的feature map上生成不同scale的anchor。但是相比于用了FPN的Faster RCNN，SSD的AnchorGenerator的规则有一些自己的特点。</p><div align=center><img title="" src="/img/article/ssd_anchor.png" width="80%" height="80%" align=center></div><p><br>按照上表的规则生成的这些anchor都直接用在300x300图像上的比例坐标表示，而不是向FasterRCNN一样，用相对于某个中心点的相对坐标。</p><p><strong>本阶段数据转化结果</strong></p><ul><li><strong>anchor参数</strong> -&gt; <strong>anchor</strong> : tensor(8732x4)</li></ul><h2 id="5-Predictor"><a href="#5-Predictor" class="headerlink" title="5. Predictor"></a>5. Predictor</h2><p>得到6个feature map之后，将其分别送入一个Predictor。每个Predictor包含两个卷积结构，一个用来生成objectness，一个用来生成box_reg。具体的结构也比较简单：<br><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs lisp"># box_extractor<br>ModuleList(<br>  (<span class="hljs-number">0</span>): Conv2d(<span class="hljs-number">1024</span>, <span class="hljs-number">16</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>  (<span class="hljs-number">1</span>): Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">24</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>  (<span class="hljs-number">2</span>): Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">24</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>  (<span class="hljs-number">3</span>): Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">24</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>  (<span class="hljs-number">4</span>): Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">16</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>  (<span class="hljs-number">5</span>): Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">16</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>)<br><br># objectness_extractor<br>ModuleList(<br>  (<span class="hljs-number">0</span>): Conv2d(<span class="hljs-number">1024</span>, <span class="hljs-number">84</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>  (<span class="hljs-number">1</span>): Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">126</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>  (<span class="hljs-number">2</span>): Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">126</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>  (<span class="hljs-number">3</span>): Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">126</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>  (<span class="hljs-number">4</span>): Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">84</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>  (<span class="hljs-number">5</span>): Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">84</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>)<br></code></pre></td></tr></table></figure></p><p>可以看到，3x3的卷积，SAME PADDING，1 STRIDE，就是不改变卷积前后的HW尺寸，只调整深度：</p><ul><li>对于box_extractor，深度调整为4 x anchor_num；</li><li>对于objectness_extractor，深度调整为21 x anchor_num。</li></ul><p>例如，1024x38x38的feature map在经过box_extractor处理之后，得到一个16x38x38的tensor。16的来由是这一层feature map上的每个cell生成4个anchor，而每个anchor有4个坐标值。就是说，1个HW cell的每4个通道组成一组完整的box_reg参数。然后再将这个16x38x38的tensor reshape成5776x4，即可得到第一个feature map生成的5776组box_reg参数，同理可以得到其余的box_reg参数，最后拼成一个8732x4的box_reg。</p><p>类似地，1024x38x38的feature map在经过objectness_extractor处理之后，得到一个84x38x38的tensor，将其reshape为5774x21然后再去拼接,最终得到8732x21的objectness。</p><blockquote><p>这里出现了取消proposal的另外一个优势，因为没有了proposal，所以300x300的图像上所有数据或者说一个feature map上的所有数据，都会被拿来使用，所以不存在需要使用ROIalign的场景。</p></blockquote><p>然后，来回忆一下FasterRCNN中的detection概念。由于未做过滤和采样，因此8732个anchor全部参与后续计算，这意味这最终将产生8732个detection。而且因为box_extractor的结构跟FasterRCNN不同，SSD每个detection的结构跟FasterRCNN也略有不同，SSD的一个detection只有1组box_reg参数，而FasterRCNN是21组，也就是每个类一组。</p><p>FasterRCNN的detection结构如下：</p><div align=center><img title="" src="/img/article/faster-rcnn-0-0.png" width="90%" height="90%" align=center></div><p><br>SSD的detection结构如下：</p><div align=center><img title="" src="/img/article/ssd_preditor.png" width="90%" height="90%" align=center></div><p><br><strong>本阶段数据转化结果</strong></p><ul><li><strong>feature map1</strong>: tensor(1024x38x38) -&gt; <strong>objectness1</strong>: tensor(84x38x38) + <strong>box_reg1</strong>: tensor(16x38x38) -&gt; <strong>objectness1</strong>: tensor(5776x21) +<strong>box_reg1</strong>: tensor(5776x4)</li><li><strong>objectness1</strong> + … + <strong>objectness6</strong> -&gt; <strong>objectness</strong>: tensor(8732x21)</li><li><strong>box_reg1</strong> + … + <strong>box_reg6</strong> -&gt; <strong>box_reg</strong>: tensor(8732x4)</li></ul><h2 id="6A-预测结果后处理"><a href="#6A-预测结果后处理" class="headerlink" title="6A. 预测结果后处理"></a>6A. 预测结果后处理</h2><p>上一步完成后，实质意义上的模型预测就已经完成了。如果是在预测模式下工作，接下来需要将objectness和box_reg解释到缩放前的原始图像上。</p><h3 id="6A-1-FilterDetection"><a href="#6A-1-FilterDetection" class="headerlink" title="6A.1 FilterDetection"></a>6A.1 FilterDetection</h3><p>对于每一张图像，具体工作如下：</p><ol><li>对class_logits做softmax，得到每一个box的score；</li><li>对box_reg和anchor角点坐标做decode，得到每一个final_box的角点坐标；</li><li>low score过滤；</li><li>low WH过滤；</li><li>针对每一个类别做nms，并且取nms之后的前100个box；</li></ol><p><strong>本阶段数据转化结果</strong></p><ul><li><strong>box_reg</strong>: tensor(8732x4) + <strong>anchor</strong>: tensor(8732x4) -&gt; <strong>final_boxes</strong>: tensor(100x4)</li><li><strong>objectness</strong>: tensor(8732x21) -&gt; <strong>final_scores</strong>: tensor(100x1)</li><li><strong>box_label</strong>: tensor(8732x21) -&gt; <strong>final_labels</strong>: tensor(100x1)</li></ul><blockquote><p>和FasterRCNN相同，这里的BoxLabel由规则生成，final_labels指的是预测信息，根据上图中box在一个detection的box序列中的相对位置确定。这就跟以往的经验不同了，这里并没有对一个detection所有框的score取最大值，然后将21个类别退化为1，而是将detection的每一列也就是每一个预测框作为一个单独的个体。就是说最终的100个预测框中完全有可能同时存在两个产生自同一个detection。</p></blockquote><h3 id="6A-2-PostTransform"><a href="#6A-2-PostTransform" class="headerlink" title="6A.2 PostTransform"></a>6A.2 PostTransform</h3><p>将detection三要素中的box坐标根据原图缩放前和缩放后的比例进行等比例缩放即可。</p><h2 id="6B-SSD损失计算"><a href="#6B-SSD损失计算" class="headerlink" title="6B. SSD损失计算"></a>6B. SSD损失计算</h2><p>当在训练模式下工作时，需要进行SSD损失计算。与FasterRCNN损失类似，SSD损失同样分为两部分，坐标损失和分类损失。首先捋一下两部分各自的真实信息和预测信息是什么：</p><ol><li>坐标回归参数的预测信息，Predictor输出的box_reg；</li><li>坐标回归参数的真实信息GT_regs，用anchor和与之匹配的GTbox进行encode得到；</li><li>预测框类别的预测信息，Predictor输出的objectness；</li><li>预测框类别的真实信息GT_labels，先将anchor和GTbox进行匹配，然后用匹配之后的IOU值的大小来判定proposal是否值得拥有与之匹配的GTbox的label，若值得(IOU&gt;0.5)则anchor的真实label就是GTbox的label，否则为0；</li></ol><p>捋清楚了上述信息之后，即可将对应数据代入到FasterRCNN的损失函数中进行计算，得到SSD的最终损失。</p><p>另外，具体还有一些细节需要注意：</p><ul><li>定位损失和分类损失SSD取1:1。</li><li>定位损失只统计真实标签不为0的anchor，或者说基于这个anchor产生的GT_reg和box_reg，即所谓正样本。</li><li>分类损失统计全部的正样本，然后再选取3倍的负样本。并且负样本不是像FasterRCNN那样随机选取，而是选取负样本中损失最大的那些。例如这一个batch有10个正样本，那么就应该选取交叉熵损失最大的30个负样本。而且负样本的数量不应超过8732。据原论文称可以这样做可以加速收敛。</li></ul><p><strong>本阶段数据转化结果</strong></p><ul><li><strong>box_label</strong>: tensor(8732x21) + <strong>GT_labels</strong>: tensor(8732x21) -&gt; $L_{cls}$</li><li><strong>box_reg</strong>: tensor(8732x4) + <strong>GT_regs</strong>: tensor(8732x4) -&gt; $L_{box}$</li></ul><blockquote><p>同样跟FasterRCNN一样，可以看到真实信息和预测信息之间差了一个classnum的维度，在计算$L_{cls}$时不要紧，因为交叉熵计算用到的GT_label是one-hot的形式，pytorch的实现机制自己会进行合理的计算。</p><p>在计算$L_{box}$时，要增加一个classnum上的索引将其退化为1，从而与GT_regs保持一致。索引的来源是GT_label的one-hot向量中1的位置，所以也就是说将GT_reg拓展为four-hot即可。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
      <category>目标检测</category>
      
      <category>SSD</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>神经网络</tag>
      
      <tag>卷积神经网络</tag>
      
      <tag>CNN</tag>
      
      <tag>目标检测</tag>
      
      <tag>SSD</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Faster RCNN源码分析（零）—— 整体框架</title>
    <link href="/2021/09/01/Faster-RCNN%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-0/"/>
    <url>/2021/09/01/Faster-RCNN%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-0/</url>
    
    <content type="html"><![CDATA[<h2 id="0-前言"><a href="#0-前言" class="headerlink" title="0. 前言"></a>0. 前言</h2><p>两段式目标检测的代表作，相当复杂。</p><p>基于pytorch的源码，捋一遍Faster-RCNN到底干了啥。</p><p>这里先说一下框架，后面有时间再开几篇依次展开说各个子流程的代码实现细节。</p><div align=center><img title="" src="/img/article/fr-rcnn-frame.jpg" width="100%" height="100%" align=center></div><h2 id="1-从dataset加载图像"><a href="#1-从dataset加载图像" class="headerlink" title="1. 从dataset加载图像"></a>1. 从dataset加载图像</h2><p>首先要从把标注好的图像文件以及标注xml文件读取进来。</p><p>参考<a href="https://guohongming.xyz/2021/08/12/%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86/">这里</a>自定义的dataset类，可以知道，dataloader每次迭代返回的是，dataset类<code>__getitem__</code>方法的返回值经过自定义的collate_fn包装过的结果，也就是image tensor的tuple，targets dict的tuple。</p><p>而后在送入模型之前，还将tuple转为list，便于cat/stack之类的操作。</p><p>另外图像的BN、增广等操作也在这里进行。</p><p><strong>本阶段数据转化结果:</strong></p><ul><li><p><strong>image</strong>: jpg -&gt; [tensor(3x350x450), tensor(3x375x500)]，3x375x450指图像的原始尺寸</p></li><li><p><strong>target</strong>: xml -&gt; [dict1, dict2]，dict的结构详见<a href="https://guohongming.xyz/2021/08/12/%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86/">这里</a></p></li></ul><h2 id="2-图像预处理"><a href="#2-图像预处理" class="headerlink" title="2. 图像预处理"></a>2. 图像预处理</h2><p>原始图像的尺寸是不保证一致的，因此送入模型的图像都要先进行尺寸缩放、padding等操作。</p><p><strong>本阶段数据转化结果:</strong></p><ul><li><strong>image</strong>: [tensor(3x350x450), tensor(3x375x500)] -&gt; ImageList，ImageList是一个同时保存预处理之后的图像数据以及padding前缩放后图像尺寸的类。如<figure class="highlight clojure"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs clojure">&#123;image_sizes = [(<span class="hljs-number">800</span>,<span class="hljs-number">1028</span>), (<span class="hljs-number">800</span>, <span class="hljs-number">1066</span>)]<br>tensors = tensor(<span class="hljs-number">2</span>x3x800x1088)&#125;<br></code></pre></td></tr></table></figure></li><li><strong>target</strong>: [dict1, dict2] -&gt; [dict1, dict2]，数据类型没有变化，只是其中boxes的坐标进行了同比例缩放</li></ul><h2 id="3-Backbone"><a href="#3-Backbone" class="headerlink" title="3. Backbone"></a>3. Backbone</h2><p>使用经典分类网络的特征提取部分，作为Backbone，来得到feature map。</p><p>以配备了FPN结构的ResNet50为例，Backbone接受上一步的ImageList.tensors之后，将输出5个feature map。这5个feature map被组织为一个dict。</p><p><strong>本阶段数据转化结果:</strong></p><ul><li><strong>image</strong>: ImageList -&gt; <strong>features</strong>: dict，dict的结构如下，<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">features</span> = &#123;<br><span class="hljs-attribute">0</span> : tensor(<span class="hljs-number">2</span>x<span class="hljs-number">256</span>x<span class="hljs-number">200</span>x<span class="hljs-number">272</span>),<br><span class="hljs-attribute">1</span> : tensor(<span class="hljs-number">2</span>x<span class="hljs-number">256</span>x<span class="hljs-number">100</span>x<span class="hljs-number">136</span>),<br><span class="hljs-attribute">2</span> : tensor(<span class="hljs-number">2</span>x<span class="hljs-number">256</span>x<span class="hljs-number">50</span>x<span class="hljs-number">68</span>),<br><span class="hljs-attribute">3</span> : tensor(<span class="hljs-number">2</span>x<span class="hljs-number">256</span>x<span class="hljs-number">25</span>x<span class="hljs-number">34</span>),<br><span class="hljs-attribute">pool</span> : tensor(<span class="hljs-number">2</span>x<span class="hljs-number">256</span>x<span class="hljs-number">13</span>x<span class="hljs-number">17</span>)&#125;<br></code></pre></td></tr></table></figure></li></ul><h2 id="4-RPN"><a href="#4-RPN" class="headerlink" title="4. RPN"></a>4. RPN</h2><p>RPN可谓是Faster RCNN算法的核心，所有关键内容基本上都杂糅在其中。后续的预测结构，损失也都跟RPN类似。具体来看，依次做了这几件事：</p><h3 id="4-1-RPN-Head"><a href="#4-1-RPN-Head" class="headerlink" title="4.1 RPN Head"></a>4.1 RPN Head</h3><p>将所有feature map的value组装为一个list，送入RPN head结构，生成两个量：</p><ul><li>针对proposal的置信度参数objectness，一个跟输入对应的list</li><li>针对proposal的边界框回归参数proposal_box_reg，同样是一个跟输入对应的list</li></ul><p><strong>本阶段数据转化结果</strong></p><ul><li><strong>features</strong>: dict -&gt; <strong>objectness</strong>: [tensor(2x3x200x272), tensor(2x3x100x136)，tensor(2x3x50x68)，tensor(2x3x25x34)，tensor(2x3x13x17)]<br>其中[B,C,H,W]中只有C维度的size发生改变，新值3的含义是要在这个feature map上的每一个HW cell上产生3个proposal，tensor的值表示对应proposal的置信度。</li><li><strong>features</strong>: dict -&gt; <strong>proposal_box_reg</strong>: [tensor(2x12x200x272), tensor(2x12x100x136)，tensor(2x12x50x68)，tensor(2x12x25x34)，tensor(2x12x13x17)]<br>其中C维度12表示每个HW cell上3个proposal的4个边界框回归参数。</li></ul><h3 id="4-2-AnchorGenerate"><a href="#4-2-AnchorGenerate" class="headerlink" title="4.2 AnchorGenerate"></a>4.2 AnchorGenerate</h3><p>为每一层feature map上的一个HW cell生成一套anchor。</p><p>anchor是基于规则生成的，而非输入图像的数据，因此需要指定一套包含几个anchor，每个anchor的面积以及HW比例。生成的这些anchor都用相对于某个中心点的相对坐标表示。</p><p>然后定位每feature map的HW cell在原图上的感受野，取感受野左上角元素为中心点，计算得到所有feature map上所有cell的所有anchor在原图上的绝对坐标，用一个list表示。</p><p><strong>本阶段数据转化结果</strong></p><ul><li><strong>anchor参数</strong> -&gt; <strong>anchor_list</strong> : [tensor(217413x4), tensor(217413x4)]<br>其中，2个tensor对应本batch的2张图像，而且2个tensor的值完全相同，因为anchor是按照规则生成的，只和图像的尺寸有关，与图像的数据无关。另外，$217413 = (200\times272 + 100\times136 + 50\times68 + 25\times34 + 13\times17)\times3$。</li></ul><h3 id="4-3-DecodeProposal"><a href="#4-3-DecodeProposal" class="headerlink" title="4.3 DecodeProposal"></a>4.3 DecodeProposal</h3><p>用proposal_box_reg和anchor_list进行decode操作，得到proposal，如<code>tensor(2x217413x4)</code>。decode/encode公式如下：</p><script type="math/tex; mode=display">P_x=A_x + A_wd_x</script><script type="math/tex; mode=display">P_y=A_y + A_hd_y</script><script type="math/tex; mode=display">P_w=A_we^{d_w}</script><script type="math/tex; mode=display">P_h=A_he^{d_h}</script><p>式中，$(A_x, A_y, A_w, A_h)$和$(d_x, d_y, d_w, d_h)$分别为anchor_list和proposal_box_reg的元素，在这里是已知。$(P_x, P_y, P_w, P_h)$为proposal的元素，在这里是未知。</p><p><strong>本阶段数据转化结果</strong></p><ul><li><strong>anchor_list</strong>: [tensor(217413x4), tensor(217413x4)] + <strong>proposal_box_reg</strong>: [tensor(2x12x200x272), tensor(2x12x100x136)，tensor(2x12x50x68)，tensor(2x12x25x34)，tensor(2x12x13x17)] -&gt; <strong>proposals</strong>: tensor(2x217413x4)</li></ul><h3 id="4-4-FilterProposal"><a href="#4-4-FilterProposal" class="headerlink" title="4.4 FilterProposal"></a>4.4 FilterProposal</h3><p>遍历本batch中的图片，过滤每张图片这数十万个proposal，每张图片只保留2000个/1000个（前者对应训练模式，后者对应预测模式）。筛选的规则如下</p><ol><li>将每一个feature map得到的proposal视为一个集合，取每个集合中objectness值最大的前2000个/1000个，不足则都算上。</li><li>将proposal中的越界坐标调整到图像边界上，然后去除H或W小于某个阈值的proposal。</li><li>去除对应的score小于阈值的proposal，其中score由objectness经sigmoid之后得到。</li><li>将所有feature map得到proposal视为一个集合，对这个集合做nms，去除与highscore box的iou大于0.7的lowscore box。其中各个feature map之间的proposal不滤除，就是说不会因为f1中的一个highscore box和f2中的一个lowscore box的iou过大，而去除这个lowscore box。</li><li>在nms之后的结果中，取score最大的前2000个/1000个，作为最终的proposal。</li></ol><p>最终得到proposal和score的list。</p><p><strong>本阶段数据转化结果</strong></p><ul><li><strong>proposals</strong>: tensor(2x217413x4) -&gt; [tensor(2000x4), tensor(2000x4)]</li><li><strong>objectness</strong>: [tensor(2x3x200x272), tensor(2x3x100x136)，tensor(2x3x50x68)，tensor(2x3x25x34)，tensor(2x3x13x17)] -&gt; <strong>socores</strong>: [tensor(2000x4), tensor(2000x4)]</li></ul><h3 id="4-5-ComputeLoss"><a href="#4-5-ComputeLoss" class="headerlink" title="4.5 ComputeLoss"></a>4.5 ComputeLoss</h3><p>如果是预测模式，那么到上一步RPN模块的工作就结束了。但如果是训练模式，还要继续进行RPN loss的计算。</p><blockquote><p>备注一下，pytorch中计算RPN损失不是基于Filter之后的那2000个proposal，而是在原有的217413个proposal中进行随机抽样256个box，并且尽量保证正负样本的比例为1:1，正样本不够的话就有多少都算上。</p></blockquote><p>我们知道，计算损失的目的是为了量化模型<strong>预测结果</strong>和<strong>真实信息</strong>的偏离程度。对于RPN而言，模型输出的<strong>预测结果</strong>是这些proposal，与之对比的<strong>真实信息</strong>是图片的GTbox。而对比一个proposal box和一个GTbox，其实是对比他们两个相同属性——坐标&amp;标签，那么量化偏离程度就要从两个角度出发：</p><script type="math/tex; mode=display">L = \frac{1}{N}\sum_{i}^{N}{L_{cls}(p_i, p_i^*)} + \lambda \frac{1}{N}\sum_{i}^{N}p_i^*{L_{box}}</script><script type="math/tex; mode=display">L_{cls}(p_i, p_i^*) = -[p_i^*\ln{p_i}+(1-p_i^*)\ln(1-p_i)]</script><script type="math/tex; mode=display">L_{box} = \sum_{i = x,y,w,h} smooth_{L1}(d_i-d_i^*)</script><p>以上式中</p><ul><li>前后两个N在原论文中是不同的值，但是在pytorch源码中，就直接等同为抽样数量了。</li><li>$p_i$指objectness的值，$p_i^*$指proposal的真实标签。</li><li>$\lambda$用来平衡两个损失项，pytorch实现中直接取消了。</li><li>$d_i$指proposal_box_reg的值，$d_i^*$指anchor和与其匹配的GTbox解码出来的边界框回归参数。</li><li>$L_{cls}(p_i,p_i^*)$在原文中是softmax函数，但是因为只有两类，pytorch直接用二值交叉熵进行计算。</li></ul><h4 id="4-5-1-边界框坐标损失计算"><a href="#4-5-1-边界框坐标损失计算" class="headerlink" title="4.5.1 边界框坐标损失计算"></a>4.5.1 边界框坐标损失计算</h4><p>首先，为anchor_list中的所有anchor分配一个最佳匹配的GTbox（来自图像标注信息target）。匹配的规则是，对于一张图片的一个anchor，计算其与本图片所有GTbox的IOU，与其有最大IOU的那个GTbox，称之为该anchor的最佳匹配GTbox。获得了anchor和GTbox之间的匹配关系后，即可进行预测信息与GT信息之间的对比，从而得到偏离程度，亦即loss。现在有，</p><p><strong>因为</strong>：<br></p><ul><li>anchor坐标 + 真实的边界框编码参数 -&gt; GTbox坐标</li><li>anchor坐标 + 预测的边界框编码参数 -&gt; proposal坐标</li></ul><p><strong>因此</strong>：<br></p><ul><li>对比proposal和GTbox坐标的偏离程度等价于对比真实的和预测的边界框编码参数</li></ul><p>前者利用anchor和与之匹配的GTbox进行decode得到，后者就是RPN Head输出的proposal_box_reg。这样便得到了边界框坐标损失。</p><h4 id="4-5-2-前-后景分类损失计算"><a href="#4-5-2-前-后景分类损失计算" class="headerlink" title="4.5.2 前/后景分类损失计算"></a>4.5.2 前/后景分类损失计算</h4><p>前/后景分类损失反映的是一个proposal box的<strong>真实标签</strong>与<strong>预测标签</strong>的差异程度。我们已知<strong>预测标签</strong>就是每一个proposal的objectness值，那么一个proposal的<strong>真实标签</strong>是什么呢？至少我们的标注信息中是没有直接包含这一信息的。一种合适的做法是，比较匹配的一对GTbox和proposal box之间的IOU。</p><blockquote><p>所谓匹配是指，在4.5.1小节中我们建立了每一个anchor和Gtbox之间的匹配关系，而每一个anchor与RPN head输出的proposal_box_reg结合可以得到一个proposal box，这样这个anchor便将Gtbox和proposal box联系起来了。</p></blockquote><p>具体的做法如下：</p><ol><li>若它们的IOU极大，说明重合度高，应认为这个proposal是一个前景的提案，其真实标签应为“前景”；</li><li>若它们的IOU极小，说明重合度低，应认为这个proposal是一个背景的提案，其真实标签应为“背景”；</li><li>若IOU不大也不小，那么简单地将其视为无效的样本，并且不将其计入损失计算过程。</li></ol><p>获得proposal的<strong>真实标签（labels）</strong>之后，便可将labels和objectness代入交叉熵公式计算损失了。</p><h2 id="5-ROI-Align"><a href="#5-ROI-Align" class="headerlink" title="5. ROI Align"></a>5. ROI Align</h2><p>RPN之后，下一步操作所依赖的原理是：经过训练的RPN现在输出的proposal在一定程度上已经足够准确了，可以将一个proposal box认为是一张只包含一个目标的小图片，然后将目标检测的问题转化为图像分类的问题。具体来讲，得到proposal之后，这张小图片从原图上哪个位置截取已经知道了，但是截取下来的内容还不知道，所以要进行本段内容描述的操作。</p><blockquote><p>备注一下，跟RPN计算损失时一样，从这里往后的损失计算也不是所有217413个proposal都使用，而是只在Filter之后的2000个之中随机抽样512个，并且尽可能地保证正负样本比例为1:3。如果是预测模式则不抽样。</p><p>另外也不是所有feature map都使用，pooling出来的那一层数据后面也不用。</p></blockquote><p>因此，我们应该将proposal box框住的feature map区域当做下一步处理的对象（而不是原图）。这引入了3个问题：</p><ol><li>RPN得到的proposal box角点坐标都是基于原图的，如何知道一个proposal在feature map上所对应区域的角点坐标呢？</li><li>在FPN介入的情况下，feature map有多个，如何知道将一个proposal box映射到哪个feature map上呢？</li><li>proposal box有大有小，从原图到不同feature map上的映射比例也不尽相同，怎么封装成一个合适的tensor供后续处理呢？</li></ol><p>对于第一个问题，确定原图到feature map之间的比例，然后对proposal box坐标进行等比例缩放即可。</p><p>对于第二个问题，原论文基于FPN越低层的输入对应越大尺度对象的原则，设计了一个经验公式。</p><script type="math/tex; mode=display">k = \lfloor k_0 + \log_2(\frac{\sqrt{wh}}{224}) \rfloor</script><p>通过这个经验公式，利用proposal box的HW尺寸即可选择一个合适的feature map进行映射。</p><blockquote><p>其实，原论文中的这个公式是基于Fast RCNN的，也就是不采用RPN时的RCNN。因为采用RPN时，每个proposal都是由feature map经过RPN Head直接生成的，因此天然地知道proposal和feature map的对应关系。而Fast RCNN采用Select Search算法得到proposal，缺失这层关系，所以得用这个经验公式。</p><p>但是pytorch实现Faster RCNN还是用了这个经验公式进行proposal与feature map的匹配，而不是用RPN自带的信息。</p></blockquote><p>对于第三个问题，采用ROI Pooling或者说ROI Align算法处理，将所有大小各异的proposal feature box缩放成一致大小的tensor。基本原理是，将每个proposal feature box等分成7x7个区域，然后取每个区域内的最大值，这样无论之前的proposal feature box的HW尺寸如何，最后的输出都是一个7x7的大小。如果7x7处理后直接对子区域坐标取整然后maxpool就是ROI Pooling，用更复杂的插值算法得到最值则是ROI Align，当然后者效果更好。</p><div align=center><img title="" src="/img/article/roipooling.gif" width="60%" height="60%" align=center></div><p><strong>本阶段数据转化结果</strong></p><ul><li><strong>proposal</strong>:[tensor(2000x4), tensor(2000x4)] -&gt; <strong>proposal</strong>:[tensor(512x4), tensor(512x4)] + <strong>proposal_Gtbox</strong>: [tensor(512x4), tensor(512x4)] + <strong>label</strong>:[tensor(512x1), tensor(512x1)]</li><li><strong>proposal</strong>:[tensor(512x4), tensor(512x4)] + <strong>features</strong> : dict -&gt; <strong>proposal_features</strong>: tensor(1024x256x7x7)</li></ul><blockquote><p>如果是预测模式则将以上出现的512替换为1000来理解</p></blockquote><h2 id="6-TwoMLPHead"><a href="#6-TwoMLPHead" class="headerlink" title="6. TwoMLPHead"></a>6. TwoMLPHead</h2><p>这一层比较简单，就是将ROI Align之后的proposal_features第一个维度之后的数据flatten，然后通过两个串联的全连接层。</p><blockquote><p>也就是说一个batch处理1024个框，每张图像512个，每个框用一个256x7x7个标量数据组成的列向量表示。如果是预测模式则是每张图像1000个框。</p></blockquote><p>第一层256x7x7个节点，没得选，输入在那，RELU激活；第二层人为设定为1024个节点，同样是RELU激活。</p><p>最终得到一个1024x1024的tensor。</p><p><strong>本阶段数据转化结果</strong></p><ul><li><strong>proposal_features</strong>: tensor(1024x256x7x7) -&gt; tensor(1024x1024)</li></ul><blockquote><p>如果是预测模式，那么应该为1000x256x7x7-&gt;1000x1024</p></blockquote><h2 id="7-Predictor"><a href="#7-Predictor" class="headerlink" title="7. Predictor"></a>7. Predictor</h2><p>这一层也比较简单，就是将TwoMLPHead输出的tensor通过两个并联的全连接层。这两个全连接层上的结构以及作用与RPN Head基本相同，一个生成类别参数，一个生成边界框回归参数。类别层class_num个节点，边界框层class_num x 4个节点。</p><p><strong>这里的预测结果要多说一句，在进入ROI align之前，每张图片的proposal经过过滤剩下512或500个，这个数字对于理解后面的内容、以及以后的内容都非常非常重要。</strong></p><p><strong>首先在这里定义，一个proposal产生的一系列最终结果为一组同源detection，那么每张图片会产生512组同源detection。然后，一个proposal框住的feature map数据经过ROI align、MLPHead和Predictor，最终生成21组边界框回归参数和21个置信度。这个21组边界框回归参数都和这一个proposal框进行decode，得到21个final_box。21个置信度经过softmax之后的到21个score。再加上天然存在的序列信息，亦可得到label。</strong></p><blockquote><p>也就是说，一个proposal框住的子图像最终会产生21个detection(一组同源detection)。这意味着一个proposal内哪怕有不同类别的多个目标也还是被同时检测出来。这个结论对于SSD也成立。（YOLOv1你脸红什么？）</p></blockquote><p>这样，每个detection的三个属性label &amp; score &amp; box_reg就都有了。一个detection的结构大致如下图所示（以3个detection，5个类别为例）：</p><div align=center><img title="" src="/img/article/faster-rcnn-0-0.png" width="90%" height="90%" align=center></div><p><strong>本阶段数据转化结果</strong></p><ul><li><strong>porposal_feature</strong>: tensor(1024x1024) -&gt; <strong>class_logits</strong>: tensor(1024 x class_num) + <strong>box_regs</strong>: tensor(1024 x [class_num x 4])</li></ul><blockquote><p>数据转化结果中的第一个维度在预测模式下同样应该是1000而不是1024</p></blockquote><h2 id="8A-预测结果后处理"><a href="#8A-预测结果后处理" class="headerlink" title="8A. 预测结果后处理"></a>8A. 预测结果后处理</h2><p>上一步完成后，实质意义上的模型预测就已经完成了。如果是在预测模式下工作，接下来需要将class_logits和box_regs解释到缩放前的原始图像上。</p><h3 id="8A-1-FilterDetection"><a href="#8A-1-FilterDetection" class="headerlink" title="8A.1 FilterDetection"></a>8A.1 FilterDetection</h3><p>对于每一张图像，具体工作如下：</p><ol><li>对class_logits做softmax，得到每一个box的score；</li><li>对box_reg和proposal角点坐标做decode，得到每一个final_box的角点坐标；</li><li>类似RPN的FilterProposal，做low score过滤；</li><li>类似RPN的FilterProposal，做low WH过滤；</li><li>类似RPN的FilterProposal，针对每一个类别做nms，并且取nms之后的前100个box；</li></ol><p><strong>本阶段数据转化结果</strong></p><ul><li><strong>box_regs</strong>: tensor(1024 x [class_num x 4]) + <strong>proposal</strong>: [tensor(512x4), tensor(512x4)] -&gt; <strong>final_boxes</strong>: [100x4, 100x4]，进行decode和filter</li><li><strong>class_logits</strong>: tensor(1024 x class_num) -&gt; <strong>final_scores</strong>: [100x1, 100x1]，进行sotfmax和filter</li><li><strong>box_labels</strong>: tensor(1024 x class_num) -&gt; <strong>final_labels</strong>: [100x1, 100x1]，进行同步filter</li></ul><blockquote><p>这里的BoxLabel由规则生成，final_labels指的是预测信息，根据上图中box在一个detection的box序列中的相对位置确定。这就跟以往的经验不同了，这里并没有对一个detection所有框的score取最大值，然后将21个类别退化为1，而是将detection的每一列也就是每一个预测框作为一个单独的个体。就是说最终的100个预测框中完全有可能同时存在两个产生自同一个detection。</p><p>数据转化结果中的第一个维度在预测模式下同样应该是1000而不是1024</p></blockquote><h3 id="8A-2-PostTransform"><a href="#8A-2-PostTransform" class="headerlink" title="8A.2 PostTransform"></a>8A.2 PostTransform</h3><p>将detection三要素中的box坐标根据原图缩放前和缩放后的比例进行等比例缩放即可。</p><h2 id="8B-FasterRCNN损失计算"><a href="#8B-FasterRCNN损失计算" class="headerlink" title="8B. FasterRCNN损失计算"></a>8B. FasterRCNN损失计算</h2><p>当在训练模式下工作时，需要进行FasterRCNN损失计算。与RPN损失类似，FasterRCNN损失同样分为两部分，坐标损失和分类损失。首先捋一下两部分各自的真实信息和预测信息是什么：</p><ol><li>坐标回归参数的预测信息，Predictor输出的box_regs；</li><li>坐标回归参数的真实信息GT_regs，用一对GTbox和proposal进行encode得到；</li><li>预测框类别的预测信息，Predictor输出的class_logits；</li><li>预测框类别的真实信息GT_labels，获取方式跟之前RPN类似，即先将proposal和GTbox进行匹配，然后用匹配之后的IOU值的大小来判定proposal是否值得拥有与之匹配的GTbox的label，若值得(IOU&gt;0.5)则proposal的真实label就是GTbox的label，否则为0；</li></ol><p>捋清楚了上述信息之后，即可将对应数据代入到类似RPN的损失函数中进行计算，得到FasterRCNN的最终损失。</p><p><strong>本阶段数据转化结果</strong></p><ul><li><strong>class_logits</strong>: tensor(1024 x classnum) + <strong>GT_labels</strong>: [tensor(512x1), tensor(512x1)] -&gt; $L_{cls}$</li><li><strong>box_regs</strong>: tensor(1024 x [classnum x 4]) + <strong>GT_regs</strong>: [tensor(512x4),tensor(512x4)] -&gt; $L_{box}$</li></ul><blockquote><p>可以看到真实信息和预测信息之间差了一个classnum的维度，在计算$L_{cls}$时不要紧，因为交叉熵计算用到的GT_label是one-hot的形式，pytorch的实现机制自己会进行合理的计算。</p><p>在计算$L_{box}$时，要增加一个classnum上的索引将其退化为1，从而与GT_regs保持一致。索引的来源是GT_label的one-hot向量中1的位置，所以也就是说将GT_reg拓展为four-hot即可。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
      <category>目标检测</category>
      
      <category>Faster RCNN</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>神经网络</tag>
      
      <tag>卷积神经网络</tag>
      
      <tag>CNN</tag>
      
      <tag>目标检测</tag>
      
      <tag>Faster RCNN</tag>
      
      <tag>RPN</tag>
      
      <tag>ROI Align</tag>
      
      <tag>ROI Pooling</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Shell笔记</title>
    <link href="/2021/08/25/note_of_shell/"/>
    <url>/2021/08/25/note_of_shell/</url>
    
    <content type="html"><![CDATA[<h3 id="shell解释器的种类"><a href="#shell解释器的种类" class="headerlink" title="shell解释器的种类"></a>shell解释器的种类</h3><ol><li>一个shell脚本可以被不同的解释器解释执行，常见的解释器有sh、bash、zsh、dash。可以使用以下命令查看本机的shell解释器配置：<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">#本机可用的shell解释器</span><br>cat <span class="hljs-regexp">/etc/</span>shells<br><br><span class="hljs-comment">#当前默认设置，一般在第一行</span><br>cat <span class="hljs-regexp">/etc/</span>passwd<br><br><span class="hljs-comment">#当前设置</span><br>echo <span class="hljs-variable">$SHELL</span><br></code></pre></td></tr></table></figure></li><li>一个shell脚本具体被哪一个解释器解释执行，依次看：<ul><li>cmd命令指定的是哪个</li><li>shebang指定的是哪个</li><li><a href="https://stackoverflow.com/questions/69643212/how-is-it-determined-which-shell-runs-a-script?noredirect=1#comment123105552_69643212">都不指定的话不清楚用哪个</a><figure class="highlight d"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs d">#cmd命令指定<br>bash ./test.sh<br>zsh ./test.sh<br><br>#Shebang指定<br><span class="hljs-meta">#!/usr/bin/env bash到PATH路径下找到bash以执行脚本</span><br><span class="hljs-meta">#!/bin/bash用/bin目录下的bash程序执行脚本</span><br><br>#暂时不清楚用哪个shell来执行<br>./test.sh<br></code></pre></td></tr></table></figure></li></ul></li></ol><h3 id="shell脚本的执行方式"><a href="#shell脚本的执行方式" class="headerlink" title="shell脚本的执行方式"></a>shell脚本的执行方式</h3><p>shell脚本的执行方式有source和bash两类，前者的一般用途是实现python的import机制，即在另一个shell脚本中实现一堆公用的变量和函数，然后加载到当前脚本中。而后者则是真实的执行。</p><p>When you execute the script you are opening a new shell, type the commands in the new shell, copy the output back to your current shell, then close the new shell. Any changes to environment will take effect only in the new shell and will be lost once the new shell is closed.</p><p>When you source the script you are typing the commands in your current shell. Any changes to the environment will take effect and stay in your current shell.</p><p>Sourcing a script will run the commands in the current shell process. Changes to the environment take effect in the current shell.</p><p>Executing a script will run the commands in a new shell process. Changes to the environment take effect in the new shell and is lost when the script is done and the new shell is terminated.</p><p>Use source if you want the script to change the environment in your currently running shell. use execute otherwise.</p><h3 id="重定向"><a href="#重定向" class="headerlink" title="重定向"></a>重定向</h3><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">cmd</span> &gt; file <span class="hljs-number">2</span>&gt;&amp;<span class="hljs-number">1</span><br><span class="hljs-comment"># 首先将cmd的输出重定向到file中，然后将标准错误输出绑定到标准输出上。合起来的意思是将cmd产生的，本来应该分别输出到标准输出和标准错误输出的打印信息，全部输出到file文件中</span><br><br></code></pre></td></tr></table></figure><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gradle">cmd &amp;&gt;<span class="hljs-regexp">/dev/</span><span class="hljs-keyword">null</span><br>cmd &gt;<span class="hljs-regexp">/dev/</span><span class="hljs-keyword">null</span> <span class="hljs-number">2</span>&gt;&amp;<span class="hljs-number">1</span><br># 这两句话等价，那么从第二句看，并且结合前面的内容可以知道，这里的意思是将cmd产生的stdout和stderr都重定向到<span class="hljs-regexp">/dev/</span><span class="hljs-keyword">null</span>中。这个<span class="hljs-regexp">/dev/</span><span class="hljs-keyword">null</span>可以看作一个blackhole，会把所有输进去的内容吃掉。因此，这句话一般用作忽略cmd的任何输出信息。<br></code></pre></td></tr></table></figure><h3 id="静默执行"><a href="#静默执行" class="headerlink" title="静默执行"></a>静默执行</h3><p>涉及到的概念有：<strong>前/后台程序</strong>，<strong>nohup前缀</strong>，<strong>&amp;后缀</strong>，<strong>Ctrl-Z</strong>，<strong>bg/fg命令</strong>，<strong>HUP信号</strong>，<strong>TSTP信号</strong>。</p><h4 id="前-后台程序"><a href="#前-后台程序" class="headerlink" title="前/后台程序"></a>前/后台程序</h4><p>前/后台程序的区别在于，启动该程序的shell是否被该程序阻塞。阻塞，意味着shell暂时不能跟用户交互了，只能等待前台程序执行结束，后台则无此影响。</p><p>在原本的启动命令后加上 &amp; 后缀，即可将该程序放到后台执行。并且，若此时未经过重定向，还是会将打印信息输出到终端，所以要想完全放到后台还需要将输出重定向。<br>  <figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arcade">yes love &amp;&gt;<span class="hljs-regexp">/dev/</span><span class="hljs-literal">null</span> &amp;<br></code></pre></td></tr></table></figure></p><p>当一个程序已经在前台阻塞式执行时，使用Ctrl-Z命令可以向程序发送TSTP信号，将程序暂停。然后通过bg命令可以将该程序恢复到后台执行，fg则恢复到前台。</p><h4 id="防挂起"><a href="#防挂起" class="headerlink" title="防挂起"></a>防挂起</h4><p>nohup前缀产生的相关效果是独立于前/后台程序的另一个话题，其直接效果是使得程序免疫HUP信号。HUP信号一般会在关闭终端或用户注销时发出，接收到HUP信号的程序会终止执行。间接效果是将程序的stdout和stderr信息重定向到一个nohup.out文件。</p><p>综上，用下面这个形式的命令可以实现一个程序的<strong>安全(终端关掉也不会停)</strong>、<strong>静默(启动了就跟没启动一样)</strong>执行。<br><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arcade">nohup cmd &amp;&gt;<span class="hljs-regexp">/dev/</span><span class="hljs-literal">null</span> &amp;<br></code></pre></td></tr></table></figure></p><p><a href="https://linuxhint.com/how_to_use_nohup_linux/">参考链接</a></p>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>shell笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>shell</tag>
      
      <tag>bash</tag>
      
      <tag>重定向</tag>
      
      <tag>nohup</tag>
      
      <tag>后台</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>C/C++笔记</title>
    <link href="/2021/08/25/note_of_cpp/"/>
    <url>/2021/08/25/note_of_cpp/</url>
    
    <content type="html"><![CDATA[<h3 id="数组指针-amp-指针的数组-amp-数组名"><a href="#数组指针-amp-指针的数组-amp-数组名" class="headerlink" title="数组指针&amp;指针的数组&amp;数组名"></a>数组指针&amp;指针的数组&amp;数组名</h3><p>故事从<code>int (*)[10]</code>开始，这是一种数据类型，具体点是一种<strong>“指向‘长度为10的int数组’这种类型的指针”</strong>类型。<br><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-built_in">int</span> a[<span class="hljs-number">5</span>] = &#123;<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>&#125;;<br><br><span class="hljs-built_in">int</span> (*)[<span class="hljs-number">5</span>] p1;<span class="hljs-comment">//竟然是错误的用法。。。</span><br><span class="hljs-built_in">int</span> (*p2)[<span class="hljs-number">5</span>] = a;<span class="hljs-comment">//正不正确看编译器的种类和版本，不建议这么用</span><br><span class="hljs-built_in">int</span> (*p3)[<span class="hljs-number">5</span>] = &amp;a;<span class="hljs-comment">//最正确的用法，注意，这里对a取地址得到的不是a的地址，而是将a的值直接赋过去，看起来就像没有取地址</span><br><br><span class="hljs-comment">/* 推荐用法 */</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-built_in">uint</span>8 Dt_ARRAY_700_uint8[<span class="hljs-number">700</span>]; <span class="hljs-comment">//先将数组定义成数据类型</span><br>Dt_ARRAY_700_uint8 uss_raw_data;<br><br>Dt_ARRAY_700_uint8 *ptr = &amp;uss_raw_data;<span class="hljs-comment">//正确用法</span><br>Dt_ARRAY_700_uint8 *ptr = uss_raw_data;<span class="hljs-comment">//等价于上面p2那个不建议使用的用法，在qnx平台上编译时就报错了。</span><br><br></code></pre></td></tr></table></figure></p><h3 id="终结字符串、字符的数组、字符数组名"><a href="#终结字符串、字符的数组、字符数组名" class="headerlink" title="终结字符串、字符的数组、字符数组名"></a>终结字符串、字符的数组、字符数组名</h3><ol><li><strong>常规的char的数组</strong><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">/* 基于C99标准 */</span><br>char s1[<span class="hljs-number">5</span>] = &#123;<span class="hljs-string">&#x27;1&#x27;</span>, <span class="hljs-string">&#x27;2&#x27;</span>, <span class="hljs-string">&#x27;3&#x27;</span>, <span class="hljs-string">&#x27;4&#x27;</span>, <span class="hljs-string">&#x27;5&#x27;</span>&#125;;<span class="hljs-regexp">//</span>常规的数组，只不过数组的元素是char<br>char s2[ ] = &#123;<span class="hljs-string">&#x27;1&#x27;</span>, <span class="hljs-string">&#x27;2&#x27;</span>, <span class="hljs-string">&#x27;3&#x27;</span>, <span class="hljs-string">&#x27;4&#x27;</span>, <span class="hljs-string">&#x27;5&#x27;</span>&#125;;<span class="hljs-regexp">//</span>效果同s1，生成一个长度为<span class="hljs-number">5</span>的数组<br>char s3[<span class="hljs-number">6</span>] = &#123;<span class="hljs-string">&#x27;1&#x27;</span>, <span class="hljs-string">&#x27;2&#x27;</span>, <span class="hljs-string">&#x27;3&#x27;</span>, <span class="hljs-string">&#x27;4&#x27;</span>, <span class="hljs-string">&#x27;5&#x27;</span>&#125;;<span class="hljs-regexp">//</span>s[<span class="hljs-number">6</span>]未提供初始值，默认初始化为<span class="hljs-string">&#x27;\0&#x27;</span><br>char s4[<span class="hljs-number">7</span>] = &#123;<span class="hljs-string">&#x27;1&#x27;</span>, <span class="hljs-string">&#x27;2&#x27;</span>, <span class="hljs-string">&#x27;3&#x27;</span>, <span class="hljs-string">&#x27;4&#x27;</span>, <span class="hljs-string">&#x27;5&#x27;</span>&#125;;<span class="hljs-regexp">//</span>原理同s3，s[<span class="hljs-number">6</span>]和s[<span class="hljs-number">7</span>]都被初始化为<span class="hljs-string">&#x27;\0&#x27;</span><br></code></pre></td></tr></table></figure></li><li><p><strong>基于”char的数组”实现的字符串语法糖</strong></p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">/* 基于C99标准 */</span><br>char s5[ ] = <span class="hljs-string">&quot;12345&quot;</span>;<span class="hljs-regexp">//</span>自动开辟<span class="hljs-number">6</span>个Byte而不是<span class="hljs-number">5</span>个，s[<span class="hljs-number">5</span>]默认初始化为<span class="hljs-string">&#x27;\0&#x27;</span>，最终效果同s3<br>char s6[<span class="hljs-number">6</span>] = <span class="hljs-string">&quot;12345&quot;</span>;<span class="hljs-regexp">//</span>效果同s3和s5<br>char s7[<span class="hljs-number">5</span>] = <span class="hljs-string">&quot;12345&quot;</span>;<span class="hljs-regexp">//</span>效果同s1和s2<br>char s8[<span class="hljs-number">7</span>] = <span class="hljs-string">&quot;12345&quot;</span>;<span class="hljs-regexp">//</span>效果同s4<br></code></pre></td></tr></table></figure></li><li><p><strong>基于”char的指针”实现的字符串语法糖</strong></p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">/* 基于C99标准 */</span><br>char* s9 = <span class="hljs-string">&quot;12345&quot;</span>;<span class="hljs-regexp">//</span>自动开辟<span class="hljs-number">6</span>个Byte而不是<span class="hljs-number">5</span>个，s[<span class="hljs-number">5</span>]默认初始化为<span class="hljs-string">&#x27;\0&#x27;</span>，最终效果同s3。但是，是在全局的只读数据区开辟，数组内容无法被修改。<br></code></pre></td></tr></table></figure></li><li><p><strong>总结</strong><br>当你想创建一个内存内容为<code>&#123;&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;,&#39;\0&#39;&#125;</code>的对象时，以下4种做法等价，正规来讲应该用s3，但最省事的肯定是s5和s9（所以说是两个语法糖）。然后再视是否需要修改对象内容来决定s5还是s9。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">char</span> s<span class="hljs-number">3</span>[<span class="hljs-number">6</span>] = &#123;&#x27;<span class="hljs-number">1</span>&#x27;, &#x27;<span class="hljs-number">2</span>&#x27;, &#x27;<span class="hljs-number">3</span>&#x27;, &#x27;<span class="hljs-number">4</span>&#x27;, &#x27;<span class="hljs-number">5</span>&#x27;&#125;;<br><span class="hljs-attribute">char</span> s<span class="hljs-number">5</span>[ ] = <span class="hljs-string">&quot;12345&quot;</span>;<br><span class="hljs-attribute">char</span> s<span class="hljs-number">6</span>[<span class="hljs-number">6</span>] = <span class="hljs-string">&quot;12345&quot;</span>;<br><span class="hljs-attribute">char</span>* s<span class="hljs-number">9</span> = <span class="hljs-string">&quot;12345&quot;</span>;<br></code></pre></td></tr></table></figure><p>不过，在C99下发现s1，s2，s7这三个不以<code>&#39;\0&#39;</code>结尾的也可以用<code>printf(&quot;%s&quot;, s)</code>打印。。。不过，为了防止混淆，还是不要这么用。</p></li></ol><h3 id="cin的控制流转移逻辑"><a href="#cin的控制流转移逻辑" class="headerlink" title="cin的控制流转移逻辑"></a>cin的控制流转移逻辑</h3><ol><li>运行到<code>cin &gt;&gt; x</code>时，控制转移到终端，等待输入；</li><li>此时可以向cin流写入多个值（以空格或者tab切分），直到输入回车，从终端向cin流写入的过程停止，控制返回给程序。</li><li>cin以分隔符将流内的内容喂给<code>&gt;&gt;</code>右侧的变量</li><li>再&gt;&gt;时，会先检查流是否为空，不为空则无需变更控制流，按照上一条的逻辑继续写目标变量。</li></ol><h3 id="未命名的命名空间与静态声明"><a href="#未命名的命名空间与静态声明" class="headerlink" title="未命名的命名空间与静态声明"></a>未命名的命名空间与静态声明</h3><div align=center><img title="" src="/img/article/cpp_static.png" width="99%" height="99%" align=center></div><p><br>静态声明的使用方法分两大类，其中面向过程的使用方法已经被C++标准取消，相应的符号隔离机制通过未命名的命名空间来实现。</p><h3 id="define的特殊符号"><a href="#define的特殊符号" class="headerlink" title="define的特殊符号"></a>define的特殊符号</h3><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">#define <span class="hljs-constructor">Conn(<span class="hljs-params">x</span>,<span class="hljs-params">y</span>)</span>  x##y<br>#define <span class="hljs-constructor">ToChar(<span class="hljs-params">x</span>)</span>  #@x<br>#define <span class="hljs-constructor">ToString(<span class="hljs-params">x</span>)</span> #x<br><br><span class="hljs-comment">// ## 表示拼接</span><br><span class="hljs-built_in">int</span> n = <span class="hljs-constructor">Conn(123, 456)</span>;<br><span class="hljs-built_in">int</span> n = <span class="hljs-number">123456</span>;<br><br><span class="hljs-comment">// #@ 表示为后面的符号x增加单引号</span><br><span class="hljs-built_in">char</span> a = <span class="hljs-constructor">ToChar(1)</span>;<br><span class="hljs-built_in">char</span> a = <span class="hljs-character">&#x27;1&#x27;</span>;<br><br><span class="hljs-comment">// # 表示为后面的符号x增加双引号</span><br><span class="hljs-built_in">char</span>* s = <span class="hljs-constructor">ToString(123)</span>;<br><span class="hljs-built_in">char</span>* s = <span class="hljs-string">&quot;123&quot;</span>;<br></code></pre></td></tr></table></figure><h3 id="unique-ptr的两种指针释放方式"><a href="#unique-ptr的两种指针释放方式" class="headerlink" title="unique_ptr的两种指针释放方式"></a>unique_ptr的两种指针释放方式</h3><ol><li>release<br>release只是简单的将被unique_ptr封装的内置指针吐出来，被指向的对象的内存不会被释放，内置指针与该对象之间的指向关系也不会被破坏。</li><li>reset<br>reset首先释放unique_ptr封装起来的那个内置指针所指向的内存，然后根据传入的参数对该内置指针进行赋值。<div align=center><img title="" src="/img/article/unique_ptr.png" width="80%" height="80%" align=center></div></li></ol>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>C/C++笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>C语言</tag>
      
      <tag>C++</tag>
      
      <tag>数组指针</tag>
      
      <tag>字符数组</tag>
      
      <tag>字符串</tag>
      
      <tag>unique_ptr</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Faster RCNN源码分析（一）—— 图像预处理</title>
    <link href="/2021/08/15/Faster-RCNN%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-1/"/>
    <url>/2021/08/15/Faster-RCNN%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-1/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>一般数据集中的图像尺寸、通道都是不一致的，因此不管是进行训练还是预测之前，都需要进行尺寸一致化等预处理操作。处理的最终结果是每一个batch中的tensor尺寸一致，但是跨batch不一定一致。</p><p>Faster RCNN源码中，将图像预处理操作封装在一个类<code>GeneralizedRCNNTransform</code>中，下面针对这个类进行介绍。</p><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-comment"># 接受4个初始化参数，用于初始化4个对应成员</span><br><span class="hljs-comment"># min_size : 指定允许的最小尺寸</span><br><span class="hljs-comment"># max_size : 指定允许的最大尺寸</span><br><span class="hljs-comment"># image_mean : 指定归一化时三个通道各自的均值（默认来自ImageNet）</span><br><span class="hljs-comment"># image_std : 指定归一化时三个通道各自的方差（默认来自ImageNet）</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, min_size, max_size, image_mean, image_std)</span></span>:<br>    <span class="hljs-keyword">self</span>.min_size = min_size      <span class="hljs-comment"># 指定图像的最小边长范围</span><br>    <span class="hljs-keyword">self</span>.max_size = max_size      <span class="hljs-comment"># 指定图像的最大边长范围</span><br>    <span class="hljs-keyword">self</span>.image_mean = image_mean  <span class="hljs-comment"># 指定图像在标准化处理中的均值</span><br>    <span class="hljs-keyword">self</span>.image_std = image_std    <span class="hljs-comment"># 指定图像在标准化处理中的方差</span><br></code></pre></td></tr></table></figure><h2 id="正向过程"><a href="#正向过程" class="headerlink" title="正向过程"></a>正向过程</h2><p>接受1个batch的图像和对应的目标信息（预测时无目标），逐个遍历。依次进行：</p><ol><li>维度检查 —— <em>因为有些数据集通道数还真不一定是3</em></li><li>归一化 —— <em>减去方差，除以均值即可</em></li><li>缩放 —— <em>因为图像与其目标信息是耦合的因此要同步做，后面细讲</em></li><li>padding —— <em>真正的尺寸一致化操作</em></li><li>二次封装 —— <em>将resize后的图像尺寸与图像封装在一起</em></li></ol><h3 id="缩放"><a href="#缩放" class="headerlink" title="缩放"></a>缩放</h3><h4 id="图像缩放"><a href="#图像缩放" class="headerlink" title="图像缩放"></a>图像缩放</h4><p>缩放的原则是长和宽等比例缩放。缩放的目的是使得原图像能够最大程度进一个既定尺寸的框中，不管横着放还是竖着放。</p><p>这两个条件意味着，缩放之后的图像的长或宽，至少有一个等于这个框的一个边，所谓最大程度嘛。</p><p>具体操作时，先用缩放前图像的短边和框的短边产生缩放比例，然后检查长边按照该比例缩放后是否fit，如果超限了那么就要用两个长边产生缩放比例然后再去缩放短边。</p><h4 id="box缩放"><a href="#box缩放" class="headerlink" title="box缩放"></a>box缩放</h4><p>因为图像的尺寸变了，box的坐标自然也要跟着变。具体操作是，对比原图像和缩放后图像的长产生长度缩放因子，然后将box的两个角点的x坐标乘以该缩放因子。y坐标同理。</p><h3 id="padding"><a href="#padding" class="headerlink" title="padding"></a>padding</h3><p>经过缩放之后，一个batch内所有图像的尺寸还是不一致，毕竟有横有竖，而且未填满的那一个边的尺寸也不能保证一致。因此，在这一步找一个更大的，刚好能装下这个batch所有图像的框，以左上角对齐的方式进行尺寸一致化，右下角填不满的地方补0。</p><h3 id="二次封装"><a href="#二次封装" class="headerlink" title="二次封装"></a>二次封装</h3><p>就是简单的将缩放后，padding前的图像尺寸与图像封装称一个结构体<code>ImageList</code>。结构体的两个成员分别是一个表示本batch所有图像的4维tensor和一个记录图像尺寸的<code>List[Tuple[int, int]]</code></p><h3 id="返回"><a href="#返回" class="headerlink" title="返回"></a>返回</h3><p>最终，返回一个<code>ImageListd</code>对象和目标信息target。</p>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
      <category>目标检测</category>
      
      <category>Faster RCNN</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>神经网络</tag>
      
      <tag>卷积神经网络</tag>
      
      <tag>CNN</tag>
      
      <tag>目标检测</tag>
      
      <tag>Faster RCNN</tag>
      
      <tag>图形预处理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>双线性插值是啥？</title>
    <link href="/2021/08/15/%E5%8F%8C%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC%E6%98%AF%E5%95%A5%EF%BC%9F/"/>
    <url>/2021/08/15/%E5%8F%8C%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC%E6%98%AF%E5%95%A5%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>今天看FASTER RCNN的pytorch实现源码，进行图像缩放时用到了双线性插值算法，记录一下自己的理解。</p><h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>当将一幅图像从100x100的尺寸放大到200x200时，势必要新增30000个像素点。那么这些新增的像素点的灰度值如何得到呢？</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>双线性插值的做法是这样：</p><h3 id="1-建立坐标的对应关系"><a href="#1-建立坐标的对应关系" class="headerlink" title="1. 建立坐标的对应关系"></a>1. 建立坐标的对应关系</h3><p>将放大前的图像A和放大后的图形B的几何中心对齐，然后有</p><script type="math/tex; mode=display">\frac{x_A + 0.5}{x_B + 0.5} = \frac{w_A}{w_B}</script><script type="math/tex; mode=display">\frac{y_A + 0.5}{y_B + 0.5} = \frac{h_A}{h_B}</script><p>如果按照上面公式计算出来是整数，就直接将原图中的对应位置的灰度值复制过来。如果是小数，说明原图像中没有对应点，就将x/y分别向上/下取整得到4个坐标。</p><blockquote><p>其实也无所谓，一律按照下面方法计算即可，只不过是整数的时候取得是两个相同灰度值的均值，也就是还是他自己罢了。省的在这讨论，x整数y小数，x小数y整数这些问题了。</p></blockquote><h3 id="2-用A上4个对应像素点的灰度值计算B上1个像素点的灰度值"><a href="#2-用A上4个对应像素点的灰度值计算B上1个像素点的灰度值" class="headerlink" title="2. 用A上4个对应像素点的灰度值计算B上1个像素点的灰度值"></a>2. 用A上4个对应像素点的灰度值计算B上1个像素点的灰度值</h3><p>双线性插值说白了就是先将这4个点分成两组在一个方向上进行线性插值，得到两个中间值，然后用这两个中间值再进行一次线性插值，得到最终结果。</p><div align=center><img title="" src="/img/sxxcz.png" width="40%" height="40%" align=center></div><p>即，先有</p><script type="math/tex; mode=display">\frac{R_1-Q_{11}}{x-x_1}=\frac{Q_{21}-Q_{11}}{x_2-x_1}</script><script type="math/tex; mode=display">\frac{R_2-Q_{12}}{x-x_1}=\frac{Q_{22}-Q_{12}}{x_2-x_1}</script><p>然后，有</p><script type="math/tex; mode=display">\frac{P-R_1}{y-y_1}=\frac{R_2-R_1}{y_2-y_1}</script><p>其中，P为所求的B上$(x_B, y_B)$处的灰度值，$(x,y)$就是上面的$(x_A, y_A)$，四个Q就是A上四个对应像素点的灰度值，R为中间值。</p>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>图像缩放</tag>
      
      <tag>双线性插值</tag>
      
      <tag>bilinear interpolation</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>自定义目标检测数据集</title>
    <link href="/2021/08/12/%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    <url>/2021/08/12/%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>目标检测的数据集跟分类数据集不同，不仅仅包含图片和图片的类别信息，还要包括bounding box等一些额外的信息。因此，使用<a href="https://guohongming.xyz/2021/08/11/pytorch%E6%A0%B8%E5%BF%83%E7%94%A8%E6%B3%95-2/">之前</a>建立目录结构 + <code>datasets.ImageFolder()</code>的方法是不行的。</p><p>总的来看，自定义目标检测数据集要围绕<strong>原始图像</strong>、<strong>标注文件</strong>、<strong>入选名单</strong>三个要素，完成<strong>图像标注</strong>和<strong>自定义dataset类</strong>两项工作。</p><h2 id="三个要素"><a href="#三个要素" class="headerlink" title="三个要素"></a>三个要素</h2><ol><li>原始图像，统统存放在一个目录下</li><li>标注文件，一般为一个xml或json，文件名与原始图像一一对应，保存对应图像的标注相关信息</li><li>入选名单，一个txt文档，记录分到train_set和val_set的名单，每行一个去掉后缀的文件名</li></ol><h2 id="两项工作"><a href="#两项工作" class="headerlink" title="两项工作"></a>两项工作</h2><h3 id="图像标注"><a href="#图像标注" class="headerlink" title="图像标注"></a>图像标注</h3><ol><li>安装lableImg<blockquote><p>pip3 install labelImg   #中间遇到报错，参考<a href="https://stackoverflow.com/questions/59711301/install-pyqt5-5-14-1-on-linux">here</a>解决。</p></blockquote></li><li>新建一个文件夹，包含img目录，annotation目录，class.txt，分别用于存放待标注图像，标注结果，类别清单。<blockquote><p>labelImg ./img ./class.txt   #即可开始标注</p></blockquote></li><li>标注完成后写一个随机抽样脚本，生成train_set和val_set入选清单两个txt文件。<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs css">import os<br>import random<br><br>def <span class="hljs-selector-tag">main</span>():<br>    random.<span class="hljs-built_in">seed</span>(<span class="hljs-number">0</span>)  # 设置随机种子，保证随机结果可复现<br><br>    files_path = <span class="hljs-string">&quot;./annotation&quot;</span><br>    assert os.path.<span class="hljs-built_in">exists</span>(files_path), <span class="hljs-string">&quot;path: &#x27;&#123;&#125;&#x27; does not exist.&quot;</span>.<span class="hljs-built_in">format</span>(files_path)<br><br>    val_rate = <span class="hljs-number">0.5</span><br><br>    files_name = <span class="hljs-built_in">sorted</span>([file.<span class="hljs-built_in">split</span>(<span class="hljs-string">&quot;.&quot;</span>)[<span class="hljs-number">0</span>] for file in os.<span class="hljs-built_in">listdir</span>(files_path)])<br>    files_num = <span class="hljs-built_in">len</span>(files_name)<br>    val_index = random.<span class="hljs-built_in">sample</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, files_num), k=<span class="hljs-built_in">int</span>(files_num*val_rate))<br>    train_files = []<br>    val_files = []<br>    for index, file_name in <span class="hljs-built_in">enumerate</span>(files_name):<br>        if index in val_index:<br>            val_files.<span class="hljs-built_in">append</span>(file_name)<br>        else:<br>            train_files.<span class="hljs-built_in">append</span>(file_name)<br><br>    try:<br>        train_f = <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;train.txt&quot;</span>, <span class="hljs-string">&quot;x&quot;</span>)<br>        eval_f = <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;val.txt&quot;</span>, <span class="hljs-string">&quot;x&quot;</span>)<br>        train_f.<span class="hljs-built_in">write</span>(<span class="hljs-string">&quot;\n&quot;</span>.<span class="hljs-built_in">join</span>(train_files))<br>        eval_f.<span class="hljs-built_in">write</span>(<span class="hljs-string">&quot;\n&quot;</span>.<span class="hljs-built_in">join</span>(val_files))<br>    except FileExistsError as e:<br>        <span class="hljs-built_in">print</span>(e)<br>        <span class="hljs-built_in">exit</span>(<span class="hljs-number">1</span>)<br><br>if __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-built_in">main</span>()<br></code></pre></td></tr></table></figure></li></ol><h3 id="自定义dataset类"><a href="#自定义dataset类" class="headerlink" title="自定义dataset类"></a>自定义dataset类</h3><p>自定义一个dataset类需要先继承<code>torch.utils.data.Dataset</code>类，然后重写<code>__init__</code>方法，<code>__getitem__</code>方法，<code>__len__</code>方法</p><h4 id="init-方法"><a href="#init-方法" class="headerlink" title="__init__方法"></a><code>__init__</code>方法</h4><p>主要有以下几项工作：</p><ol><li>根据train_set.txt或者val_set.txt的内容建立<code>self.xml_list</code>，一个存放所有xml文件路径的list，并检查这些xml文件是否确实存在</li><li>根据描述类别信息的json文件建立<code>self.class_dict</code></li><li>根据传入参数设定预处理函数<code>self.transforms</code>的行为，包括RandomFlip等augmentation操作以及to_tensor，normalize等操作，在<code>getitem</code>方法中也就是具体内容前执行。</li></ol><h4 id="getitem-方法"><a href="#getitem-方法" class="headerlink" title="__getitem__方法"></a><code>__getitem__</code>方法</h4><p><code>__getitem__</code>方法目的是定义用[idx]索引本类示例时返回什么。在这里，是返回一个tuple，内容为<code>(image_tensor, img_attr_dict)</code>。整个函数的行为就是为了得到这两个元素。</p><ol><li>解析<code>self.xml_list[idx]</code>对应的xml，得到一个dict<blockquote><p>借助lxml的etree工具</p></blockquote></li><li>根据dict中的<code>filename</code>找到对应的图像文件，并转化tensor，得到<code>image_tensor</code><blockquote><p>借助PIL库的<code>Image.open()</code>函数</p></blockquote></li><li>根据dict中的其他信息找到boxes，label等标注信息，并转为tensor，最后组装成<code>img_attr_dict</code>。<blockquote><p>多目标情形时，box作为key，对应一个list of tensor，每个tensor对应一个box，label等同理。一个典型的包含两个box的dict如下：<br>{boxes:tensor(2x4),<br>labels:tensor(2x1),<br>image_id:tensor(1x1),<br>area:tensor(2x1),<br>iscrowd:tensor(2x1),<br>}</p></blockquote></li></ol><h4 id="len-方法"><a href="#len-方法" class="headerlink" title="__len__方法"></a><code>__len__</code>方法</h4><p>返回<code>self.xml_list</code>的长度即可</p><h4 id="one-more-thing"><a href="#one-more-thing" class="headerlink" title="one more thing"></a>one more thing</h4><p>当<code>torch.utils.data.DataLoader</code>按照既定的batch_size去获取和组装图像时，不能用默认的<code>collate_fn</code>。</p><p>因为这个默认的<code>collate_fn</code>只是简单的调用<code>torch.stack()</code>将b个[c, h, w]的tensor组合成一个[b, c, h, w]的tensor。但是这里索引到的是b个<code>(image_tensor, img_attr_dict)</code>，直接stack将得到一个</p><blockquote><p>[(image_tensor_0, img_attr_dict_0)<br> ···<br> (image_tensor_b, img_attr_dict_b)]</p></blockquote><p>这不是我们想要的。我们想要的是各个图像的像素值集中在一起，图像的标注信息集中在一起：</p><blockquote><p>[(image_tensor_0,<br>  …<br>  image_tensor_b),</p><p> (img_attr_dict_0,<br>  …,<br>  img_attr_dict_b)]</p></blockquote><p>所以要<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">collate_fn</span>(<span class="hljs-params">batch</span>):</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">tuple</span>(<span class="hljs-built_in">zip</span>(*batch))<br></code></pre></td></tr></table></figure></p>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
      <category>pytorch使用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>目标检测</tag>
      
      <tag>pytorch</tag>
      
      <tag>数据集</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch基础用法-预测</title>
    <link href="/2021/08/11/pytorch%E6%A0%B8%E5%BF%83%E7%94%A8%E6%B3%95-3/"/>
    <url>/2021/08/11/pytorch%E6%A0%B8%E5%BF%83%E7%94%A8%E6%B3%95-3/</url>
    
    <content type="html"><![CDATA[<h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs julia">transform = transforms.Compose(<br>        [transforms.Resize((<span class="hljs-number">32</span>, <span class="hljs-number">32</span>)),<br>         transforms.ToTensor(),<br>         transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))])<br><br><span class="hljs-literal">im</span> = Image.open(&#x27;<span class="hljs-number">1.</span>jpg&#x27;)<br><span class="hljs-literal">im</span> = transform(<span class="hljs-literal">im</span>)  <span class="hljs-comment"># [C, H, W]</span><br><span class="hljs-literal">im</span> = torch.unsqueeze(<span class="hljs-literal">im</span>, dim=<span class="hljs-number">0</span>)  <span class="hljs-comment"># [N, C, H, W]</span><br></code></pre></td></tr></table></figure><h2 id="模型定义"><a href="#模型定义" class="headerlink" title="模型定义"></a>模型定义</h2><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># 不需要to(device)吗？mark</span><br><span class="hljs-attr">net</span> = LeNet()<br></code></pre></td></tr></table></figure><h2 id="参数加载"><a href="#参数加载" class="headerlink" title="参数加载"></a>参数加载</h2><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"># 优化器也有同样的操作，可用于恢复训练<br>net.load<span class="hljs-constructor">_state_dict(<span class="hljs-params">torch</span>.<span class="hljs-params">load</span>(&#x27;Lenet.<span class="hljs-params">pth</span>&#x27;)</span>)<br></code></pre></td></tr></table></figure><h2 id="前向计算"><a href="#前向计算" class="headerlink" title="前向计算"></a>前向计算</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">with torch<span class="hljs-selector-class">.no_grad</span>():<br>    outputs = net(im)<br>    predict = torch<span class="hljs-selector-class">.max</span>(outputs, dim=<span class="hljs-number">1</span>)<span class="hljs-selector-attr">[1]</span><span class="hljs-selector-class">.data</span><span class="hljs-selector-class">.numpy</span>()<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
      <category>pytorch使用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch基础用法-训练</title>
    <link href="/2021/08/11/pytorch%E6%A0%B8%E5%BF%83%E7%94%A8%E6%B3%95-2/"/>
    <url>/2021/08/11/pytorch%E6%A0%B8%E5%BF%83%E7%94%A8%E6%B3%95-2/</url>
    
    <content type="html"><![CDATA[<h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><h3 id="引入数据集"><a href="#引入数据集" class="headerlink" title="引入数据集"></a>引入数据集</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 图片在送入网络之前要进行一定的变化才能适应网络入口的要求，比如尺寸一致化，张量化，归一化等</span><br>data_transform = &#123;<br>        <span class="hljs-string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(224),<br>                                     transforms.RandomHorizontalFlip(),<br>                                     transforms.ToTensor(),<br>                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),<br>        <span class="hljs-string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize((224, 224)), <br>                                   transforms.ToTensor(),<br>                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])&#125;<br><br><span class="hljs-comment"># 用pytorch官方的数据集，本地没有就去下载，需要指明是用数据集中的train部分，还是val部分</span><br>train_set = torchvision.datasets.CIFAR10(<span class="hljs-attribute">root</span>=<span class="hljs-string">&#x27;./data&#x27;</span>, <span class="hljs-attribute">train</span>=<span class="hljs-literal">True</span>, <span class="hljs-attribute">download</span>=<span class="hljs-literal">True</span>, <span class="hljs-attribute">transform</span>=transform)<br>val_set = torchvision.datasets.CIFAR10(<span class="hljs-attribute">root</span>=<span class="hljs-string">&#x27;./data&#x27;</span>, <span class="hljs-attribute">train</span>=<span class="hljs-literal">False</span>, <span class="hljs-attribute">download</span>=<span class="hljs-literal">False</span>, <span class="hljs-attribute">transform</span>=transform)<br><br><span class="hljs-comment"># 用自定义的数据集，前提是本地先下载好，并且建立好目录结构:</span><br><span class="hljs-comment"># image_path</span><br><span class="hljs-comment"># - train</span><br><span class="hljs-comment"># - class1</span><br><span class="hljs-comment">#- 1.png</span><br><span class="hljs-comment">#- 2.png</span><br><span class="hljs-comment"># - class2</span><br><span class="hljs-comment">#- 1.png</span><br><span class="hljs-comment">#- 2.png</span><br><span class="hljs-comment"># - val</span><br><span class="hljs-comment"># - class1</span><br><span class="hljs-comment">#- 1.png</span><br><span class="hljs-comment">#- 2.png</span><br><span class="hljs-comment"># - class2</span><br><span class="hljs-comment">#- 1.png</span><br><span class="hljs-comment">#- 2.png</span><br>train_dataset = datasets.ImageFolder(<span class="hljs-attribute">root</span>=os.path.join(image_path, <span class="hljs-string">&quot;train&quot;</span>), <span class="hljs-attribute">transform</span>=data_transform[<span class="hljs-string">&quot;train&quot;</span>])<br>validate_dataset = datasets.ImageFolder(<span class="hljs-attribute">root</span>=os.path.join(image_path, <span class="hljs-string">&quot;val&quot;</span>), <span class="hljs-attribute">transform</span>=data_transform[<span class="hljs-string">&quot;val&quot;</span>])<br><br><span class="hljs-comment"># 最后得到的是一个torch定义的class，按[]索引得到的是一个tuple，tuple元素是(tensor,id)，每个tensor对应一个张量化后的图片。</span><br></code></pre></td></tr></table></figure><h3 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 用num_workers个线程，将train_set打乱顺序，分成36个一份的batch</span><br>train_loader = torch.utils.data.DataLoader(train_set, <span class="hljs-attribute">batch_size</span>=36, <span class="hljs-attribute">shuffle</span>=<span class="hljs-literal">True</span>, <span class="hljs-attribute">num_workers</span>=0)<br><br><span class="hljs-comment"># 最后得到也是一个torch定义的class，被enumerate返回一个[tensor,tensor]</span><br><span class="hljs-comment"># 第一个tensor代表inputs，维度为[batch_size, c, h, w]</span><br><span class="hljs-comment"># 第二个为labels，维度为[batch_size]</span><br><span class="hljs-comment"># 也可以用iter将其加工成一个可迭代对象来访问其内容</span><br>train_data_iter = iter(train_loader)<br>img, label = train_data_iter.next()<br></code></pre></td></tr></table></figure><h2 id="工具定义"><a href="#工具定义" class="headerlink" title="工具定义"></a>工具定义</h2><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs nix">from model <span class="hljs-built_in">import</span> LeNet<br><span class="hljs-built_in">import</span> torch.optim as optim<br><br><span class="hljs-comment"># 模型定义</span><br><span class="hljs-attr">net</span> = LeNet()<br>net.to(device)<br><br><span class="hljs-comment"># 损失函数定义</span><br><span class="hljs-attr">loss_function</span> = nn.CrossEntropyLoss()<br><br><span class="hljs-comment"># 优化器定义</span><br><span class="hljs-comment"># 注意这里的优化器不是按照SGD/BGD/MBGD这样实现的，因为这种分类方式依赖的分类标准是batch_size的值。也就是说这里的SGD其实是基本的GD，然后如果实际的batch_size是1，那么才是真正的SGD。而且如果加上momentum参数，那么就是GD with Momentum。在定义优化器是需要指定的其实是参数更新的方式，而不是每次送入几个样本。</span><br><span class="hljs-attr">params</span> = [p for p <span class="hljs-keyword">in</span> model.parameters() <span class="hljs-keyword">if</span> p.requires_grad] <span class="hljs-comment">#可以在这里之前将某些层的参数锁定，从而实现冻结某些层不训练的效果</span><br><span class="hljs-attr">optimizer</span> = optim.Adam(params, <span class="hljs-attr">lr=0.0002)</span><br><span class="hljs-attr">optimizer</span> = optim.SGD(params, <span class="hljs-attr">lr=0.0002,</span> <span class="hljs-attr">momentum=0.1)</span><br><br><br><span class="hljs-comment"># 学习率调整器定义</span><br><span class="hljs-comment"># 在整个训练过程中，学习率保持一个定值效果往往不太好。因此一般用这个调整器来规划学习率随着epoch数量增加的变化策略。一种流行的做法是三角学习率，即学习率先增后减。开始阶段过大容易直接跑飞，结束阶段过大很难收敛，中间过程太小又会导致损失下降太慢，因此先增后减。</span><br><br>def f(x):<br>     <span class="hljs-keyword">if</span> x &gt;= warmup_iters:  <span class="hljs-comment"># 当迭代数大于给定的warmup_iters时，倍率因子为1</span><br>         return <span class="hljs-number">1</span><br>     <span class="hljs-attr">alpha</span> = float(x) / warmup_iters<br>     <span class="hljs-comment"># 迭代过程中倍率因子从warmup_factor -&gt; 1</span><br>     <span class="hljs-attr">fx</span> = warmup_factor * (<span class="hljs-number">1</span> - alpha) + alpha<br>     return fx<br><span class="hljs-attr">lr_warmpuper</span> = torch.optim.lr_scheduler.LambdaLR(optimizer, <span class="hljs-attr">lr_lambda=f)</span> <span class="hljs-comment">#第i次调用step方法时会将optimizer的学习率变为initial_alpha*f(i)</span><br><span class="hljs-attr">lr_scheduler</span> = torch.optim.lr_scheduler.StepLR(optimizer, <span class="hljs-attr">step_size=3,</span> <span class="hljs-attr">gamma=0.33)</span> <span class="hljs-comment">#每调用3次step方法，optimizer的学习率乘以一次0.33</span><br></code></pre></td></tr></table></figure><h2 id="核心循环"><a href="#核心循环" class="headerlink" title="核心循环"></a>核心循环</h2><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs nix">for epoch <span class="hljs-keyword">in</span> range(epochs):<br><span class="hljs-comment"># 训练循环</span><br>        <span class="hljs-comment"># 设置train模式，以打开BN，Dropout等训练专用的运算</span><br>        net.train()<br>        for data <span class="hljs-keyword">in</span> train_loader:<br>            images, <span class="hljs-attr">labels</span> = data<br>            <span class="hljs-comment"># 重置梯度变换量，防止过大？mark</span><br>            optimizer.zero_grad()<br>            <span class="hljs-comment"># 正向计算</span><br>            <span class="hljs-attr">outputs</span> = net(images.to(device))<br>            <span class="hljs-comment"># 计算损失</span><br>            <span class="hljs-attr">loss</span> = loss_function(outputs, labels.to(device))<br>            <span class="hljs-comment"># 反向传播</span><br>            loss.backward()<br>            <span class="hljs-comment"># 梯度更新 </span><br>    optimizer.step()<br>    <span class="hljs-keyword">if</span> <span class="hljs-attr">epoch==0:</span>  <span class="hljs-comment"># 第一轮使用warmup训练方式，每一个iteration调整一次学习率</span><br>               lr_warmuper.step()         <br>lr_scheduler.step()<br><span class="hljs-comment"># 验证循环</span><br>        <span class="hljs-comment"># 设置eval模式，以关闭BN，Dropout等训练专用的运算</span><br>        net.eval()<br>        <span class="hljs-comment"># 验证过程不需要自动存储梯度？mark</span><br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            for val_data <span class="hljs-keyword">in</span> val_loader:<br>                val_images, <span class="hljs-attr">val_labels</span> = val_data<br>                <span class="hljs-attr">outputs</span> = net(val_images.to(device))<br>                <span class="hljs-comment"># 求softmax向量的最大值的索引作为预测结果。</span><br>                <span class="hljs-attr">predict_y</span> = torch.max(outputs, <span class="hljs-attr">dim=1)[1]</span><br><span class="hljs-comment"># 模型保存</span><br>        <span class="hljs-keyword">if</span> val_accurate &gt; best_acc:<br>            <span class="hljs-attr">best_acc</span> = val_accurate<br>            <span class="hljs-comment"># 只保存权重，官方推荐这一种</span><br>            torch.save(net.state_dict(), save_weight_path)<br>            <span class="hljs-comment"># 同时保存和网络</span><br>            torch.save(net, save_model_path)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
      <category>pytorch使用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch基础用法-模型</title>
    <link href="/2021/08/11/pytorch%E6%A0%B8%E5%BF%83%E7%94%A8%E6%B3%95-1/"/>
    <url>/2021/08/11/pytorch%E6%A0%B8%E5%BF%83%E7%94%A8%E6%B3%95-1/</url>
    
    <content type="html"><![CDATA[<p>搭建一个CNN模型用作图像分类的过程，整体而言还是比较清晰的，主要分为模型、训练、预测三项工作。</p><p>第一项工作，模型搭建，套路也很清晰。新建一个继承于<code>nn.Module</code>的类，然后</p><ol><li>将网络层一一作为类的成员添加进来。这些网络层可以是<code>Conv2d</code>, <code>MaxPool2d</code>, <code>Linear</code>等<code>torch.nn</code>提供的基本模块，也可以是由这些基本模块组合成的自定义building blocks，如ResNet中的Residual单元，GoogLeNet中的Inception单元等。</li><li>定义网络层之间的连接关系，也就是<code>forward</code>函数的行为。</li></ol><p>另外，一种常见的做法是在定义网络层成员的时候，直接使用<code>nn.sequential</code>函数将多个网络层连接模块（比如一个classifier和一个features），然后在<code>forward</code>中连接这些模块即可。<br></p><p>BN, Dropout, Relu都可以作为一个网络层存在和连接。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> torch.nn as nn<br><span class="hljs-attribute">import</span> torch.nn.functional as F<br><br><span class="hljs-attribute">class</span> LeNet(nn.Module):<br>    <span class="hljs-comment"># 设定有哪些网络层，每层的尺寸</span><br>    <span class="hljs-attribute">def</span> __init__(self):<br>        <span class="hljs-attribute">super</span>(LeNet, self).__init__()<br>        <span class="hljs-attribute">self</span>.conv<span class="hljs-number">1</span> = nn.Conv<span class="hljs-number">2</span>d(<span class="hljs-number">3</span>, <span class="hljs-number">16</span>, <span class="hljs-number">5</span>)<br>        <span class="hljs-attribute">self</span>.pool<span class="hljs-number">1</span> = nn.MaxPool<span class="hljs-number">2</span>d(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>        <span class="hljs-attribute">self</span>.conv<span class="hljs-number">2</span> = nn.Conv<span class="hljs-number">2</span>d(<span class="hljs-number">16</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>)<br>        <span class="hljs-attribute">self</span>.pool<span class="hljs-number">2</span> = nn.MaxPool<span class="hljs-number">2</span>d(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>        <span class="hljs-attribute">self</span>.fc<span class="hljs-number">1</span> = nn.Linear(<span class="hljs-number">32</span>*<span class="hljs-number">5</span>*<span class="hljs-number">5</span>, <span class="hljs-number">120</span>)<br>        <span class="hljs-attribute">self</span>.fc<span class="hljs-number">2</span> = nn.Linear(<span class="hljs-number">120</span>, <span class="hljs-number">84</span>)<br>        <span class="hljs-attribute">self</span>.fc<span class="hljs-number">3</span> = nn.Linear(<span class="hljs-number">84</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-comment"># 设定层与层之间的怎样连接</span><br>    <span class="hljs-attribute">def</span> forward(self, x):<br>        <span class="hljs-attribute">x</span> = F.relu(self.conv<span class="hljs-number">1</span>(x))    # input(<span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>) output(<span class="hljs-number">16</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>)<br>        <span class="hljs-attribute">x</span> = self.pool<span class="hljs-number">1</span>(x)            # output(<span class="hljs-number">16</span>, <span class="hljs-number">14</span>, <span class="hljs-number">14</span>)<br>        <span class="hljs-attribute">x</span> = F.relu(self.conv<span class="hljs-number">2</span>(x))    # output(<span class="hljs-number">32</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>)<br>        <span class="hljs-attribute">x</span> = self.pool<span class="hljs-number">2</span>(x)            # output(<span class="hljs-number">32</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>)<br>        <span class="hljs-attribute">x</span> = x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">32</span>*<span class="hljs-number">5</span>*<span class="hljs-number">5</span>)       # output(<span class="hljs-number">32</span>*<span class="hljs-number">5</span>*<span class="hljs-number">5</span>)<br>        <span class="hljs-attribute">x</span> = F.relu(self.fc<span class="hljs-number">1</span>(x))      # output(<span class="hljs-number">120</span>)<br>        <span class="hljs-attribute">x</span> = F.relu(self.fc<span class="hljs-number">2</span>(x))      # output(<span class="hljs-number">84</span>)<br>        <span class="hljs-attribute">x</span> = self.fc<span class="hljs-number">3</span>(x)              # output(<span class="hljs-number">10</span>)<br>        <span class="hljs-attribute">return</span> x<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
      <category>pytorch使用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>流形(manifold)是个啥?</title>
    <link href="/2021/08/10/manifold%E6%98%AF%E4%B8%AA%E5%95%A5/"/>
    <url>/2021/08/10/manifold%E6%98%AF%E4%B8%AA%E5%95%A5/</url>
    
    <content type="html"><![CDATA[<p>今天看MobileNet v2，其中为了得到<strong><em>“在处理低维度的特征tensor时，Relu激活函数相比于Linear激活函数在激活前后会造成更多的特征丢失”</em></strong>这一推论，使用了流形（manifold）的概念。所以来看看流形到底是个啥：</p><p>数学语言的定义是：<strong><em>流形是局部具有欧几里得空间性质的空间，在数学中用于描述几何形体。物理上，经典力学的相空间和构造广义相对论的时空模型的四维伪黎曼流形都是流形的实例</em></strong>。牵扯出更多新概念，比较复杂。所以这里只看machine learning中的流形概念。如下图所示，</p><div align=center><img title="" src="/img/article/manifold.jpeg" width="60%" height="60%" align=center></div><p><br>图中的每一个点，严格来讲都是一个三维的点。但是又可以明显看出这些点在三维空间中的分布是非常有规律的，基本上都集中在一个三维曲面上。基于这种现象，我们将流形理解为，高维空间中一个可变换成低维空间的子空间，例如上图，这个曲面作为一个三维曲面其实可以变换为一个二维平面。</p><p>对于机器学习和深度学习领域的数据，一般数据因为固有的特性（比如在不同光照条件下的同一张人脸的灰度图像），导致无法“填满”整个高维空间。例如如果数据只能出现在三维空间中的一个球面上。那这个球面以外的空间永远不会有数据点。而一个表面我们完全可以只用两个参数来表示(经度、维度)。</p><p>这样在聚类求样本间的相似距离时，就有了两种方式。一种是在流形的高维空间中求，即图中直线。另一种是在流形展开后的低维空间中求，即图中的曲线。具体用途，后面谈到再说吧。mark</p><p>参考链接：<br>[1] <a href="https://www.zhihu.com/question/24015486/answer/194284643">https://www.zhihu.com/question/24015486/answer/194284643</a></p>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>流形</tag>
      
      <tag>manifold</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MobileNet v2</title>
    <link href="/2021/08/08/2-MobileNet/"/>
    <url>/2021/08/08/2-MobileNet/</url>
    
    <content type="html"><![CDATA[<h2 id="背景简介"><a href="#背景简介" class="headerlink" title="背景简介"></a>背景简介</h2><p>2018年Google团队在v1的基础上提出的改进版。核心思想仍然是DW卷积，但是这次借鉴了ResNet的残差结构，提高了性能。</p><h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><h3 id="Inverted-Residual"><a href="#Inverted-Residual" class="headerlink" title="Inverted Residual"></a>Inverted Residual</h3><p>所谓倒残差结构，其实就是在ResNet残差结构的基础上做了一些修改。首先看以下简图：</p><div align=center><img title="" src="/img/net/ir.png" width="70%" height="70%" align=center></div><p><br>对于残差结构而言，三个卷积层每一层卷积核的个数一般依次为[64, 64, 256]这样，先对具有256个通道的输入进行降维，然后3x3卷积 with SAME PADDING, 尺寸和通道都不变，最后再用1x1卷积进行升维。就三个卷积层的4个计算对象而言，通道数依次为[256, 64, 64, 256]，两头大中间小。</p><p>对于倒残差结构则刚好相反，它先升维，再用DW卷积保持深度，然后再降维输出，呈现两头小中间大的形状，因此称之为倒残差。</p><p>具体来看倒残差结构的结构和参数，如下表所示：<br><br><div align=center><img title="" src="/img/net/ir2.png" width="60%" height="60%" align=center></div><br></p><ol><li>第一层为PW卷积+BN+RELU6，其中卷积层参数为1F-1S-SP-tk#，k为单元输入的通道数；</li><li>第二层为DW卷积+BN+RELU6，参数为3F-sS-SP, 当s=1或2；</li><li>第三层为PW卷积+BN+Linear，卷积层参数为1F-1S-SP-k’#，k’为单元输出的通道数；</li></ol><p>综上，一个倒残差单元的参数有k，t，s，k’四个。4个计算对象的深度分别为[k, tk, tk, k’]。</p><h3 id="Relu6激活函数"><a href="#Relu6激活函数" class="headerlink" title="Relu6激活函数"></a>Relu6激活函数</h3><p>倒残差结构相对于残差结构的另外一个不同点，其实就是在x=6处饱和的Relu函数。</p><h3 id="Linear激活函数"><a href="#Linear激活函数" class="headerlink" title="Linear激活函数"></a>Linear激活函数</h3><p>倒残差单元输出之前进行的不是Relu激活，而是线性激活。因为，据称，在对通道数较少的tensor进行激活时，Relu会丢失更多信息。而每个倒残差单元又是两头小，因此最后的激活函数使用了简单的线性函数。另外，由于线性激活函数的表达式就是$y = x$，所以线性激活=不做激活。</p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>整个网络来看，先用倒残差单元串联组成单元层，单元层和普通卷积层、平均池化层、FC层再串联组成网络。</p><div align=center><img title="" src="/img/net/mbv2.png" width="50%" height="50%" align=center></div><p>看懂上表首先要明确一个单元层的4个参数t,c,n,s的含义：</p><ul><li>t, 对应倒残差单元的参数t</li><li>c, 对应本单元层中的第一个倒残差单元的k’参数，以及后续的倒残差单元的k和k’参数。就是说对于一个单元层，计算对象的深度依次为[input, input x t, input x t, c]、[c, c x t, c x t, c]、[c, c x t, c x t, c]……</li><li>n, 将几个倒残差单元串联起来形成本单元层</li><li>s，对应本单元层中第一个倒残差单元的s参数，其余单元的s参数都为1</li></ul><p>另外，还要注意以下3个细节：</p><ol><li>每个单元层的第一个倒残差单元与ResNet中的处理方式不一样，这里是放弃shortcut而不是在shortcut上插入一个1x1卷积来进行深度的一致化。</li><li>当每个单元层的中间单元，不满足输入输出的tensor形状、深度一致的条件时，也不进行shortcut。</li><li>对于t=1的单元层，取消其倒残差单元的第一个PW卷积，因为通道数量并不需要变化。</li></ol><h2 id="其他内容"><a href="#其他内容" class="headerlink" title="其他内容"></a>其他内容</h2><ol><li>倒残差结构的三个特点为什么work？mark</li><li>DW卷积在pytorch中的实现是通过控制<code>nn.conv2D()</code>构造函数中的<code>groups</code>参数来实现。<code>groups = 1</code>时就普通的卷积，<code>groups = input_chs</code>时就是DW卷积。</li></ol>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
      <category>经典网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>神经网络</tag>
      
      <tag>卷积神经网络</tag>
      
      <tag>CNN</tag>
      
      <tag>经典网络</tag>
      
      <tag>MobileNet</tag>
      
      <tag>Residual结构</tag>
      
      <tag>Inverted Residual结构</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MobileNet v1</title>
    <link href="/2021/08/08/MobileNet/"/>
    <url>/2021/08/08/MobileNet/</url>
    
    <content type="html"><![CDATA[<h2 id="背景简介"><a href="#背景简介" class="headerlink" title="背景简介"></a>背景简介</h2><p>由Google团队于2017年提出，专注于移动端和嵌入式设备。采用Depthwise卷积，大幅减少参数量，虽然效果有一些折扣，但是可以接受。</p><h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><h3 id="DW卷积"><a href="#DW卷积" class="headerlink" title="DW卷积"></a><strong>DW卷积</strong></h3><p>先来回忆以下常规的卷积是怎样的，如下图所示。</p><div align=center><img title="" src="/img/net/mobilenet1.png" width="70%" height="70%" align=center></div><p>而DW卷积呢，其实就是最符合直觉的那种卷积。就是每个卷积核的深度不是和上一层输出相同，而是等于1。这意味着：</p><ul><li>卷积之后不再做跨深度的求和</li><li>每一个DW卷积层的#参数必然等于输入tensor的深度，因为要保证输入tensor的每一个通道都有一个1层的卷积核去和它运算</li><li>经过DW卷积之后得到的输出，深度不变</li></ul><div align=center><img title="" src="/img/net/mobilenet2.png" width="70%" height="70%" align=center></div><h3 id="PW卷积"><a href="#PW卷积" class="headerlink" title="PW卷积"></a><strong>PW卷积</strong></h3><p>DW卷积一看就是个瘸腿儿的机制，搞来搞去没法manipulate tensor的深度啊，所以必须伴随这PW卷积使用。PW卷积就是常规1x1的卷积，它的特点是不改变tensor的尺寸，只改变tensor的深度。这么一来跟DW卷积就完美配合了——先对tensor进行DW卷积改变尺寸，然后进行PW卷积对DW的输出进行跨通道加权求和，每个PW卷积核得到一个2维的tensor，这样，通过设置不同的卷积核个数即可控制最终输出的通道数。</p><div align=center><img title="" src="/img/net/mobilenet3.png" width="70%" height="70%" align=center></div><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><div align=center><img title="" src="/img/net/mbv1.png" width="60%" height="60%" align=center></div><p>主要就是DW层和PW层的堆叠。另外，额外设有两个可调的超参数$\alpha$和$\beta$，前者是每一层的PW卷积核数量基于上表中数量的系数，后者是基于224x224的输入图像分辨率的系数。</p><h2 id="其他内容"><a href="#其他内容" class="headerlink" title="其他内容"></a>其他内容</h2><ol><li>实际使用发现，经常有很多DW卷积核的元素值为0，造成浪费，原因后面再补充吧。mark</li></ol>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
      <category>经典网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>神经网络</tag>
      
      <tag>卷积神经网络</tag>
      
      <tag>CNN</tag>
      
      <tag>经典网络</tag>
      
      <tag>MobileNet</tag>
      
      <tag>DW卷积</tag>
      
      <tag>PW卷积</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ResNet</title>
    <link href="/2021/08/08/ResNet/"/>
    <url>/2021/08/08/ResNet/</url>
    
    <content type="html"><![CDATA[<h2 id="背景简介"><a href="#背景简介" class="headerlink" title="背景简介"></a>背景简介</h2><p>来自2015年的微软实验室，He Kaiming/Ren Shaoqing/Zhang Xiangyu等，啥啥啥都第一名…不用dropout了，引入BN，提出residual以应对退化问题，支持上千层的网络结构。</p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><h3 id="整体结构"><a href="#整体结构" class="headerlink" title="整体结构"></a>整体结构</h3><p>网络由一种叫做residual的building block串行组建而成，整体结构见下表：</p><div align=center><img title="" src="/img/net/resnet.png" width="100%" height="100%" align=center></div><h3 id="常规的Residual单元"><a href="#常规的Residual单元" class="headerlink" title="常规的Residual单元"></a>常规的Residual单元</h3><p>如下图所示，常规的Residual有两种规格，前者用于层数较少的网络，后者用于层数较多的网络。</p><div align=center><img title="" src="/img/net/residual1.png" width="80%" height="80%" align=center></div><p>Residual特点如下：</p><ol><li>为了实现shortcut结构，必须保证单元的输入与输出尺寸完全一致，包括维度。这样才能做tensor的逐元素相加。</li><li>最后一个relu是在逐元素相加之后进行的。</li><li>和Inception单元一样，每个卷积层的FSP都是确定的，其中F看位置取1或3，S=1，P=SAME PADDING。因此一个Residual单元的配置参数只有每个卷积层的#。</li></ol><h3 id="特殊的Residual单元"><a href="#特殊的Residual单元" class="headerlink" title="特殊的Residual单元"></a>特殊的Residual单元</h3><p>在分界线处的Residual单元还要额外承担tensor尺寸调整的任务，因此其结构相对于常规结构要增加一些变化。</p><div align=center><img title="" src="/img/net/residual2.png" width="60%" height="60%" align=center></div><div align=center><img title="" src="/img/net/residual3.png" width="60%" height="60%" align=center></div><p>首先是在shortcut上增加一个1F2S0P?#的卷积层对单元输入进行尺寸调整。另外是主线上的第一个卷积层的S变为2，进行尺寸调整。</p><blockquote><p>上图是按照pytorch中的实现，是在第2个卷积层做的下采样，实测效果更好，所以这么用了。</p></blockquote><h2 id="其他内容"><a href="#其他内容" class="headerlink" title="其他内容"></a>其他内容</h2><ol><li><strong>Residual结构为什么有效？</strong><br>xxxx</li></ol>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
      <category>经典网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>神经网络</tag>
      
      <tag>卷积神经网络</tag>
      
      <tag>CNN</tag>
      
      <tag>经典网络</tag>
      
      <tag>Residual结构</tag>
      
      <tag>ResNet</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>argparse的基本用法</title>
    <link href="/2021/08/06/argparse%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/"/>
    <url>/2021/08/06/argparse%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h3 id="用途及原理"><a href="#用途及原理" class="headerlink" title="用途及原理"></a>用途及原理</h3><p>为python脚本运行时所添加额外命令行参数提供解释。大致原理是为一个parser对象添加一些属性，然后这个parser对象在接受一系列参数（默认是命令行参数）之后，就拥有了一系列属性，然后程序就可以用这些属性来做事了。就是说，信息从命令行传递到了脚本内。</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># 创建对象</span><br>import argparse<br>parser = argparse.ArgumentParser()<br><br><span class="hljs-comment"># 添加属性</span><br>parser.add_argument(<span class="hljs-string">&#x27;integers&#x27;</span>, <span class="hljs-regexp">//</span>位置型属性，与添加顺序有关<br>    metavar=<span class="hljs-string">&#x27;N&#x27;</span>,  <span class="hljs-regexp">//</span>帮助文档中的示例显示内容<br>    type=int,  <span class="hljs-regexp">//</span>这个属性的类型<br>    nargs=<span class="hljs-string">&#x27;+&#x27;</span>, <span class="hljs-regexp">//</span>这个属性的值为自适应长度的列表<br>                    help=<span class="hljs-string">&#x27;an integer for the accumulator&#x27;</span>) <span class="hljs-regexp">//</span>与这个属性相关的帮助信息<br>parser.add_argument(<span class="hljs-string">&#x27;--sum&#x27;</span>,  <span class="hljs-regexp">//</span>flag型属性，位置无关<br>                    dest=<span class="hljs-string">&#x27;accumulate&#x27;</span>, <span class="hljs-regexp">//</span>属性的正式名称，有了这个之后sum这个名称就不能用了，没有的话sum是正式名称<br>    action=<span class="hljs-string">&#x27;store_const&#x27;</span>, <span class="hljs-regexp">//</span>与下面的const配合使用，定义--sum在命令行中出现时，sum属性的赋值行为，这里是accumulate = sum<br>                    const=sum, <br>    default=max, <span class="hljs-regexp">//</span>定义当--sum未出现时sum属性的赋值行为，这里是accumulate = max。<br>                    help=<span class="hljs-string">&#x27;sum the integers (default: find the max)&#x27;</span>)<br><br><span class="hljs-comment"># 接受参数</span><br>args = parser.parse_args()<br><br><span class="hljs-comment"># 使用参数</span><br>print(args.accumulate(args.integers)) <span class="hljs-regexp">//</span>解析后等价于print(sum([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]))<br></code></pre></td></tr></table></figure><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><p>[1] <a href="https://towardsdatascience.com/a-simple-guide-to-command-line-arguments-with-argparse-6824c30ab1c3">https://towardsdatascience.com/a-simple-guide-to-command-line-arguments-with-argparse-6824c30ab1c3</a><br>[2] <a href="https://www.huaweicloud.com/articles/208c06ca1f4aba8dfd9219c6e2c72b23.html">https://www.huaweicloud.com/articles/208c06ca1f4aba8dfd9219c6e2c72b23.html</a><br>[3] <a href="https://blog.csdn.net/liuweiyuxiang/article/details/82918911">https://blog.csdn.net/liuweiyuxiang/article/details/82918911</a><br>[4] <a href="https://docs.python.org/zh-cn/3/library/argparse.html">https://docs.python.org/zh-cn/3/library/argparse.html</a></p>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>python笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>argparse</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GoogLeNet</title>
    <link href="/2021/08/03/GoogleNet/"/>
    <url>/2021/08/03/GoogleNet/</url>
    
    <content type="html"><![CDATA[<h2 id="背景简介"><a href="#背景简介" class="headerlink" title="背景简介"></a>背景简介</h2><p>2014年Google团队提出，当年的ImageNet分类任务第一名（第二名是VGG）。其中的Inception结构和辅助分类器的概念很有启发性和创造性。</p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><h3 id="整体结构"><a href="#整体结构" class="headerlink" title="整体结构"></a>整体结构</h3><p>构建起整个网络的building blocks有5种：</p><ol><li>常规的卷积层，默认以RELU为激活函数，SAME padding</li><li>常规的池化层，包括最大池化和平均池化</li><li>Inception单元，共计3层9个，具体结构后面解释</li><li>辅助分类器2个，具体结构后面解释</li><li>最终输出的softmax FC层</li></ol><div align=center><img title="" src="/img/net/googlenet.png" width="90%" height="90%" align=center></div><p><br>如上图所示，常规卷积层、池化层、softmax FC层的结构参数已标出。各个Inception单元的参数可参照下表得出，表头的解释详见<a href="https://towardsdatascience.com/deep-learning-googlenet-explained-de8861c82765">这里</a>。辅助分类器的结构是固定的，在后面会讲。</p><blockquote><p>第一个maxpool之后，第二个maxpool之前还各有一个LRN操作，但据说用处不大，就省略了。</p></blockquote><div align=center><img title="" src="/img/net/googlenet_table.png" width="100%" height="100%" align=center></div><h3 id="Inception单元"><a href="#Inception单元" class="headerlink" title="Inception单元"></a>Inception单元</h3><p>理解GoogLeNet的网络结构首先要理解Inception结构，整个GoogLeNet主要由若干个Inception单元的组合。</p><div align=center><img title="" src="/img/net/inception.png" width="80%" height="80%" align=center></div><p>从上图可以看出，对于一个Inception单元而言，input通过4个并联的卷积运算分支产生4路输出。这4个分支的卷积核各不相同，意味着从input提取出不同尺度的特征，这使得训练出来的模型能够同时兼顾一副图像中不同尺度的特征。并且，4路输出的tensor的宽和高是相同的，因此可以将其沿着深度方向堆叠起来，形成整个Inception单元的输出。看下图更直观的说明了这个过程</p><div align=center><img title="" src="/img/net/inception_eg.png" width="80%" height="80%" align=center></div><p>具体来看这4路分支：</p><ul><li>1x1卷积，调整深度，宽和高相对于input不变。</li><li>1x1卷积 + 3x3卷积，其中会造成尺寸缩减的3x3卷积采用SAME padding，同样保持了尺寸。</li><li>1x1卷积 + 5x5卷积，其中会造成尺寸缩减的5x5卷积采用SAME padding，同样保持了尺寸。</li><li>3x3池化 + 1x1卷积，其中池化层做了SAME padding。<strong><em>——先后顺序为什么这么突出？mark</em></strong></li></ul><blockquote><p>另外值得注意的是，在对于一个Inception单元而言，4个支路的卷积核数量一般是配置参数，而卷积核的尺寸是固定的。这意味着一个Inception单元的参数应该为上述6个卷积核的个数+本单元的输入的深度。</p></blockquote><h3 id="辅助分类器"><a href="#辅助分类器" class="headerlink" title="辅助分类器"></a>辅助分类器</h3><p>另外一个特殊之处是，GoogLeNet在进行模型训练时（预测时没有）在中间层也进行了两次结果输出。</p><h4 id="辅助分类器的结构"><a href="#辅助分类器的结构" class="headerlink" title="辅助分类器的结构"></a>辅助分类器的结构</h4><p>这两个辅助分类器的结构是相同的：</p><div align=center><img title="" src="/img/net/inception_aux.png" width="20%" height="20%" align=center></div><ul><li>首先是一个5x5,s=3的平均池化</li><li>然后接一个1x1卷积层，卷积核数量128</li><li>然后展平、dropout、接第一个FC（激活函数为RELU）</li><li>然后在dropout，接第二个FC(激活函数为softmax)</li></ul><p>第一层FC有1024个神经元，第二层为输出层，神经元数量取决于class_num。另外值得注意的是，两个辅助分类器的输入tensor的形状是相同的，只有深度不同，都是[batch, d, 4, 4]。经过相同的池化层处理后，形状继续保持一致。再经过相同的1x1卷积层处理后，深度也变为一致的。因此可以看出这里的1x1卷积层是为了rectify辅助分类器的输入，使其适配性更强。</p><h4 id="对应的损失函数"><a href="#对应的损失函数" class="headerlink" title="对应的损失函数"></a>对应的损失函数</h4><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">loss0 = loss<span class="hljs-constructor">_function(<span class="hljs-params">logits</span>, <span class="hljs-params">labels</span>.<span class="hljs-params">to</span>(<span class="hljs-params">device</span>)</span>)<br>loss1 = loss<span class="hljs-constructor">_function(<span class="hljs-params">aux_logits1</span>, <span class="hljs-params">labels</span>.<span class="hljs-params">to</span>(<span class="hljs-params">device</span>)</span>)<br>loss2 = loss<span class="hljs-constructor">_function(<span class="hljs-params">aux_logits2</span>, <span class="hljs-params">labels</span>.<span class="hljs-params">to</span>(<span class="hljs-params">device</span>)</span><br>loss = loss0 + loss1<span class="hljs-operator"> * </span><span class="hljs-number">0.3</span> + loss2<span class="hljs-operator"> * </span><span class="hljs-number">0.3</span><br></code></pre></td></tr></table></figure><p>三个分类器的输出分别计算loss，然后加权之后的和作为整个模型的loss。</p><h4 id="实现时的trick"><a href="#实现时的trick" class="headerlink" title="实现时的trick"></a>实现时的trick</h4><p>由于最终的结果只看主分类器的，那么就带了两个问题：</p><ol><li>训练过程的验证时不需要进行辅助分类器的计算，此时通过在模型的forward方法中借助<code>self.training</code>设定即可。该属性在<code>net.train()</code>时为true，<code>net.eval()</code>时为false；</li><li>实际部署时，不仅不需要辅助分类器的计算，连辅助分类器的结构都不需要。此时，首先通过设定一个额外的flag，在model class中不构建辅助分类器。然后还要解决保存训练时保存的权重文件比此时的网络结构的参数多的问题。这个通过在<code>model.load_state_dict(torch.load(PATH),strict=False)</code>增加strict参数来实现。</li></ol><h2 id="其他内容"><a href="#其他内容" class="headerlink" title="其他内容"></a>其他内容</h2><ul><li>Inception结构中的卷积层默认包含一个RELU。</li><li>池化层跟1x1卷积刚好相反，它不改变tensor的深度，只改变tensor的宽和高，因此两者可以组成tensor尺寸manipulation的一对基。</li><li>tensor的堆叠在pytorch中用<code>torch.cat()</code>实现。</li></ul>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
      <category>经典网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>神经网络</tag>
      
      <tag>卷积神经网络</tag>
      
      <tag>CNN</tag>
      
      <tag>经典网络</tag>
      
      <tag>GoogLeNet</tag>
      
      <tag>Inception结构</tag>
      
      <tag>辅助分类器</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VGGnet</title>
    <link href="/2021/08/01/VGGnet/"/>
    <url>/2021/08/01/VGGnet/</url>
    
    <content type="html"><![CDATA[<h2 id="背景简介"><a href="#背景简介" class="headerlink" title="背景简介"></a>背景简介</h2><p>牛津VGG团队2014年提出，ImageNet分类任务第二名，定位任务第一名。结构简单，配置丰富，被广泛用作backbone。</p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>原作有5种配置，分别为11层，13层，16层-1，16层-3，19层。统计层数时不统计池化层和softmax，只统计有weight的网络层。</p><div align=center><img title="" src="/img/net/vgg.png" width="80%" height="80%" align=center></div><h2 id="网络特点"><a href="#网络特点" class="headerlink" title="网络特点"></a>网络特点</h2><ul><li>所有的卷积核尺寸一致，均采用3x3。</li><li><p>引入<strong>感受野（receptive field）</strong>的概念，利用小卷积核的堆叠代替大卷积核，从而减少了参数量。所谓感受野，简单说就是对于某一层的输出的矩阵中的一个元素而言，它对应直接输入层中的那一片区域，就叫做它在那一层的感受野，然后依次向前递归。<br><div align=center><img title="" src="/img/net/rf.png" width="60%" height="60%" align=center></div><br>VGG网络对于这个概念，使用了这么一个推论：<strong>相同的感受野得到的特征表达的含义应该是同质的。</strong>因此，在同一个感受野上进行一层大卷积核的卷积操作，和进行多层小卷积核的卷积操作，最终得到的特征应该是同质的。具体操作是，用两层3x3的卷积来表达一层5x5的卷积效果，用三层3x3的卷积来表达一层7x7的卷积效果。由此引入一个计算过程，即如何计算某一层L在其之前某层N上的感受野尺寸。计算公式如下：</p><blockquote><script type="math/tex; mode=display">RF_n = (RF_{n+1} - 1) * s + f</script></blockquote><p>该公式其中就是卷积尺寸计算公式的移项，可以理解为已知卷积后的尺寸为1x1，求卷积前的尺寸。并且，不考虑padding，为什么呢？因为考虑padding考虑的是全局尺寸，而感受野讨论的是局部尺寸。</p></li><li><p>参数量减少的原理</p><blockquote><script type="math/tex; mode=display">3*3*3 = 27 < 49 = 7*7</script></blockquote></li></ul>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
      <category>经典网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>神经网络</tag>
      
      <tag>卷积神经网络</tag>
      
      <tag>CNN</tag>
      
      <tag>经典网络</tag>
      
      <tag>VGGnet</tag>
      
      <tag>感受野</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>预测结果评价的量化指标</title>
    <link href="/2021/08/01/%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E8%AF%84%E4%BB%B7%E7%9A%84%E9%87%8F%E5%8C%96%E6%8C%87%E6%A0%87/"/>
    <url>/2021/08/01/%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E8%AF%84%E4%BB%B7%E7%9A%84%E9%87%8F%E5%8C%96%E6%8C%87%E6%A0%87/</url>
    
    <content type="html"><![CDATA[<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="二分类情形下的P-N-T-F概念"><a href="#二分类情形下的P-N-T-F概念" class="headerlink" title="二分类情形下的P/N/T/F概念"></a>二分类情形下的P/N/T/F概念</h3><ol><li>Positive/Negative：样本空间的原始分类;</li><li>True/False，预测结果与样本原始属性的偏差情况，即P-&gt;P/N-&gt;N为T，P-&gt;N/N-&gt;P为F;因此，T和F需要再细分为：<ul><li>TP：P-&gt;P(正类被预测为正类，真正类)</li><li>TN：N-&gt;N(负类被预测为负类，真负类)</li><li>FP：N-&gt;P(负类被预测为正类，假正类)</li><li>FN：P-&gt;N(正类被预测为负类，假负类）</li></ul></li></ol><h3 id="多分类情形下的P-N-T-F概念"><a href="#多分类情形下的P-N-T-F概念" class="headerlink" title="多分类情形下的P/N/T/F概念"></a>多分类情形下的P/N/T/F概念</h3><p>多分类时需要针对单独每一个类别进行分析，然后再综合分析。比如，对于一个三分类情形，先分析类别A，则A类为Positive，B类和C类为Negative。然后得到A的混淆矩阵：</p><div class="table-container"><table><thead><tr><th style="text-align:center">原始\预测</th><th style="text-align:center">a</th><th style="text-align:center">非a</th></tr></thead><tbody><tr><td style="text-align:center"><strong>A</strong></td><td style="text-align:center">$TP_A$</td><td style="text-align:center">$FN_A$</td></tr><tr><td style="text-align:center"><strong>非A</strong></td><td style="text-align:center">$FP_A$</td><td style="text-align:center">$TN_A$</td></tr></tbody></table></div><h2 id="变量命名-personal"><a href="#变量命名-personal" class="headerlink" title="变量命名(personal)"></a>变量命名(personal)</h2><p>若以X为样本中X类数量，M为样本总数，x为预测结果中的X类数量，T为正确预测数量，F为错误预测数量，综上有：</p><ul><li>$M = A+B+C = a+b+c = T + F$（不解释）</li><li>$T = TP_A+TP_B+TP_C$（不解释）</li><li>$F = FP_A+FP_B+FP_C = FN_A+FN_B+FN_C$（不解释） </li><li>$A = TP_A+FN_A$（样本中的A类数量=真A类数量+假非A类数量）</li><li>$a = TP_A+FP_A$（预测中的A类数量=真A类数量+假A类数量）</li></ul><p>综合来看还是比较复杂的，实操时最好先把混淆矩阵算出来，然后再进行下面基本指标和高级指标的计算。</p><h2 id="基本指标"><a href="#基本指标" class="headerlink" title="基本指标"></a>基本指标</h2><ul><li><strong>accuracy</strong>: 模型做正确预测的能力 <script type="math/tex; mode=display">\frac{T}{M}</script></li><li><strong>recall/hit-rate/TruePositiveRate/sensitivity</strong>: 原始样本中的A类有多少被正确预测出来 <script type="math/tex; mode=display">\frac{TP_A}{A}</script></li><li><strong>precision</strong>: 找到的A类中有多少是真正的A类 <script type="math/tex; mode=display">\frac{TP_A}{a}</script></li><li><strong>fall-out/FalsePositiveRate</strong>: 原始样本中的非A类有多少被错误地预测成了A类 <script type="math/tex; mode=display">\frac{FN_A}{B+C}</script></li><li><strong>F1 score</strong>: precision和recall的调和平均数<script type="math/tex; mode=display">\frac{2}{\frac{1}{precision}+\frac{1}{recall}}</script></li></ul><p>综上可以看出，除了accuracy之外，其他4个指标都与类别强相关，这意味着对于每一类别都有这4个指标。那么如何综合不同类别的基本指标，从而得到对于一个模型而言的全局指标呢？常用以下三种方式：</p><ol><li>Macro-Average : 求各个类别指标的算数平均值作为全局指标。举个例子<script type="math/tex; mode=display">presicion = \frac{precision_A+precision_B+precision_C}{3}= \frac{1}{3}(\frac{TP_A}{a}+\frac{TP_B}{b}+\frac{TP_C}{c})</script></li><li>Micro-Average : 看下面例子就明白，此时全局precision和recall是相同的。<script type="math/tex; mode=display">precision = \frac{TP_A+TP_B+TP_C}{a+b+c} = \frac{TP_A+TP_B+TP_C}{M}</script></li><li>Weighted-Average : 求各个类别指标的加权平均值作为全局指标，权重为该类别在样本空间中的比例。<script type="math/tex; mode=display">precision = precision_A * \frac{A}{M} + precision_B * \frac{B}{M} +precision_C * \frac{C}{M}</script></li></ol><h2 id="高级指标"><a href="#高级指标" class="headerlink" title="高级指标"></a>高级指标</h2><h3 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a><strong>ROC曲线</strong></h3><ul><li>横轴为FPR，样本中非A类多少被错误预测成了A类</li><li>纵轴为TPR，样本中A类多少被正确预测成了A类（也就是recalll）</li><li>0-1之间选择不同的分类阈值，从而得到同一分类器的不同subversion，因此ROC曲线上一个点(x,y)的含义为：对于某个特定的分类阈值，有y%的A类被成功预测成了A类，但代价是x%的非A类也被预测成了A类。</li><li>我们肯定希望x越小越好，y越大越好（所有的飞机都被找到，大雁及其他鸟类还不被当成飞机），从图形上来看就是尽量靠近左上角。</li><li><strong>ROC-AUC值</strong>，ROC曲线对x轴的积分，对于同样的x值，y值越大，面积越大，越符合我们的期望，也就是分类效果越好。</li></ul><h3 id="P-R曲线"><a href="#P-R曲线" class="headerlink" title="P-R曲线"></a><strong>P-R曲线</strong></h3><ul><li>横轴为recall（真A类占全体样本A类的比例）</li><li>纵轴为precision（真A类占全体预测A类的比例）</li><li>0-1之间选择不同的分类阈值，从而得到同一分类器的不同subversion，因此P-R曲线上一个点(x,y)的含义为：对于某个特定的分类阈值，有x%的A类被成功预测成了A类(被召回)，并且这些真A类占a的比例为y%。</li><li>我们希望x和y都越大越好，因为这意味着所有的飞机都被找到的同时，被认为是飞机的还真就都是飞机。从图形上来看就是尽量靠近右上角。</li><li><strong>PR-AUC值</strong>，即所谓的<strong>AP</strong>值，P-R曲线对x轴的积分，也是越大越好。</li><li><strong>mAP</strong>，计算出所有类别的<strong>AP</strong>值，然后计算算数平均数，即为整个模型的mAP值。</li></ul><h2 id="其他话题"><a href="#其他话题" class="headerlink" title="其他话题"></a>其他话题</h2><h3 id="mAP计算步骤"><a href="#mAP计算步骤" class="headerlink" title="mAP计算步骤"></a>mAP计算步骤</h3><ol><li>取得模型预测结果，一般为一个prediction score</li><li>选取一个threshold，将prediction score转化为PNTF</li><li>依次统计每个类别的混淆矩阵</li><li>根据每个类别的混淆矩阵计算出对应的precision和recall</li><li>更换threshold，重复2-4</li><li>所有的threshold完成后，即可得到每个类别各自的PR曲线，求AUC面积得到各个类别的AP值</li><li>求所有类别AP值的算数平均数，即可得到mAP</li></ol><h3 id="目标检测中的mAP计算"><a href="#目标检测中的mAP计算" class="headerlink" title="目标检测中的mAP计算"></a>目标检测中的mAP计算</h3><p>目标检测中不仅要对比原始标签和预测结果标签的偏离情况，还要计算Bounding Box的IOU值。在预测前后标签相同的前提下，将IOU值代替分类任务中的prediction score来进行后续计算。</p><h3 id="ROC曲线和PR曲线对比"><a href="#ROC曲线和PR曲线对比" class="headerlink" title="ROC曲线和PR曲线对比"></a><strong>ROC曲线和PR曲线对比</strong></h3><ol><li>选定一个分类阈值，那么此时的recall是相同的，那么对于达到这个recall效果:<ul><li>ROC曲线中衡量的是FPR（FP/N），也就是样本中的这么多大雁有多少被错当成了飞机</li><li>PR曲线中衡量的是precision，也就是预测中的这么多飞机有多少真的是飞机（或者说有多少其实是大雁）</li></ul></li><li>如果非A类样本增加：<ul><li>预测结果中，由于分类模型没有变，所以将B/C类错误地预测为A类的数量和B/C类正确地预测为B/C必然会同时增加，因此FPR的分子分母同时变大，总体变化不会很大</li><li>预测结果中，真A类数量不会变化，但是假A类数量必然增加，precision总体会变小</li></ul></li><li>如果A类样本增加：<ul><li>B/C类数量不会发生变化，假A类数量也不会发生变化，因此FPR不变 假A类数量不变，真A类数量必然增加，precision总体会变大</li><li>综上所述，我们说，样本的分布情况会影响PR曲线形状，但（基本）不会影响ROC曲线形状；也因此，样本分布极不均匀时，优先选择PR曲线评估分类模型的性能（ROC曲线特喵的不受样本分布影响啊）</li><li>归根结底，还是因为precision这个指标受样本分布影响太大，如果样本中A类占巨大多数，那么对A类进行预测的precision很容易显得很高，vice versa。</li></ul></li></ol><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>[1] <a href="https://zhuanlan.zhihu.com/p/147663370">https://zhuanlan.zhihu.com/p/147663370</a><br>[2] <a href="https://blog.paperspace.com/mean-average-precision/">https://blog.paperspace.com/mean-average-precision/</a></p>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ROC曲线</tag>
      
      <tag>PR曲线</tag>
      
      <tag>mAP</tag>
      
      <tag>mmAP</tag>
      
      <tag>recall</tag>
      
      <tag>precision</tag>
      
      <tag>AUC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AlexNet</title>
    <link href="/2021/07/31/AlexNet/"/>
    <url>/2021/07/31/AlexNet/</url>
    
    <content type="html"><![CDATA[<h2 id="背景简介"><a href="#背景简介" class="headerlink" title="背景简介"></a>背景简介</h2><p>Hinton学生Alex之作，2012年的ISLVRC冠军，深度学习方法甩开传统图像算法的开端，GPU训练的开端。</p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><div align=center><img title="" src="/img/net/AlexNet_model.pth.png" width="100%" height="100%" align=center></div><ol><li><p><strong>原始输入</strong>：尺寸为[224, 224, 3]的三通道RGB彩色图像</p></li><li><p><strong>特征提取层</strong>：上图中的第一行，(conv, relu, max_pool)经典三元结构x2 + (conv, relu)经典二元结构x3 + max_pool</p></li><li><p><strong>分类层</strong>：将特征提取层的结果flatten之后，接上2个FC层和1个softmax层，其中这两个FC层之前都用了dropout机制。</p></li></ol><h2 id="网络特点"><a href="#网络特点" class="headerlink" title="网络特点"></a>网络特点</h2><ul><li>首用RELU代替以往的sigmoid和tanh(后面补充上各种激活函数的详情文章链接)</li><li>首用LRN局部相应归一化（有时间这里展开讲一下，目前看不是很重要。。）</li><li>首用DROPOUT机制进行正则，具体的实现原理如下：<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">d = np.<span class="hljs-built_in">random</span>.rand( <span class="hljs-keyword">a</span>.shape[<span class="hljs-number">1</span>], <span class="hljs-keyword">a</span>.shape[<span class="hljs-number">1</span>] ) &lt; keep_prob<br><span class="hljs-keyword">a</span> = <span class="hljs-keyword">a</span> * d / keep_prob<br></code></pre></td></tr></table></figure><ol><li>对于一个需要进行dropout的网络层，在获得这一层的激活值a之后，输入到下一层网络之前，用一个随机生成的dropout mask矩阵和a进行逐元素乘法。当然，两者形状一致。</li><li>dropout mask矩阵一般是用rand函数产生的一个和a同尺寸的矩阵，每个元素的值为0-1之间的随机数。若某个元素小于keep_prob则得到1，大于则得到0。这解释了keep_prob的名称的由来，有比例为keep_prob的元素未被置0。</li><li>最后在将a输入到下一层之前，还要恢复a的数学期望，即代码中除以keep_prob的操作。这样就只需要在train过程考虑dropout，而在test时直接关闭dropout即可(对应pytorch中模型eval和train模式的设定)</li></ol></li></ul><h2 id="其他内容"><a href="#其他内容" class="headerlink" title="其他内容"></a>其他内容</h2><p>网络结构图中为了减少参数量，加快训练过程，所有网络层的尺寸都设为了原作的一半。这不是重点。</p>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
      <category>经典网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>神经网络</tag>
      
      <tag>卷积神经网络</tag>
      
      <tag>CNN</tag>
      
      <tag>经典网络</tag>
      
      <tag>AlexNet</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python列表的切片</title>
    <link href="/2021/07/29/python%E5%88%97%E8%A1%A8%E7%9A%84%E5%88%87%E7%89%87/"/>
    <url>/2021/07/29/python%E5%88%97%E8%A1%A8%E7%9A%84%E5%88%87%E7%89%87/</url>
    
    <content type="html"><![CDATA[<p>普通索引<code>a[i]</code>返回序列对象的一个元素，切片<code>a[::1]</code>则返回一些元素。</p><h2 id="基本索引"><a href="#基本索引" class="headerlink" title="基本索引"></a>基本索引</h2><div class="table-container"><table><thead><tr><th style="text-align:center">a中元素</th><th style="text-align:center">2</th><th style="text-align:center">4</th><th style="text-align:center">6</th><th style="text-align:center">8</th></tr></thead><tbody><tr><td style="text-align:center">非负索引</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">2</td><td style="text-align:center">3</td></tr><tr><td style="text-align:center">负数索引</td><td style="text-align:center">-4</td><td style="text-align:center">-3</td><td style="text-align:center">-2</td><td style="text-align:center">-1</td></tr></tbody></table></div><blockquote><p>非负索引从0开始，负数索引从-1开始<br>基本索引不可越界</p></blockquote><h2 id="简单切片"><a href="#简单切片" class="headerlink" title="简单切片"></a>简单切片</h2><p><code>a[start:stop]</code>返回基本索引范围在[start,stop)内的元素</p><ol><li>start/stop越界：此时有多少算多少，不报错</li><li>start &gt; stop：返回空即可</li><li>start/stop缺省：start默认无穷小，stop默认无穷大</li></ol><h2 id="扩展切片"><a href="#扩展切片" class="headerlink" title="扩展切片"></a>扩展切片</h2><h4 id="step为正数，从前往后选取"><a href="#step为正数，从前往后选取" class="headerlink" title="step为正数，从前往后选取"></a>step为正数，从前往后选取</h4><p><code>a[start:stop:step]</code>在[start,stop)区间内，依次选取索引为start, start + step, start + 2step…..直到索引值不在[start, stop)区间中</p><ol><li>越界：同样有多少算多少，不报错</li><li>start &gt; stop：返回空</li><li>缺省：同上</li></ol><h4 id="step为负数，从后向前选取"><a href="#step为负数，从后向前选取" class="headerlink" title="step为负数，从后向前选取"></a>step为负数，从后向前选取</h4><p>此时，start是stop，stop是start，而且还是左开右闭，比如<br><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">a</span>[<span class="hljs-number">2</span>:<span class="hljs-number">0</span>:-<span class="hljs-number">1</span>] -&gt;<span class="hljs-meta"> [6, 4]</span><br><br><span class="hljs-attribute">a</span>[:<span class="hljs-number">1</span>:-<span class="hljs-number">2</span>] -&gt;<span class="hljs-meta"> [8]</span><br></code></pre></td></tr></table></figure></p><h2 id="多维数组切片"><a href="#多维数组切片" class="headerlink" title="多维数组切片"></a>多维数组切片</h2><p>numpy和tensor这样的数据类型相比于原生的list提供了多维数组切片方法，示例如下：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">pad_img<span class="hljs-selector-attr">[: img.shape[0]</span>, : <span class="hljs-selector-tag">img</span><span class="hljs-selector-class">.shape</span><span class="hljs-selector-attr">[1]</span>, : <span class="hljs-selector-tag">img</span><span class="hljs-selector-class">.shape</span><span class="hljs-selector-attr">[2]</span>]<span class="hljs-selector-class">.copy_</span>(img)<br></code></pre></td></tr></table></figure><br>两个逗号隔开三个索引表达式，分别对应这个图像/tensor/numpy数组的3个维度，各个索引表达式在各自维度上的切片规则同上，得到各个维度上的索引列表后对3个列表的元素进行全排列，即可得到最终的三维索引(x, y, z)。这个例子的含义是把img中的像素值复制到pad_img中，左上角对齐。</p><p>研究SSD的源码时又发现一个tensor的切片方式：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs stylus">bboxes = <span class="hljs-selector-attr">[[0, 1, 2]</span>, <span class="hljs-selector-attr">[3, 4, 5]</span>, <span class="hljs-selector-attr">[6, 7, 8]</span>]<br><br><span class="hljs-selector-tag">a</span> = bboxes<span class="hljs-selector-attr">[[True, False, True]</span>, <span class="hljs-number">0</span>]<br><span class="hljs-selector-tag">b</span> = bboxes<span class="hljs-selector-attr">[[1, 0, 1]</span>, <span class="hljs-number">0</span>]<br><br>&gt;&gt;&gt; <span class="hljs-selector-tag">a</span> = <span class="hljs-selector-attr">[0, 6]</span><br>&gt;&gt;&gt; <span class="hljs-selector-tag">b</span> = <span class="hljs-selector-attr">[3, 0, 3]</span><br></code></pre></td></tr></table></figure><br>基本的规则还是跟第一个例子一样，先获取各个维度的索引列表，然后进行全排列，得到最终的二维索引(x, y)。但是第一个维度上的索引列表是一个bool类型元素的列表，当取Fasle时，不参与索引。</p>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>python笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>切片</tag>
      
      <tag>花式索引</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python函数参数的打包与拆解</title>
    <link href="/2021/07/29/python%E5%87%BD%E6%95%B0%E5%8F%82%E6%95%B0%E7%9A%84%E6%89%93%E5%8C%85%E4%B8%8E%E6%8B%86%E8%A7%A3/"/>
    <url>/2021/07/29/python%E5%87%BD%E6%95%B0%E5%8F%82%E6%95%B0%E7%9A%84%E6%89%93%E5%8C%85%E4%B8%8E%E6%8B%86%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<p><strong>标志</strong>：单/双星号出现在入参或形参之前<br><strong>原则</strong>：</p><ol><li>入参前加星号代表拆解，形参前加星号代表打包</li><li>list/tuple只有一种拆解方式，dictionary有两种</li></ol><h2 id="打包情形1：单星号出现在形参前"><a href="#打包情形1：单星号出现在形参前" class="headerlink" title="打包情形1：单星号出现在形参前"></a>打包情形1：单星号出现在形参前</h2><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-title">def</span> pack(a, *b):<br>        print <span class="hljs-keyword">type</span>(a), a<br>        print <span class="hljs-keyword">type</span>(b), b<br><br><span class="hljs-title">pack</span>(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>)<br><br>&gt;&gt; &lt;<span class="hljs-keyword">type</span> &#x27;int&#x27;&gt; 1<br>&gt;&gt; &lt;<span class="hljs-keyword">type</span> &#x27;tuple&#x27;&gt; (2, 3, 4, 5)<br></code></pre></td></tr></table></figure><p>单星号打包，按照匹配顺序认领多个非关键字入参，打包称一个tuple。</p><h2 id="打包情形2：双星号出现在形参前"><a href="#打包情形2：双星号出现在形参前" class="headerlink" title="打包情形2：双星号出现在形参前"></a>打包情形2：双星号出现在形参前</h2><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs routeros">def pack(a, *<span class="hljs-number">*b</span>):<br>        <span class="hljs-builtin-name">print</span> type(a), a<br>        <span class="hljs-builtin-name">print</span> type(b), b<br> <br>pack(1, <span class="hljs-attribute">a1</span>=2, <span class="hljs-attribute">a2</span>=3)<br><br>&gt;&gt; &lt;type <span class="hljs-string">&#x27;int&#x27;</span>&gt; 1<br>&gt;&gt; &lt;type <span class="hljs-string">&#x27;dict&#x27;</span>&gt; &#123;<span class="hljs-string">&#x27;a1&#x27;</span>: 2, <span class="hljs-string">&#x27;a2&#x27;</span>: 3&#125;<br></code></pre></td></tr></table></figure><p>双星号打包，按照匹配顺序认领多个关键字入参，打包成一个dictionary</p><h2 id="拆解情形1：单星号出现在入参前"><a href="#拆解情形1：单星号出现在入参前" class="headerlink" title="拆解情形1：单星号出现在入参前"></a>拆解情形1：单星号出现在入参前</h2><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-title">def</span> pack(a, b, *c):<br>        print <span class="hljs-keyword">type</span>(a), a<br>        print <span class="hljs-keyword">type</span>(b), b<br>        print <span class="hljs-keyword">type</span>(c), c<br> <br><span class="hljs-title">score</span> = [<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>]<br><span class="hljs-title">pack</span>(*score)<br><br>&gt;&gt; &lt;<span class="hljs-keyword">type</span> &#x27;float&#x27;&gt; 1.0<br>&gt;&gt; &lt;<span class="hljs-keyword">type</span> &#x27;float&#x27;&gt; 2.0<br>&gt;&gt; &lt;<span class="hljs-keyword">type</span> &#x27;tuple&#x27;&gt; (3.0, 4.0)<br></code></pre></td></tr></table></figure><p>单星号拆解，将list/tuple/dictionary的内容当做独立非关键字的入参列表，其中dictionary只保留key</p><h2 id="拆解情形2：双星号出现在入参前"><a href="#拆解情形2：双星号出现在入参前" class="headerlink" title="拆解情形2：双星号出现在入参前"></a>拆解情形2：双星号出现在入参前</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">pack</span>(<span class="hljs-params">*a, **b</span>):</span><br>        <span class="hljs-built_in">print</span> <span class="hljs-built_in">type</span>(a), a<br>        <span class="hljs-built_in">print</span> <span class="hljs-built_in">type</span>(b), b<br> <br>age = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br>student = &#123;<span class="hljs-string">&#x27;score&#x27;</span> : <span class="hljs-number">1.0</span>, <span class="hljs-string">&#x27;id&#x27;</span> : <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;name&#x27;</span> : <span class="hljs-string">&#x27;xiaoxiao&#x27;</span>&#125;<br>pack(*age, **student)<br><br>&gt;&gt; &lt;<span class="hljs-built_in">type</span> <span class="hljs-string">&#x27;tuple&#x27;</span>&gt; (<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br>&gt;&gt; &lt;<span class="hljs-built_in">type</span> <span class="hljs-string">&#x27;dict&#x27;</span>&gt; &#123;<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">1.0</span>, <span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;xiaoxiao&#x27;</span>&#125;<br></code></pre></td></tr></table></figure><p>双星号拆解，只针对dictionary，将其内容拆解为关键字入参列表。</p>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>python笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>nvidia-smi突然跪了！</title>
    <link href="/2021/07/26/nvidia-smi%E7%AA%81%E7%84%B6%E8%B7%AA%E4%BA%86%EF%BC%81/"/>
    <url>/2021/07/26/nvidia-smi%E7%AA%81%E7%84%B6%E8%B7%AA%E4%BA%86%EF%BC%81/</url>
    
    <content type="html"><![CDATA[<h2 id="解决过程"><a href="#解决过程" class="headerlink" title="解决过程"></a>解决过程</h2><p>看着代码唱着歌，CUDA就突然啥啥啥初始化失败了。</p><p>nvidia-smi一看，又是一个新报错Failed to initialize NVML: Driver/library version mismatch，闹心。</p><p>整半天，大概意思是作为内核模块的nvidia驱动程序版本和libnvidia-compute-460这个库的版本不一致。</p><p>两者一般都应该是安装驱动的时候指定的版本（for me is 460.84），但是后者竟然通过ubuntu的后台更新程序自动更新了（460.91），所以造成了这个问题。</p><p>最后，更新了驱动程序，关闭了自动更新，reboot，告一段落。</p><h2 id="用到的命令："><a href="#用到的命令：" class="headerlink" title="用到的命令："></a>用到的命令：</h2><blockquote><p>lsmod | grep nvidia*<br>显示和nvidia有关的内核模块有哪些</p><p>modinfo nvidiaxxx | grep version<br>显示这些内核模块的版本</p><p>dpkg —list | grep nvidia<br>显示libnvidia-compute这个库的版本</p><p>dmesg | tail -4<br>nvidia-smi的报错详情，可以看到版本差异<br>dmesg | grep nvidia<br>nvidia-smi的执行过程详情</p><p>cat /var/log/apt/history.log | grep -a -C 10 nvidia<br>libnvidia-compute的更新记录，可以看到是unattended-upgrade造成的更新</p><p>cat /etc/apt/apt.conf.d/20auto-upgrades<br>自动更新的配置文件，修改即可关闭自动更新<a href="https://unix.stackexchange.com/questions/342663/how-is-unattended-upgrades-started-and-how-can-i-modify-its-schedule">detail</a></p><p>sudo apt install nvidia-driver-460<br>更新驱动程序</p></blockquote><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li><a href="https://stackoverflow.com/questions/62250491/nvml-driver-library-mismatch-after-libnvidia-compute-update">https://stackoverflow.com/questions/62250491/nvml-driver-library-mismatch-after-libnvidia-compute-update</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>生活记录</category>
      
      <category>电脑设置</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Nvidia</tag>
      
      <tag>驱动失效</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python笔记</title>
    <link href="/2021/07/22/python%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/07/22/python%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h3 id="python的zip函数"><a href="#python的zip函数" class="headerlink" title="python的zip函数"></a>python的zip函数</h3><p>输入若干个Iterable对象，将这些Iterable对象对应位置的元素打包为一个tuple，然后将所有tuple作为一个zip对象返回。</p><p>当传入的Iterable对象长度不一致时取最短的。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-selector-tag">a</span> = <span class="hljs-selector-attr">[[1,2]</span>,<span class="hljs-selector-attr">[3,4]</span>,<span class="hljs-selector-attr">[5,6]</span>]<br><span class="hljs-selector-tag">b</span> = zip(*a)<br>c = tuple(b)<br><br>&gt;&gt;&gt; <span class="hljs-selector-tag">a</span> = ((<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>), (<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>))<br></code></pre></td></tr></table></figure></p><h3 id="python-string的split方法"><a href="#python-string的split方法" class="headerlink" title="python string的split方法"></a>python string的split方法</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-selector-tag">a</span> = <span class="hljs-string">&quot;, my, name, is, ming&quot;</span><br><span class="hljs-selector-tag">b</span> = <span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.split</span>(<span class="hljs-string">&#x27;,&#x27;</span>)<br><br>&gt;&gt;&gt; <span class="hljs-selector-tag">b</span> = <span class="hljs-selector-attr">[<span class="hljs-string">&#x27;&#x27;</span>,<span class="hljs-string">&#x27; my&#x27;</span>,<span class="hljs-string">&#x27; name&#x27;</span>,<span class="hljs-string">&#x27; is&#x27;</span>,<span class="hljs-string">&#x27; ming&#x27;</span> ]</span><br></code></pre></td></tr></table></figure><p>即，将原string按照字符串分割，不包含分隔符，返回一个列表。</p><h3 id="pyhton-函数装饰器"><a href="#pyhton-函数装饰器" class="headerlink" title="pyhton 函数装饰器"></a>pyhton 函数装饰器</h3><p>对被修饰的函数增加一层封装，被修饰的函数仍然正常被调用，被执行，但是增加了一些“私货”，比如打log。这么做的好处是在不修改原函数代码以及调用原函数的代码的前提下改变其行为。<br><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">import</span> logging<br><br>def use_logging(func):<br>def <span class="hljs-keyword">wrapper</span>(*args, **kwargs):<br>logging.warn(&quot;%s is running&quot; % func.__name__)<br><span class="hljs-keyword">return</span> func(*args)<br><span class="hljs-keyword">return</span> <span class="hljs-keyword">wrapper</span><br><br>@use_logging<br>def foo():<br>print(&quot;i am foo&quot;)<br><br>@use_logging<br>def bar():<br>print(&quot;i am bar&quot;)<br><br>foo()<br>bar()<br><br>&gt;&gt;&gt; i am foo<br>&gt;&gt;&gt; i am bar<br>&gt;&gt;&gt; <span class="hljs-built_in">WARNING</span>:root:foo <span class="hljs-keyword">is</span> running<br>&gt;&gt;&gt; <span class="hljs-built_in">WARNING</span>:root:bar <span class="hljs-keyword">is</span> running<br></code></pre></td></tr></table></figure></p><h3 id="python-赋值-amp-浅拷贝-amp-深拷贝的区别"><a href="#python-赋值-amp-浅拷贝-amp-深拷贝的区别" class="headerlink" title="python 赋值&amp;浅拷贝&amp;深拷贝的区别"></a>python 赋值&amp;浅拷贝&amp;深拷贝的区别</h3><ol><li>对于不可变对象，三者同质，都只增加原对象的引用计数</li><li>对于可变对象<ul><li>赋值，仍然是引用计数</li><li>浅拷贝，新瓶装旧酒，瓶是新的，酒还是原对象元素的计数引用</li><li>深拷贝，实质意义上的拷贝，啥都重新搞一份</li></ul></li></ol><h3 id="python-init-py文件的作用"><a href="#python-init-py文件的作用" class="headerlink" title="python init.py文件的作用"></a>python <strong>init</strong>.py文件的作用</h3><p>一个包含了<strong>init</strong>.py目录可以被识别为一个包，而目录内的.py文件是这个包的模块。一个包也是一个模块，反之则不一定。</p><p>在import一个包时，实际上是在执行这个包的<strong>init</strong>.py中的代码。看一个例子，</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs stylus">.<br>├── <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.py</span><br>└── mypackage<br>    ├── __init__<span class="hljs-selector-class">.py</span><br>    ├── subpackage_1<br>    │   ├── test11<span class="hljs-selector-class">.py</span><br>    │   └── test12<span class="hljs-selector-class">.py</span><br>    └── subpackage_2<br>        ├── __init__<span class="hljs-selector-class">.py</span><br>        ├── test21<span class="hljs-selector-class">.py</span><br>        └── test22.py<br></code></pre></td></tr></table></figure><p>在main.py中<code>import mypackage</code>时，python后台程序会按照以下顺序搜索<code>mypackage</code></p><ol><li>当前的工作目录；</li><li>PYTHONPATH（环境变量）中的每一个目录；</li><li>Python 默认的安装目录。</li></ol><p>本例中，在当前工作目录下即可找到<code>mypackage</code>，然后会执行其下<strong>init</strong>.py中的代码。</p><p>对于mypackage的<strong>init</strong>.py，值得注意的是：<br><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs clean"><span class="hljs-keyword">import</span> subpackage_1# 错误，因为在main的当前目录找不到subpackage_1<br><span class="hljs-keyword">import</span> subpackage_2# 错误<br><span class="hljs-keyword">import</span> mypackage.subpackage_1# 正确，先找到mypackage再找到subpackage_1<br><span class="hljs-keyword">import</span> mypackage.subpackage_2# 正确<br><span class="hljs-keyword">from</span> . <span class="hljs-keyword">import</span> subpackage_1# 正确，在<span class="hljs-keyword">from</span>指定的目录可以找到subpackage_1<br><span class="hljs-keyword">from</span> . <span class="hljs-keyword">import</span> subpackage_2# 正确<br><span class="hljs-keyword">from</span> mypackage <span class="hljs-keyword">import</span> subpackage_1 # 正确，同上<br><span class="hljs-keyword">from</span> mypackage <span class="hljs-keyword">import</span> subpackage_2<br><br><span class="hljs-keyword">from</span> mypackage <span class="hljs-keyword">import</span> test11# 错误<br><span class="hljs-keyword">from</span> mypackage.subpackage_1 <span class="hljs-keyword">import</span> test11# 正确<br><span class="hljs-keyword">from</span> .subpackage_1 <span class="hljs-keyword">import</span> test11# 正确，语义同上<br><span class="hljs-keyword">from</span> mypackage <span class="hljs-keyword">import</span> test21<br><span class="hljs-keyword">from</span> mypackage.subpackage_2 <span class="hljs-keyword">import</span> test21<br><span class="hljs-keyword">from</span> .subpackage_2 <span class="hljs-keyword">import</span> test21<br></code></pre></td></tr></table></figure></p><h3 id="itertools库"><a href="#itertools库" class="headerlink" title="itertools库"></a><code>itertools</code>库</h3><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs fortran">v1 = [(i, j) for i, j <span class="hljs-keyword">in</span> itertools.<span class="hljs-built_in">product</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>), <span class="hljs-built_in">repeat</span>=<span class="hljs-number">2</span>)]<br>v2 = [(i, j) for i, j <span class="hljs-keyword">in</span> itertools.<span class="hljs-built_in">product</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>), <span class="hljs-built_in">repeat</span>=<span class="hljs-number">3</span>)]<br><br>&gt;&gt;&gt; v1 = [(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>), (<span class="hljs-number">0</span>, <span class="hljs-number">1</span>), (<span class="hljs-number">1</span>, <span class="hljs-number">0</span>), (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)]<br>&gt;&gt;&gt; v2 = [(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>), (<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>), (<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>), (<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), (<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>), (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>), (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)]<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>python笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>split</tag>
      
      <tag>函数装饰器</tag>
      
      <tag>深拷贝</tag>
      
      <tag>浅拷贝</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch笔记</title>
    <link href="/2021/07/22/pytorch%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/07/22/pytorch%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h3 id="max-sum-等操作中指定dim的含义"><a href="#max-sum-等操作中指定dim的含义" class="headerlink" title="max() sum()等操作中指定dim的含义"></a><code>max() sum()</code>等操作中指定dim的含义</h3><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs inform7">a = <span class="hljs-comment">[ <span class="hljs-comment">[ <span class="hljs-comment">[1, 2]</span>, <span class="hljs-comment">[3, 4]</span> ]</span>, <span class="hljs-comment">[ <span class="hljs-comment">[5, 6]</span>, <span class="hljs-comment">[7, 8]</span> ]</span> ]</span><br></code></pre></td></tr></table></figure><ol><li>对于这个[2, 2, 2]的三维矩阵，三维意味着[]有三层，三个2表示每一层[]内有两个元素</li><li>对dim=0求max意味着<ol><li>将<script type="math/tex">a_{000}</script>与<script type="math/tex">a_{100}</script>比较得出最大值作为<script type="math/tex">a_{00}</script></li><li>将<script type="math/tex">a_{010}</script>与<script type="math/tex">a_{110}</script>比较得出最大值作为<script type="math/tex">a_{10}</script>…</li></ol></li><li>对dim=1求max意味着<ol><li>将<script type="math/tex">a_{000}</script>与<script type="math/tex">a_{010}</script>比较得出最大值作为<script type="math/tex">a_{00}</script></li><li>将<script type="math/tex">a_{100}</script>与<script type="math/tex">a_{110}</script>比较得出最大值作为<script type="math/tex">a_{10}</script>…</li></ol></li><li>而$a_{010}$对应于，第一层[]中的第一个元素的，第二个元素的，第一个元素</li></ol><h3 id="torch-flatten-中指定dim的含义"><a href="#torch-flatten-中指定dim的含义" class="headerlink" title="torch.flatten()中指定dim的含义"></a><code>torch.flatten()</code>中指定dim的含义</h3><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs less"># 默认情况，消除<span class="hljs-selector-tag">x</span>第<span class="hljs-selector-tag">1</span>层<span class="hljs-selector-attr">[]</span>内的所有<span class="hljs-selector-attr">[]</span><br><span class="hljs-selector-tag">torch</span><span class="hljs-selector-class">.flatten</span>(x)<br><br># 指定<span class="hljs-selector-tag">start_dim</span>,从<span class="hljs-selector-tag">x</span>的第<span class="hljs-selector-tag">s</span>+<span class="hljs-selector-tag">1</span>层<span class="hljs-selector-attr">[]</span>开始，消除其中的所有<span class="hljs-selector-attr">[]</span><br><span class="hljs-selector-tag">torch</span><span class="hljs-selector-class">.flatten</span>(x, <span class="hljs-number">1</span>)<br><br># 指定<span class="hljs-selector-tag">start_dim</span>和<span class="hljs-selector-tag">end_dim</span>，将第<span class="hljs-selector-tag">e</span>+<span class="hljs-selector-tag">1</span>层<span class="hljs-selector-attr">[]</span>包围的元素作为一个基础元素，然后从第<span class="hljs-selector-tag">s</span>+<span class="hljs-selector-tag">1</span>层开始消除所有基础元素外的<span class="hljs-selector-attr">[]</span><br><span class="hljs-selector-tag">torch</span><span class="hljs-selector-class">.flatten</span>(x, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br><br># 综上，其实就是<span class="hljs-selector-tag">start_dim</span>默认为<span class="hljs-selector-tag">0</span>，<span class="hljs-selector-tag">end_dim</span>默认为<span class="hljs-selector-tag">-1</span><br></code></pre></td></tr></table></figure><h3 id="torch-cat-x-y-d-中指定dim的含义"><a href="#torch-cat-x-y-d-中指定dim的含义" class="headerlink" title="torch.cat((x,y),d)中指定dim的含义"></a><code>torch.cat((x,y),d)</code>中指定dim的含义</h3><ol><li>第一种解释，d=0就是按行堆叠x和y，堆叠后有了更多的行。然后是按列，按深度，以此类推。容易理解，适用于3维以下。</li><li>第二种解释，就是扩展x第d+1层[]中的内容，拿什么来扩展呢，拿y对应位置的元素，比较难理解，但适用性更广。</li></ol><h3 id="nn-MaxPool2d-3-stride-2-ceil-mode-True-中ceil-mode的含义"><a href="#nn-MaxPool2d-3-stride-2-ceil-mode-True-中ceil-mode的含义" class="headerlink" title="nn.MaxPool2d(3, stride=2, ceil_mode=True)中ceil_mode的含义"></a><code>nn.MaxPool2d(3, stride=2, ceil_mode=True)</code>中ceil_mode的含义</h3><p>其实就是尺寸计算公式中是向上取整还是向下取整，默认向下取整，开了ceil_mode之后就向上取整。</p><h3 id="nn-AvgPool2d-kernel-size-5-stride-3-与nn-AdaptiveAvgPool2d-1-1-的区别"><a href="#nn-AvgPool2d-kernel-size-5-stride-3-与nn-AdaptiveAvgPool2d-1-1-的区别" class="headerlink" title="nn.AvgPool2d(kernel_size=5, stride=3)与nn.AdaptiveAvgPool2d((1, 1))的区别"></a><code>nn.AvgPool2d(kernel_size=5, stride=3)</code>与<code>nn.AdaptiveAvgPool2d((1, 1))</code>的区别</h3><p>前者用指定的kernel_size和stride定义池化操作，后者则通过指定输出tensor的尺寸来定义池化操作，stride和kernel_size会自动算出来。</p><blockquote><p>In average-pooling or max-pooling, you essentially set the stride and kernel-size by your own, setting them as hyper-parameters. You will have to re-configure them if you happen to change your input size.<br>In Adaptive Pooling on the other hand, we specify the output size instead. And the stride and kernel-size are automatically selected to adapt to the needs. The following equations are used to calculate the value in the source code.<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-attr">Stride</span> = (input_size//output_size)  <br>Kernel <span class="hljs-attr">size</span> = input_size - (output_size-<span class="hljs-number">1</span>)*stride  <br><span class="hljs-attr">Padding</span> = <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure></p></blockquote><h3 id="plt-imshow-与plt-show-的区别"><a href="#plt-imshow-与plt-show-的区别" class="headerlink" title="plt.imshow()与plt.show()的区别"></a><code>plt.imshow()</code>与<code>plt.show()</code>的区别</h3><p><code>plt.imshow()</code>只是将图片与plt发生关联，但不显示，还可以继续对这张图片进行其他draw操作，最后再用<code>plt.show()</code>显示出来。</p><h3 id="dataset-dataset-loader-dataset-loader-iter的区别"><a href="#dataset-dataset-loader-dataset-loader-iter的区别" class="headerlink" title="dataset dataset_loader dataset_loader_iter的区别"></a><code>dataset</code> <code>dataset_loader</code> <code>dataset_loader_iter</code>的区别</h3><ul><li><code>train_set</code>不是Iterator，也不是Iterabel;</li><li><code>train_loader</code>不是Iterator，但是Iterable;</li><li>Iterable意味着可用于for循环被迭代, Iterator则是算法，不断用next产生需要的数据，Iterator必然Iterable</li></ul><h3 id="model的常用方法"><a href="#model的常用方法" class="headerlink" title="model的常用方法"></a>model的常用方法</h3><p>一般一个model都是由一串<code>nn.Module</code>的派生类组合而成的class，而且其本身一般也是一个<code>nn.Module</code>的派生类。因为各个相关对象都来自一个公共基类，因此常用的成员函数也大致相同：</p><ul><li><code>model.modules()</code> &amp; <code>model.named_modules()</code></li><li><code>model.children()</code> &amp; <code>model.named_children()</code></li><li><code>model.parameters()</code> &amp; <code>model.named_parameters()</code></li><li><code>model.buffers()</code> &amp; <code>model.named_buffers()</code></li></ul><p>这些方法都是返回一个generator，迭代它可以得到相应的元素。</p><p>其中，module和children返回的是一个<code>nn.Module</code>的派生类对象，不同点是前者递归式地返回model所有后代(而不只是叶子节点哦)，后者返回其直接后代。</p><p>parameters返回的是一个Parameter对象，暂时可以理解为是一个tensor。</p><p>buffers返回的是一个tensor，保存过程数据running_mean、running_var等，具体含义暂时未知。一般只有作为叶子节点的module才有parameter和buffers。</p><p>另外就是带name的版本，相比与不带name的版本，迭代generator得到的是一个包含两个元素的tuple，第一个元素是name，第二个元素跟不带name的版本一样。</p><p>各个方法返回的元素的命名都是基于module的名称，以InvertedResidual模块为例，具体的命名逻辑如下图所示：</p><div align=center><img title="" src="/img/article/pytorch_module_name.png" width="90%" height="90%" align=center></div>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
      <category>pytorch使用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
      <tag>plt</tag>
      
      <tag>AaptivePool</tag>
      
      <tag>flatten</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CNN的数学原理</title>
    <link href="/2021/07/15/CNN%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"/>
    <url>/2021/07/15/CNN%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="二维卷积的数学原理"><a href="#二维卷积的数学原理" class="headerlink" title="二维卷积的数学原理"></a>二维卷积的数学原理</h2><p>不管信号处理中“卷积”和“相关”的定义如何，至少在CNN中卷积的含义是明确的。就是</p><ol><li>将卷积核(一个尺寸较小的方阵)与矩阵$\boldsymbol{A}$左上角对齐</li><li>两个矩阵逐元素相乘后求和，作为结果矩阵$\boldsymbol{B}$的左上角第一个元素</li><li>向右/下移动卷积核的位置，重复2，直到卷积核到达矩阵$\boldsymbol{A}$的右下角<div align=center><img title="CNN中卷积的数学含义" src="/img/article/juanji.gif" width="60%" height="60%" align=center></div></li></ol><p>由此带来了<strong>padding</strong>和<strong>stride</strong>的概念：</p><ul><li><strong>padding</strong>：为了解决卷积带来的尺寸缩减，在卷积之前在$\boldsymbol{A}$周围补上p圈0。</li><li><strong>stride</strong>：卷积核每次向右/下移动s个元素。</li></ul><p>综上，有以下公式计算卷积前后的尺寸变化：</p><blockquote><p>$(n,n) and (f,f) \Longrightarrow \lfloor \frac{n+2p-f}{s}+1 \rfloor$</p></blockquote><h2 id="多维度卷积的数学原理"><a href="#多维度卷积的数学原理" class="headerlink" title="多维度卷积的数学原理"></a>多维度卷积的数学原理</h2><p><strong>关键字</strong>：<strong>卷积</strong>-&gt;<strong>偏移</strong>-&gt;<strong>激活</strong></p><p>CNN模型的输入——RGB三通道图像可以看做一个三层的2D矩阵，对其卷积的含义是：</p><ol><li>将一个层数相同的卷积核与这个3层的2D矩阵左上角对齐，然后做逐元素的乘积求和，并不断移动到右下角为止</li><li>由于求和是跨通道的，因此卷积的结果是一个单层的2D矩阵。</li><li>然后，仿照DNN对这个单层的2D矩阵中的每一个元素进行偏移和激活，得到作为输出的单层的2D矩阵。</li><li>选取另一个同尺寸的卷积核重复1-3，得到另一个单层的2D矩阵</li><li>将输入量与本层所有卷积核的卷积结果堆叠后，得到一个新的多层2D矩阵，作为本层的输出。</li><li>经过若干个卷积层处理后，将最后一个卷积层输出的多层2D矩阵看做一个列向量，将这个列向量作为$\boldsymbol{a}^{[l-1]}$，送入输出层处理。</li><li>若是二分类，则输出层是一个DNN神经元；若是多分类，则输出层是一个以$softmax$为激活函数的DNN网络层。此处DNN的含义指，通过矩阵乘法产生$\boldsymbol{z}^{[l]}$，而不是卷积操作。</li></ol><blockquote><ul><li>显然输出的层数等于本层卷积核的数量，而输出的每一层的尺寸则由前文提及的公式计算得到。</li><li>与DNN不同这里的权重矩阵$\boldsymbol{W}$的维度，都是人为指定的。这也正式CNN存在的理由，减少参数。</li></ul></blockquote><h2 id="池化的数学原理"><a href="#池化的数学原理" class="headerlink" title="池化的数学原理"></a>池化的数学原理</h2><p>与卷积操作的过程相同，但是每个核与输入矩阵进行的不是卷积操作，而是选取区域最大值的操作（最大池化）或者计算区域平均值的操作（平均池化）。一般用于降维。最大池化比较常用，并且一般伴随着0 padding。</p><h2 id="CNN目标检测的基本原理"><a href="#CNN目标检测的基本原理" class="headerlink" title="CNN目标检测的基本原理"></a>CNN目标检测的基本原理</h2><h3 id="单图片，单目标"><a href="#单图片，单目标" class="headerlink" title="单图片，单目标"></a>单图片，单目标</h3><p>先说最简单的情形，即判断一张图片中有没有猫的问题。只需要将图片送入CNN，然后将模型输出向量定义为如下形式即可（假设待检测目标有3类）</p><blockquote><p>$\hat{\boldsymbol{y}} = (p,x,y,w,h,c_1,c_2,c_3)^T$</p></blockquote><p>其中</p><ul><li>$p$为这个result向量，或者说这个检测框存在目标的概率</li><li>$x,y,w,h$为这个检测框的在输入图片中的位置</li><li>$c_1, c_2, c_3$为该检测框属于各个类别的概率</li></ul><h3 id="单图片，多目标"><a href="#单图片，多目标" class="headerlink" title="单图片，多目标"></a>单图片，多目标</h3><p>如果一张图片存在多个目标——这也是实际情况中更可能发生的情况，事情就变得复杂起来。最直观并且容易理解的思路是<strong>滑动窗口搜索法</strong>：<br></p><ol><li>定义一个尺寸的框，将输入图片的左上角与这个框对齐</li><li>将被框框住的部分作为“单图片，单目标”的情形处理，问题解决</li><li>然后移动框的位置，不断向右，向下遍历整张输入图片</li><li>完成遍历之后，换一个尺寸，重复1-3</li><li>所有尺寸都尝试过之后，输入图片中的所有目标自然被检测出来</li></ol><p>很明显，上述做法计算量非常大，症结主要有</p><ol><li>每一个框都要不断移动，遍历整张图</li><li>两个要穷举所有尺寸的框</li></ol><p>对于第1个问题，可以通过<strong>滑动窗口的卷积实现</strong>来规避。而对于第二个问题，目前有两种主流思路：</p><ol><li>感兴趣区域预提取的思路<ol><li>通过图像分割，提取感兴趣区域，然后将所有感兴趣区域依次送入CNN进行预测——RCNN</li><li>用滑动窗口的卷积实现，代替RCNN中依次进行的CNN处理——Fast RCNN</li><li>用一个CNN代替图像分割进行感兴趣区域提取——Faster RCNN</li></ol></li><li>YOLO思路<br>将输入图片分割为19x19个区域，然后结合<strong>滑动窗口卷积实现</strong>的思路将整张图片送入CNN网络，得到19x19个$(p,x,y,w,h,c_1,c_2,c_3)^T$，每一个$(p,x,y,w,h,c_1,c_2,c_3)^T$表示对应区域中的目标检测结果。特别的，存在区域认领目标的概念，意思是说，当一个目标的检测框的中心在某个区域之内时，这个区域对应的result向量才会生成有效信息。基于这个概念，产生了以下两个问题：<ol><li>一个区域内就是有多个目标的检测框的中心点怎么办？</li><li>相邻的几个区域都声称同一个目标的中心点在它那里，然后都生成了几乎相同的有效的result向量怎么办？<br>对于问题1，采用anchor box应对，问题2则采用NMS应对。</li></ol></li></ol><h2 id="滑动窗口的卷积实现原理"><a href="#滑动窗口的卷积实现原理" class="headerlink" title="滑动窗口的卷积实现原理"></a>滑动窗口的卷积实现原理</h2><p>将CNN网络模型中最后的几个全连接层看作卷积层。因为从数学角度看，卷积层和全连接层是一样的，因为这400个节点中每个节点的$\boldsymbol{w}$向量都可以看作一个5×5×16的过滤器，所以不论是把最后这几层看作全连接层还是卷积层，他们的输出都是上一层输出经过某个任意线性函数处理后的结果。所以本质上就是一个如何看的问题，计算的本质过程是不变的。这么做的好处是，可以把输入的19x19个区域与输出的19x19个result做有意义的关联了。</p><div align=center><img title="滑动窗口的卷积实现" src="/img/article/hdck.png" width="60%" height="60%" align=center></div><h2 id="anchor-box的工作原理"><a href="#anchor-box的工作原理" class="headerlink" title="anchor box的工作原理"></a>anchor box的工作原理</h2><p>将某个区域认领某个目标的对应关系再细分一级，变成某个区域的某个anchor box认领某个目标。这样，当一个区域内有多个中心点时，再额外的计算一下每个目标与每个预设的anchor box之间的交并比之后，即可将目标细分到anchor box。这时，每个区域便可以认领多个不同种类的目标。一般通过聚类训练集中的目标进行anchor box的尺寸设定。</p><h2 id="NMS的工作原理"><a href="#NMS的工作原理" class="headerlink" title="NMS的工作原理"></a>NMS的工作原理</h2><p>对于所有19x19个result向量，一类一类的来看，比如先看归属于vehicle类的box：</p><ol><li>选取这类box中scores最大的哪一个，记为box_best，并保留它</li><li>计算box_best与其余的box的IOU</li><li>如果其IOU&gt;0.5了，那么就舍弃这个box（由于可能这两个box表示同一目标，所以保留分数高的哪一个）</li><li>从最后剩余的boxes中，再找出最大scores的哪一个，如此循环往复</li></ol>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>卷积神经网络</tag>
      
      <tag>CNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DNN的数学原理</title>
    <link href="/2021/07/12/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"/>
    <url>/2021/07/12/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>数学是现实世界的精确抽象，再花里胡哨的东西，内在终究还是一堆加减乘除。因此，从数学的角度写一下到底啥是深度学习，学过线代就能懂。</p><h2 id="神经网络模型的结构"><a href="#神经网络模型的结构" class="headerlink" title="神经网络模型的结构"></a>神经网络模型的结构</h2><p><strong>神经网络</strong>的基础单元是<strong>神经元</strong>，多个<strong>神经元</strong>纵向堆叠形成神经<strong>网络层</strong>，神经<strong>网络层</strong>横向堆叠形成<strong>神经网络</strong>。</p><div align=center><img title="" src="/img/article/神经网络的数学原理/神经网络.png" width="50%" height="50%" align=center></div><br><div align=center><img title="" src="/img/article/神经网络的数学原理/神经元.png" width="60%" height="60%" align=center></div><h2 id="神经元的数学原理"><a href="#神经元的数学原理" class="headerlink" title="神经元的数学原理"></a>神经元的数学原理</h2><p>对于一个神经元，进行的数学计算为：</p><blockquote><p>接受一个向量$\boldsymbol{a}^{[j-1]}$，通过与$\boldsymbol{w}^{[j]}_i$进行向量内积运算产生一个中间值$z_i^{[j]}$（标量），然后用激活函数$g_i^{[j]}()$将$z$转换为$a_i^{[j]}$。</p></blockquote><p>其中:</p><blockquote><p>上标用来定位该神经元位于哪一层，一般输入层后的第一层为1；<br>下标用来定位该神经元位于第几个，一般最上方的序号为0；</p></blockquote><h2 id="矩阵维度确认的数学原理"><a href="#矩阵维度确认的数学原理" class="headerlink" title="矩阵维度确认的数学原理"></a>矩阵维度确认的数学原理</h2><p>首先区分开这4个概念：<strong>模型的参数</strong>，<strong>层的参数</strong>，<strong>神经元的参数</strong>，<strong>数据及数据的中间值</strong>。然后，仔细理解上面两段话，神经网络中最为tricky的维度问题便迎刃而解：</p><ol><li>对于$\boldsymbol{x}$和$\boldsymbol{y}$，其维度看样本就知道，已经定义好了;</li><li>对于某一个神经元的权重参数$\boldsymbol{w}^{[j]}_i$，由于要跟输入的向量$\boldsymbol{a}^{[j-1]}$进行内积，所以两者的维度必然是相同的，而后者作为一个列向量，其行数等于上一层的神经元数量（因为每个神经元输出一个标量）。然后由于本层的每一个神经元都有一个权重参数$\boldsymbol{w}^{[j]}$，那么由${\boldsymbol{w}^{[j]}}^T$纵向堆叠形成的${\boldsymbol{W}^{[j]}}^T$的行数就是$\boldsymbol{w}^{[j]}$的个数，亦即本层的神经元数量，其列数前面已经说了，就是$\boldsymbol{w}^{[j]}$的行数，亦即上一层的神经元数量。<br></li><li>对于某一个神经元的偏移量参数${b}^{[j]}$，自然是一个标量。那么本层的偏移量参数$\boldsymbol{b}^{[j]}$的行数就是${b}^{[j]}$的数量，亦即本层的神经元数量。</li><li>对于每一层的中间值$\boldsymbol{z}^{[j]}$，输出值$\boldsymbol{a}^{[j]}$，其维度确定方式与$\boldsymbol{b}^{[j]}$一样。</li><li>另外对于激活函数，一般同一层都一样，所以$\boldsymbol{g}^{[j]}()$退化为${g}^{[j]}()$。</li></ol><h2 id="矢量化的数学原理"><a href="#矢量化的数学原理" class="headerlink" title="矢量化的数学原理"></a>矢量化的数学原理</h2><p>矢量化的本质是将样本在时间轴上被神经网络模型处理的序列转化为空间上的序列：<br></p><blockquote><p>$X= (\boldsymbol{x}^1,\boldsymbol{x}^2, …,  \boldsymbol{x}^)$</p></blockquote><p>说人话就是，原来每次送入模型一个列向量，计算得到一个列向量。现在每次送入m个列向量，计算的到m个列向量。当然了，各层的中间值$\boldsymbol{z}^{[j]}$和输出值$\boldsymbol{a}^{[j]}$也都将因此横向扩充一个维度。</p><h2 id="Batch的数学原理"><a href="#Batch的数学原理" class="headerlink" title="Batch的数学原理"></a>Batch的数学原理</h2><p>一个batch指每次送入模型的一批样本。比如，现有2000个样本，将其划分为4个batch，那么每个batch包含500个样本，即</p><blockquote><p>batch_size=500;<br>batch_num = 4;</p></blockquote><p>一个epoch指整个训练集被利用了一次。即，2000个样本中的每一个都被代入模型进行了一次前向计算和反向传播。</p><p>一个iteration指权重参数更新一次。一个epoch中可能有多个iteration，也可能只有一个iteration，这取决于batch_num的值。</p><p>留一个疑问，在一个epoch中，一个batch会循环多次使用吗？还是只用1次就结束了？例如，在一个epoch中用batch_1迭代10次，然后batch_2迭代10次，….，最后batch_4迭代10次，一个epoch完成。是这样吗？<em>——<a href="https://stackoverflow.com/questions/4752626/epoch-vs-iteration-when-training-neural-networks">目前来看不是这样，而是只用1次。 2021年7月15日</a></em></p><h2 id="正向计算的数学原理"><a href="#正向计算的数学原理" class="headerlink" title="正向计算的数学原理"></a>正向计算的数学原理</h2><p>正向计算，用于得到所需的预测结果：</p><ol><li>输入一个列向量：<br><blockquote><p> $\boldsymbol{x} = (x_1, x_2, … , x_n )^T$</p></blockquote></li><li><p>进行一系列矩阵计算：<br></p><blockquote><p> $\boldsymbol{a}^{[0]} = \boldsymbol{x}$<br> $\boldsymbol{z}^{[1]} = {\boldsymbol{W}^{[1]}}^T\boldsymbol{a}^{[0]}+\boldsymbol{b}^{[1]}$<br> $\boldsymbol{a}^{[2]} = g^{[1]}(\boldsymbol{z}^{[1]})$<br> …<br> $\boldsymbol{z}^{[j]} = {\boldsymbol{W}^{[j]}}^T\boldsymbol{a}^{[j-1]}+\boldsymbol{b}^{[j]}$<br> $\boldsymbol{a}^{[j]} = g^{[j]}(\boldsymbol{z}^{[j]})$<br> …<br> $\boldsymbol{z}^{[l]} = {\boldsymbol{W}^{[l]}}^T\boldsymbol{a}^{[l-1]}+\boldsymbol{b}^{[l]}$<br> $\boldsymbol{a}^{[l]} = g^{[l]}(\boldsymbol{z}^{[l]})$<br> $\boldsymbol{\hat{y}} = \boldsymbol{a}^{[l]}$</p></blockquote><p>特别地，对于多分类模型的输出层（最后一层），一般有：</p><blockquote><p>$g^{[l]}(\boldsymbol{x}) = softmax(\boldsymbol{x}) = \frac{exp(\boldsymbol{x})}{\boldsymbol{1}^Texp(\boldsymbol{x})}$</p></blockquote><p>其中 $\boldsymbol{1}$ 为全1列向量，维度可从context推得。</p></li><li>得到一个列向量：<br><blockquote><p> $\boldsymbol{\hat{y}} = (\hat{y}_1,\hat{y}_2, … , \hat{y}_n)^T$</p></blockquote></li></ol><h2 id="反向传播的数学原理"><a href="#反向传播的数学原理" class="headerlink" title="反向传播的数学原理"></a>反向传播的数学原理</h2><p>反向传播，用于得到各网络层参数的更新量。主要有以下3个步骤：</p><ol><li>单个样本$\boldsymbol{x}$ 正向计算，得到各层的$\boldsymbol{z}$和$\boldsymbol{a}$备用。</li><li>计算输出层的参数更新量：<ol><li>求得损失$L$对$\boldsymbol{z}^{[l]}$的偏导$\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l]}}}$，记作$d\boldsymbol{z}^{[l]}$。上标$l$表示最后一层，即输出层。若输出层激活函数为$softmax$且损失函数为交叉熵，则有$d\boldsymbol{z}^{[l]} = softmax(\boldsymbol{z}^{[l]}) - \boldsymbol{y}$，对应的求导过程如下：<blockquote><p>$L = -\boldsymbol{y}^Tlog\hat{\boldsymbol{y}}$<br>$\downarrow$<br>$dL = -d\boldsymbol{y}^Tlog\hat{\boldsymbol{y}}-\boldsymbol{y}^Td(log\hat{\boldsymbol{y}})$<br>$= -\boldsymbol{y}^T d(log\hat{\boldsymbol{y}})$<br>$= -\boldsymbol{y}^Td(log(softmax(\boldsymbol{z}^{[l]})))$<br>$= -\boldsymbol{y}^Td(log(\frac{exp(\boldsymbol{\boldsymbol{z}^{[l]}})}{\boldsymbol{1}^Texp(\boldsymbol{\boldsymbol{z}^{[l]}})}))$<br>$= -\boldsymbol{y}^Td(log(exp(\boldsymbol{\boldsymbol{z}^{[l]}}))+\boldsymbol{1}log(\boldsymbol{1}^Texp(\boldsymbol{\boldsymbol{z}^{[l]}})))$<br>$= -\boldsymbol{y}^Td\boldsymbol{z}^{[l]} + d(log(\boldsymbol{1}^Texp(\boldsymbol{\boldsymbol{z}^{[l]}})))$<br>$= -\boldsymbol{y}^Td\boldsymbol{z}^{[l]} + \frac{d(\boldsymbol{1}^Texp(\boldsymbol{\boldsymbol{z}^{[l]}}))}{\boldsymbol{1}^Texp(\boldsymbol{\boldsymbol{z}^{[l]}})}$<br>$= -\boldsymbol{y}^Td\boldsymbol{z}^{[l]} + \frac{\boldsymbol{1}^T(exp(\boldsymbol{\boldsymbol{z}^{[l]}}) \odot d\boldsymbol{z}^{[l]} )}{\boldsymbol{1}^Texp(\boldsymbol{\boldsymbol{z}^{[l]}})}$<br>$= -\boldsymbol{y}^Td\boldsymbol{z}^{[l]} + {\frac{exp(\boldsymbol{\boldsymbol{z}^{[l]}})}{\boldsymbol{1}^Texp(\boldsymbol{z}^{[l]})}}^Td\boldsymbol{z}^{[l]}$<br>$= (softmax(\boldsymbol{z}^{[l]})-\boldsymbol{y}^T)^Td\boldsymbol{z}^{[l]}$<br>$\downarrow$<br>$tr(dL) = dL = tr((softmax(\boldsymbol{z}^{[l]})-\boldsymbol{y}^T)^Td\boldsymbol{z}^{[l]}) = tr({\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l]}}}}^Td\boldsymbol{z}^{[l]})$<br>$\downarrow$<br>$\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l]}}} = softmax(\boldsymbol{z}^{[l]})-\boldsymbol{y}^T$<br>$\downarrow$<br>$d\boldsymbol{z}^{[l]} = softmax(\boldsymbol{z}^{[l]})-\boldsymbol{y}^T$</p></blockquote></li><li>利用微分的分解+迹技巧实现链式法则，由$d\boldsymbol{z}^{[l]}$得到$d{\boldsymbol{W}^{[l]}}^T$，$d\boldsymbol{b}^{[l]}$，$d\boldsymbol{a}^{[l-1]}$<ul><li>$d{\boldsymbol{W}^{[l]}}^T$的求导过程如下：<blockquote><p>$tr(dL) = tr({\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l]}}}}^Td\boldsymbol{z}^{[l]})$<br>$= tr({\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l]}}}}^Td({\boldsymbol{W}^{[l]}}^T\boldsymbol{a}^{[l-1]}+\boldsymbol{b}^{[l]}))$<br>$= tr({\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l]}}}}^Td{\boldsymbol{W}^{[l]}}^T\boldsymbol{a}^{[l-1]})$<br>$= tr(\boldsymbol{a}^{[l-1]}{\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l]}}}}^Td{\boldsymbol{W}^{[l]}}^T)$<br>$= tr(({\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l]}}}}{\boldsymbol{a}^{[l-1]}}^T)^Td{\boldsymbol{W}^{[l]}}^T)$<br>$\downarrow$<br>$\frac{\partial{L}}{\partial{\boldsymbol{W}^{[l]}}^T} = {\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l]}}}}{\boldsymbol{a}^{[l-1]}}^T$<br>$\downarrow$<br>$d{\boldsymbol{W}^{[l]}}^T = d\boldsymbol{z}^{[l]}{\boldsymbol{a}^{[l-1]}}^T$</p></blockquote></li><li>$d\boldsymbol{b}^{[l]}$的求导过程<blockquote><p>$tr(dL) = tr({\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l]}}}}^Td\boldsymbol{z}^{[l]})$<br>$= tr({\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l]}}}}^Td({\boldsymbol{W}^{[l]}}^T\boldsymbol{a}^{[l-1]}+\boldsymbol{b}^{[l]}))$<br>$= tr({\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l]}}}}^Td\boldsymbol{b}^{[l]})$<br>$\downarrow$<br>$\frac{\partial{L}}{\partial{\boldsymbol{b}^{[l]}}} = {\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l]}}}}$<br>$\downarrow$<br>$d\boldsymbol{b}^{[l]} = d\boldsymbol{z}^{[l]}$</p></blockquote></li><li>$d\boldsymbol{a}^{[l-1]}$的求导过程如下：<blockquote><p>$tr(dL) = tr({\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l]}}}}^Td\boldsymbol{z}^{[l]})$<br>$= tr({\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l]}}}}^Td({\boldsymbol{W}^{[l]}}^T\boldsymbol{a}^{[l-1]}+\boldsymbol{b}^{[l]}))$<br>$= tr({\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l]}}}}^T{\boldsymbol{W}^{[l]}}^Td\boldsymbol{a}^{[l-1]})$<br>$= tr((\boldsymbol{W}^{[l]}\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l]}}})^Td\boldsymbol{a}^{[l-1]})$<br>$\downarrow$<br>$\frac{\partial{L}}{\partial{\boldsymbol{a}^{[l-1]}}} = {\boldsymbol{W}^{[l]}\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l]}}}}$<br>$\downarrow$<br>$d\boldsymbol{a}^{[l-1]} = \boldsymbol{W}^{[l]}d\boldsymbol{z}^{[l]}$</p></blockquote></li></ul></li><li>利用微分的分解+迹技巧实现链式法则，由$d\boldsymbol{a}^{[l-1]}$得到$d\boldsymbol{z}^{[l-1]}$，对应的求导过程如下：<blockquote><p>$tr(dL) = tr({\frac{\partial{L}}{\partial{\boldsymbol{a}^{[l-1]}}}}^Td\boldsymbol{a}^{[l-1]})$<br>$= tr({\frac{\partial{L}}{\partial{\boldsymbol{a}^{[l-1]}}}}^Td(g(\boldsymbol{z}^{[l-1]}))$<br>$= tr({\frac{\partial{L}}{\partial{\boldsymbol{a}^{[l-1]}}}}^T(g’(\boldsymbol{z}^{[l-1]}) \odot d\boldsymbol{z}^{[l-1]}))$<br>$= tr((\frac{\partial{L}}{\partial{\boldsymbol{a}^{[l-1]}}} \odot g’(\boldsymbol{z}^{[l-1]}))^T d\boldsymbol{z}^{[l-1]})$<br>$\downarrow$<br>$\frac{\partial{L}}{\partial{\boldsymbol{z}^{[l-1]}}} = \frac{\partial{L}}{\partial{\boldsymbol{a}^{[l-1]}}} \odot g’(\boldsymbol{z}^{[l-1]})$<br>$\downarrow$<br>$d\boldsymbol{z}^{[l-1]} = d\boldsymbol{a}^{[l-1]}\odot g’(\boldsymbol{z}^{[l-1]})$</p></blockquote></li></ol></li><li>仿照输出层的计算方式，反向传播，依次得到各层的参数更新量。<blockquote><p>$d\boldsymbol{z}^{[l]} = softmax(\boldsymbol{z}^{[l]}) - \boldsymbol{y}$<br>$d{\boldsymbol{W}^{[l]}}^T = d\boldsymbol{z}^{[l]}{\boldsymbol{a}^{[l-1]}}^T$ AND $d\boldsymbol{b}^{[l]} = d\boldsymbol{z}^{[l]}$<br>…<br>$d\boldsymbol{z}^{[j]} = (\boldsymbol{W}^{[j+1]}d\boldsymbol{z}^{[j+1]}) \odot g’(\boldsymbol{z}^{[j]})$<br>$d{\boldsymbol{W}^{[j]}}^T = d\boldsymbol{z}^{[j]}{\boldsymbol{a}^{[j-1]}}^T$ AND $d\boldsymbol{b}^{[j]} = d\boldsymbol{z}^{[j]}$<br>$d\boldsymbol{z}^{[j-1]} = (\boldsymbol{W}^{[j]}d\boldsymbol{z}^{[j]}) \odot g’(\boldsymbol{z}^{[j-1]})$<br>…<br>$d{\boldsymbol{W}^{[1]}}^T = d\boldsymbol{z}^{[1]}{\boldsymbol{a}^{[0]}}^T$ AND $d\boldsymbol{b}^{[1]} = d\boldsymbol{z}^{[1]}$<br>$d\boldsymbol{z}^{[0]} = (\boldsymbol{W}^{[1]}d\boldsymbol{z}^{[1]}) \odot g’(\boldsymbol{z}^{[0]})$</p></blockquote></li></ol><h2 id="梯度下降的数学原理"><a href="#梯度下降的数学原理" class="headerlink" title="梯度下降的数学原理"></a>梯度下降的数学原理</h2><p>梯度下降的思路：</p><ol><li>将整个模型视为一个以模型参数为自变量，以L为因变量，以样本数据为参数的函数</li><li>然后将模型参数寻优的问题转化为求这个函数最值和驻点的问题</li><li>然后基于这样一个原理<strong>自变量的数值沿梯度方向靠近时因变量的数值将随之向最值靠近</strong>，便可得到梯度下降公式：<blockquote><p>$\boldsymbol{W} -= \alpha d\boldsymbol{W}$<br>$\boldsymbol{b} -= \alpha d\boldsymbol{b}$</p></blockquote></li></ol><p>然后根据不同的实现，又有以下的梯度下降法变种：</p><ol><li>基于batch_size的不同<ul><li>batch_size = sample_size，称Batch Gradient Descent；</li><li>batch_size = 1，称Stocastic Gradient Descent；</li><li>batch_size介于两者之间，称Mini-Batch Gradient Descent;</li></ul></li><li>每次不是简单的减去更新量，而是减去更新量的移动平均值，即可得到GD with Momentum；其中移动平均的含义是取前n次更新量的平均值作为本次的更新量，$n=\frac{1}{1-\beta}$，$\beta$一般取0.9；<blockquote><p>$v^{d\boldsymbol{W}} = \beta v^{d\boldsymbol{W}} + (1-\beta)d\boldsymbol{W}$<br><br>$v^{d\boldsymbol{b}} = \beta v^{d\boldsymbol{b}} + (1-\beta)d\boldsymbol{b}$<br><br>$\boldsymbol{W} -= \alpha v^{d\boldsymbol{W}}$<br><br>$\boldsymbol{b} -= \alpha v^{d\boldsymbol{W}}$<br></p></blockquote></li><li>在上面的基础上，如果将用更新量的平方进行移动平均，然后再对移动平均值开方得到本次的更新量，即可得到RMSprop；<blockquote><p>$S^{d\boldsymbol{W}} = \beta S^{d\boldsymbol{W}} + (1-\beta)({d\boldsymbol{W}})^2$<br><br>$S^{d\boldsymbol{b}} = \beta S^{d\boldsymbol{b}} + (1-\beta)({d\boldsymbol{b}})^2$<br><br>$\boldsymbol{W} -= \alpha \frac{d\boldsymbol{W}}{\sqrt{S^{d\boldsymbol{W}}}}$<br><br>$\boldsymbol{b} -= \alpha \frac{d\boldsymbol{b}}{\sqrt{S^{d\boldsymbol{b}}}}$<br></p></blockquote></li><li>将2和3合并起来使用，即可得到Adam；<blockquote><p>$v^{d\boldsymbol{W}} = \beta_1 v^{d\boldsymbol{W}} + (1-\beta_1)d\boldsymbol{W}$<br><br>$v^{d\boldsymbol{b}} = \beta_1 v^{d\boldsymbol{b}} + (1-\beta_1)d\boldsymbol{b}$<br><br>$S^{d\boldsymbol{W}} = \beta_2 S^{d\boldsymbol{W}} + (1-\beta_2)({d\boldsymbol{W}})^2$<br><br>$S^{d\boldsymbol{b}} = \beta_2 S^{d\boldsymbol{b}} + (1-\beta_2)({d\boldsymbol{b}})^2$<br><br>$\boldsymbol{W} -= \alpha \frac{v^{d\boldsymbol{W}}}{\sqrt{S^{d\boldsymbol{W}}}+\epsilon}$<br><br>$\boldsymbol{b} -= \alpha \frac{v^{d\boldsymbol{b}}}{\sqrt{S^{d\boldsymbol{b}}}+\epsilon}$<br></p></blockquote></li></ol><h2 id="归一化的数学原理"><a href="#归一化的数学原理" class="headerlink" title="归一化的数学原理"></a>归一化的数学原理</h2><p>在向量化和Mini-Batch的前提下，每一层的中间值$Z^{[j]}$先进行跨样本的normalization之后再进行激活，就是所谓的归一化。</p><blockquote><p>矩阵$Z^{[j]}$按行求算数平均，得到均值列向量$\bar{z}$；<br>矩阵$Z^{[j]}$与均值列向量$\bar{z}$进行标准差运算，得到标准差矩阵$\boldsymbol{\Sigma}$；<br>矩阵$Z^{[j]}$的每一列都减去均值列向量$\bar{z}$后，再逐元素除以标准差矩阵$\boldsymbol{\Sigma}$即可得到归一化后的新中间值矩阵。</p></blockquote><p>另外归一化还存在一个小问题，就是他的前提是向量化和Mini-Batch，就是说跨样本求均值和方差的基础是有多个样本。但是在完成模型训练之后进行预测时，肯定都是每次喂到模型中一个样本，那么此时如何求均值和方差呢？毕竟最好怎么训练出来的怎么用嘛。</p><p>一般的做法是，在这个训练过程中用移动平均数实时追踪均值和方差，或者用整个训练集的均值和方差也行，问题不大，而且主流的DL框架一般都封装好了。</p><h2 id="正则化的数学原理"><a href="#正则化的数学原理" class="headerlink" title="正则化的数学原理"></a>正则化的数学原理</h2><p>正则化是一种缓解高方差，过拟合问题的措施。具体做法是在原有的损失函数之后额外增加一个关于权重矩阵的损失项，这样一来权重越大损失就越大，随着训练的进行权重会越来越趋近于0，变相地降低了模型的参数量，缓解了过拟合。</p><p>常用的两种正则化方式如下，</p><script type="math/tex; mode=display">L = L_{original} + L_1 = L_{original} + \lambda \sum_{i = 0}^{l} \lvert\lvert \boldsymbol{W}^{[i]} \rvert\rvert _1</script><script type="math/tex; mode=display">L = L_{original} + L_2 = L_{original} + \frac{\lambda}{2} \sum_{i = 0}^{l}  \lvert\lvert \boldsymbol{W}^{[i]} \rvert\rvert ^2_2</script><h3 id="L1正则化"><a href="#L1正则化" class="headerlink" title="L1正则化"></a>L1正则化</h3><p>$\lvert\lvert \boldsymbol{W}^{[i]} \rvert\rvert _1$的含义是矩阵$\boldsymbol{W}^{[i]}$每个元素的绝对值的总和，被称为L1正则化，最后容易得到稀疏的权重矩阵，有利于后续的剪枝和模型压缩。对应地，由于$d\boldsymbol{W}^{[i]}$是$L$关于$\boldsymbol{W}^{[i]}$的偏导，此时有</p><script type="math/tex; mode=display">d\boldsymbol{W}^{[i]} = d\boldsymbol{W}^{[i]}_{original} + \lambda</script><script type="math/tex; mode=display">\boldsymbol{W}^{[i]} -= \alpha (d\boldsymbol{W}^{[i]}_{original} + \lambda)</script><h3 id="L2正则化"><a href="#L2正则化" class="headerlink" title="L2正则化"></a>L2正则化</h3><p>$\lvert\lvert \boldsymbol{W}^{[i]} \rvert\rvert ^2_2$的含义是矩阵$\boldsymbol{W}^{[i]}$每个元素的平方的总和，被称为L2正则化，最后得到的权重矩阵较为平滑，被广泛用于防止过拟合。此时有</p><script type="math/tex; mode=display">d\boldsymbol{W}^{[i]} = d\boldsymbol{W}^{[i]}_{original} + \lambda \boldsymbol{W}^{[i]}</script><script type="math/tex; mode=display">\boldsymbol{W}^{[i]} -= \alpha (d\boldsymbol{W}^{[i]}_{original} + \lambda \boldsymbol{W}^{[i]})</script><p>从L2正则权重更新的公式可以看出，相对于在不加正则的基础上，先将原矩阵乘以$1-\alpha\lambda$因子，然后在进行参数更新，因此L2正则又被称为权重衰减。</p><h3 id="正则权重更新公式推导"><a href="#正则权重更新公式推导" class="headerlink" title="正则权重更新公式推导"></a>正则权重更新公式推导</h3><p>本来想用矩阵求导术推导出加入正则后的$d\boldsymbol{W}^{[i]}$，但是好像不太适用。所以这里就离散的理解一下好了，比如对于L2正则，求其对于某一层的权重矩阵的偏导$d\boldsymbol{W}^{[i]}$时是不依赖于链式法则的。首先，因为求的是偏导，其它层的W项自动忽略。然后将矩阵打开来看，分别对每一个标量w求偏导，此时其他w自动忽略。</p><script type="math/tex; mode=display">d\boldsymbol{W}^{[i]}_{l2} = \frac{\partial L_2}{\partial \boldsymbol{W}^{[i]}} =\left[\begin{array}{cccc}  \frac{\partial L_2}{w^{[i]}_{11}} & \frac{\partial L_2}{w^{[i]}_{12}}       & \cdots & \frac{\partial L_2}{w^{[i]}_{1n}}       \\ \frac{\partial L_2}{w^{[i]}_{21}}       & \frac{\partial L_2}{w^{[i]}_{22}}       &{\cdot^{\cdot^{\cdot}}} & \frac{\partial L_2}{w^{[i]}_{2n}}       \\ \vdots & \vdots & \ddots & \vdots \\ \frac{\partial L_2}{w^{[i]}_{m1}}       & \frac{\partial L_2}{w^{[i]}_{m2}}       & \cdots & \frac{\partial L_2}{w^{[i]}_{mn}}       \\\end{array}\right]</script><script type="math/tex; mode=display">L_2 = \frac{\lambda}{2} (w_{11}^2 + w_{12}^2 + w_{13}^2 + ... + w_{mn}^2)</script><script type="math/tex; mode=display">\frac{\partial L_2}{w^{[i]}_{11}} = \frac{\lambda}{2} \cdot 2w^{[i]}_{11}</script><script type="math/tex; mode=display">d\boldsymbol{W}^{[i]}_{l2} = \lambda \boldsymbol{W}^{[i]}</script>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>神经网络</tag>
      
      <tag>DNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CSAPP并发编程总结</title>
    <link href="/2021/07/09/CSAPP%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E6%80%BB%E7%BB%93/"/>
    <url>/2021/07/09/CSAPP%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<h2 id="并发编程基本概念"><a href="#并发编程基本概念" class="headerlink" title="并发编程基本概念"></a>并发编程基本概念</h2><ul><li><strong>并发</strong>：多个逻辑控制流的生命周期有重叠，即称为<strong>并发现象</strong>(concurrency)</li><li><strong>并行</strong>：发生在多核/多计算机上的并发现象（在一个时刻上存在多个逻辑控制流），称为<strong>并行现象</strong>（parallel），是并发现象的真子集；</li></ul><h2 id="并发程序的三种构造方式："><a href="#并发程序的三种构造方式：" class="headerlink" title="并发程序的三种构造方式："></a>并发程序的三种构造方式：</h2><ul><li><strong>进程</strong>：每个逻辑控制流实现为一个进程<ul><li>特点：独立的虚拟地址空间</li><li>优点：独立则不易混淆</li><li>缺点：<ul><li>独立则难以共享数据</li><li>进程context切换和IPC开销高，所以往往比较慢（ 进程间通信机制）</li></ul></li></ul></li><li><strong>I/O多路复用</strong>：状态机化，逻辑控制流的切换实现为状态机的状态切换。具体原理看<a href="https://www.zhihu.com/question/32163005/answer/55772739">这个</a><ul><li>优点：共享数据容易，并且没有进程context切换的开销</li><li>缺点：编码复杂，不能充分利用多核处理器</li></ul></li><li><strong>线程</strong>：重点，下面展开讲。</li></ul><h2 id="线程基本概念："><a href="#线程基本概念：" class="headerlink" title="线程基本概念："></a>线程基本概念：</h2><ul><li><strong>主线程</strong>：进程中第一个运行的线程</li><li><strong>对等线程</strong>：进程中后来运行的线程</li><li><strong>与进程的区别</strong>：<ul><li>上下文内容少，切换更快，开销更少，具体包括：线程ID、栈和栈指针、PC、条件码、register value</li><li>一个进程的所有线程（对等线程池）彼此之间没有层次结构，都是对等的；</li><li>对等线程之间共享进程的虚拟地址空间，可以等待另外一个对等线程终止或主动杀死它</li></ul></li><li><strong>共享变量</strong>：一个变量的一个实例被不止一个线程引用，那么这个变量称为共享变量</li><li><strong>线程安全的函数</strong>：被多个并发线程反复调用时能够一直产生正确结果的函数称为线程安全函数</li><li><strong>可重入函数</strong>：线程安全函数的一个真子集，指不会引入任何共享数据的函数<ul><li><strong>显式可重入</strong>：传参均为值传递（且非指针值传递），而且所有数据引用的都是本地自动栈变量</li><li><strong>隐式可重入</strong>：在显式的基础上取消“值传递（且非指针值传递）”的限制，允许指针值传递和引用传递，但是传递的变量都是非共享变量时，该函数是隐式可重入的</li></ul></li><li><strong>竞争</strong>：程序的正确性依赖于某条/某些特定的轨迹线，或者说不是全部的轨迹线都能让程序正确执行，哪怕是那些绕过了互斥锁禁止区的全部轨迹线也不行。（具体例子见CSAPP P719）</li></ul><h2 id="Posix线程模型："><a href="#Posix线程模型：" class="headerlink" title="Posix线程模型："></a>Posix线程模型：</h2><p>管理Linux线程的C语言接口包<pthread.h>，包含大约60个函数。</p><ul><li><strong>线程例程概念</strong>：接受和返回一个void指针的函数类型，其内容为线程真正要做的事。若输入输出的参数较多，应封装为一个结构体。</li><li><strong>常用的pthread函数</strong>：<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">/*创建线程*/</span><br>int pthread_creat(&amp;tid, NULL, thread, NULL)<br><span class="hljs-regexp">//</span>(返回线程ID，设置线程属性(高阶内容)，线程例程函数名，线程例程函数的传参)，成功返回<span class="hljs-number">0</span>，否则非<span class="hljs-number">0</span><br><br><span class="hljs-regexp">/*终止线程*/</span><br><span class="hljs-regexp">//</span>方式<span class="hljs-number">1</span>：某个对等线程的例程函数执行完毕，该线程会隐式终止<br><span class="hljs-regexp">//</span>方式<span class="hljs-number">2</span>：某个对等线程调用pthread_exit函数，线程会显式终止，而且如果是主线程调用，它会等待所有其他对等线程终止后再终止（进程也被终止了）<br>void pthread_exit(void *thread_return) <span class="hljs-regexp">//</span>函数不返回（因为逻辑控制流都结束了啊），会将一些信息写到thread_return中<br><span class="hljs-regexp">//</span>方式<span class="hljs-number">3</span>：某个对等线程调用系统<span class="hljs-keyword">exit</span>函数，终止其所属进程及该进程所有的线程<br><span class="hljs-regexp">//</span>方式<span class="hljs-number">4</span>：某个对等线程调用pthread_cancel函数，终止另一个对等线程<br>int pthread_cancel(pthread_t tid)  <span class="hljs-regexp">//</span>终止线程ID为tid的对等线程，成功返回<span class="hljs-number">0</span>，否则非<span class="hljs-number">0</span><br><br><span class="hljs-regexp">/*回收已终止线程的资源*/</span><br>int pthread_join(pthread_t tid, void**thread_return) <span class="hljs-regexp">//</span>调用该函数的对等线程阻塞，等待线程ID为tid的对等线程结束，然后回收其资源后返回<br><br><span class="hljs-regexp">/*分离线程*/</span><br><span class="hljs-regexp">//</span>一个线程的状态要么是detached要么是joinable，处于后者时意味着可以被其他线程杀死和回收资源，前者不可（自行终止，系统回收资源）<br>int pthread_detach(pthread_t tid)  <span class="hljs-regexp">//</span>调用该函数的对等线程将线程ID为tid的线程分离<br><br><span class="hljs-regexp">/*获取自身ID*/</span><br>pthread_t pthread_self();<br></code></pre></td></tr></table></figure></li></ul><h2 id="线程的内存模型（两个关键问题）"><a href="#线程的内存模型（两个关键问题）" class="headerlink" title="线程的内存模型（两个关键问题）"></a>线程的内存模型（两个关键问题）</h2><ul><li><strong>线程的内存模型是怎样的？</strong>——不是整齐清楚的。。。</li><li><strong>变量的实例如何映射到线程的内存模型中？</strong><ul><li>全局变量+局部的静态变量：一个进程中只有一个实例，任何线程均可引用；</li><li>局部的自动变量：多个实例，由各个线程栈自行管理。</li></ul></li></ul><h2 id="线程共享变量的冲突问题"><a href="#线程共享变量的冲突问题" class="headerlink" title="线程共享变量的冲突问题"></a>线程共享变量的冲突问题</h2><p>关键字：进度图-&gt;信号量-&gt;PV操作-&gt;互斥锁-&gt;互斥锁加/解锁-&gt;死锁</p><ul><li><strong>进度图</strong>：注意把P/V操作放到线段上，状态放到端点上，这样端点的状态即可解释为执行P/V操作前或者P/V操作后</li><li><strong>信号量</strong>s：一个非负整数全局变量</li><li><strong>PV操作</strong>（原子操作）：<ul><li>P(s)操作：检查s是否为0；<ul><li>是，则调用该函数的线程在此处阻塞；</li><li>否，则将s减1后继续向下执行；</li></ul></li><li>V(s)操作：先将s加1，然后检查有么有因为P(s)阻塞的线程，如有则将完成其P操作，然后置为就绪状态（等待调度），若没有那就没有。。若有不止一个，就随机选择一个，反正只能一个（因为要完成P操作啊）</li></ul></li><li><strong>互斥锁</strong>：二元的信号量</li><li><strong>互斥锁加/解锁</strong>：针对二元信号量的P/V操作</li><li><strong>死锁</strong>：<br>禁止区外存在这样一些状态点，既不能向右，也不能向上，因为向上会进入线程A的禁止区，向右会进入线程B的禁止区。<br><br>通过以下原则来防止死锁：<br>给定所有互斥操作的一个全序( 全序概念)，如果每个线程都是以该全序获得互斥锁并以相反的顺序（不是说全序的逆序，而是线程A和线程B释放的顺序相反）释放，那么这个程序就不会出现死锁。（但是该原则现在看下来只适用于两个线程，更多的线程就要用到更复杂的银行家算法了）<br><br>例如：<br><ul><li>线程1： P(s) -&gt; P(t) -&gt; V(t) -&gt; V(s);</li><li>线程2： P(s) -&gt; P(t) -&gt; V(s) -&gt; V(t);</li></ul></li></ul><h2 id="并行程序的性能量化（暂时略过）"><a href="#并行程序的性能量化（暂时略过）" class="headerlink" title="并行程序的性能量化（暂时略过）"></a>并行程序的性能量化（暂时略过）</h2><h2 id="信号量用于共享资源调度（暂时略过）"><a href="#信号量用于共享资源调度（暂时略过）" class="headerlink" title="信号量用于共享资源调度（暂时略过）"></a>信号量用于共享资源调度（暂时略过）</h2>]]></content>
    
    
    <categories>
      
      <category>工作技能</category>
      
      <category>操作系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>并发编程</tag>
      
      <tag>线程</tag>
      
      <tag>信号量</tag>
      
      <tag>锁</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何用vim写markdown</title>
    <link href="/2021/07/08/%E5%A6%82%E4%BD%95%E7%94%A8vim%E5%86%99markdown/"/>
    <url>/2021/07/08/%E5%A6%82%E4%BD%95%E7%94%A8vim%E5%86%99markdown/</url>
    
    <content type="html"><![CDATA[<h1 id="安装neovim"><a href="#安装neovim" class="headerlink" title="安装neovim"></a>安装neovim</h1><blockquote><p>sudo apt-get install neovim<br>neovim<br>:checkhealth</p></blockquote><h1 id="安装vim插件管理器vim-plug"><a href="#安装vim插件管理器vim-plug" class="headerlink" title="安装vim插件管理器vim-plug"></a>安装vim插件管理器vim-plug</h1><blockquote><p>sh -c ‘curl -fLo “${XDG_DATA_HOME:-$HOME/.local/share}”/nvim/site/autoload/plug.vim —create-dirs<br><a href="https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim">https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim</a>‘</p></blockquote><p>链接不上的话，需要：<br></p><blockquote><p>sudo nvim /etc/hosts<br></p></blockquote><p>添加一行：<br></p><blockquote><p>199.232.96.133 raw.githubusercontent.com<br></p></blockquote><p>其中的ip地址来自于<em><a href="https://githubusercontent.com.ipaddress.com/raw.githubusercontent.com">https://githubusercontent.com.ipaddress.com/raw.githubusercontent.com</a></em></p><h1 id="创建neovim配置文件init-vim"><a href="#创建neovim配置文件init-vim" class="headerlink" title="创建neovim配置文件init.vim"></a>创建neovim配置文件init.vim</h1><blockquote><p>mkdir .config/nvim<br>touch .config/nvim/init.vim</p></blockquote><h1 id="修改init-vim以添加插件"><a href="#修改init-vim以添加插件" class="headerlink" title="修改init.vim以添加插件"></a>修改init.vim以添加插件</h1><p>目录，markdown，preview一共三个暂时（修改的内容直接看文件）,<br>中间: </p><ul><li>遇到了自动折叠问题：修改配置文件解决  </li><li>又遇到了无法预览的问题，看github<a href="https://github.com/iamcco/markdown-preview.nvim/issues/120">作者回复</a>解决</li></ul>]]></content>
    
    
    <categories>
      
      <category>生活记录</category>
      
      <category>电脑设置</category>
      
    </categories>
    
    
    <tags>
      
      <tag>vim</tag>
      
      <tag>markdown</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
