

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/time.jpg">
  <link rel="icon" href="/img/time.jpg">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="王者之路，就在脚下">
  <meta name="author" content="William Guo">
  <meta name="keywords" content="">
  
  <title>Faster RCNN源码分析（零）—— 整体框架 by 电竞大师小明</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.11","typing":{"enable":true,"typeSpeed":70,"cursorChar":"","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"ApWFLRBvVptYicRhN7DQqrOa-gzGzoHsz","app_key":"ihFV8rR5s2zuqoKPXqW9sydt","server_url":"https://apwflrbv.lc-cn-n1-shared.com"}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>电竞大师小明</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/article.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.7)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="Faster RCNN源码分析（零）—— 整体框架">
              
            </span>

            
              <div class="mt-3">
  
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      4.2k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      49
       分钟
    </span>
  

  
  
    
      <!-- LeanCloud 统计文章PV -->
      <span id="leancloud-page-views-container" class="post-meta" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="leancloud-page-views"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Faster RCNN源码分析（零）—— 整体框架</h1>
            
              <p class="note note-info">
                
                  本文最后更新于：3 天前
                
              </p>
            
            <div class="markdown-body">
              <h2 id="0-前言"><a href="#0-前言" class="headerlink" title="0. 前言"></a>0. 前言</h2><p>两段式目标检测的代表作，相当复杂。</p>
<p>基于pytorch的源码，捋一遍Faster-RCNN到底干了啥。</p>
<p>这里先说一下框架，后面有时间再开几篇依次展开说各个子流程的代码实现细节。</p>
<div align=center><img title="" src="/img/article/fr-rcnn-frame.jpg" srcset="/img/loading.gif" lazyload width="100%" height="100%" align=center></div>

<h2 id="1-从dataset加载图像"><a href="#1-从dataset加载图像" class="headerlink" title="1. 从dataset加载图像"></a>1. 从dataset加载图像</h2><p>首先要从把标注好的图像文件以及标注xml文件读取进来。</p>
<p>参考<a target="_blank" rel="noopener" href="https://guohongming.xyz/2021/08/12/%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86/">这里</a>自定义的dataset类，可以知道，dataloader每次迭代返回的是，dataset类<code>__getitem__</code>方法的返回值经过自定义的collate_fn包装过的结果，也就是image tensor的tuple，targets dict的tuple。</p>
<p>而后在送入模型之前，还将tuple转为list，便于cat/stack之类的操作。</p>
<p>另外图像的BN、增广等操作也在这里进行。</p>
<p><strong>本阶段数据转化结果:</strong></p>
<ul>
<li><p><strong>image</strong>: jpg -&gt; [tensor(3x350x450), tensor(3x375x500)]，3x375x450指图像的原始尺寸</p>
</li>
<li><p><strong>target</strong>: xml -&gt; [dict1, dict2]，dict的结构详见<a target="_blank" rel="noopener" href="https://guohongming.xyz/2021/08/12/%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86/">这里</a></p>
</li>
</ul>
<h2 id="2-图像预处理"><a href="#2-图像预处理" class="headerlink" title="2. 图像预处理"></a>2. 图像预处理</h2><p>原始图像的尺寸是不保证一致的，因此送入模型的图像都要先进行尺寸缩放、padding等操作。</p>
<p><strong>本阶段数据转化结果:</strong></p>
<ul>
<li><strong>image</strong>: [tensor(3x350x450), tensor(3x375x500)] -&gt; ImageList，ImageList是一个同时保存预处理之后的图像数据以及padding前缩放后图像尺寸的类。如<figure class="highlight clojure"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs clojure">&#123;image_sizes = [(<span class="hljs-number">800</span>,<span class="hljs-number">1028</span>), (<span class="hljs-number">800</span>, <span class="hljs-number">1066</span>)]<br>tensors = tensor(<span class="hljs-number">2</span>x3x800x1088)&#125;<br></code></pre></td></tr></table></figure></li>
<li><strong>target</strong>: [dict1, dict2] -&gt; [dict1, dict2]，数据类型没有变化，只是其中boxes的坐标进行了同比例缩放</li>
</ul>
<h2 id="3-Backbone"><a href="#3-Backbone" class="headerlink" title="3. Backbone"></a>3. Backbone</h2><p>使用经典分类网络的特征提取部分，作为Backbone，来得到feature map。</p>
<p>以配备了FPN结构的ResNet50为例，Backbone接受上一步的ImageList.tensors之后，将输出5个feature map。这5个feature map被组织为一个dict。</p>
<p><strong>本阶段数据转化结果:</strong></p>
<ul>
<li><strong>image</strong>: ImageList -&gt; <strong>features</strong>: dict，dict的结构如下，<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">features</span> = &#123;<br><span class="hljs-attribute">0</span> : tensor(<span class="hljs-number">2</span>x<span class="hljs-number">256</span>x<span class="hljs-number">200</span>x<span class="hljs-number">272</span>),<br><span class="hljs-attribute">1</span> : tensor(<span class="hljs-number">2</span>x<span class="hljs-number">256</span>x<span class="hljs-number">100</span>x<span class="hljs-number">136</span>),<br><span class="hljs-attribute">2</span> : tensor(<span class="hljs-number">2</span>x<span class="hljs-number">256</span>x<span class="hljs-number">50</span>x<span class="hljs-number">68</span>),<br><span class="hljs-attribute">3</span> : tensor(<span class="hljs-number">2</span>x<span class="hljs-number">256</span>x<span class="hljs-number">25</span>x<span class="hljs-number">34</span>),<br><span class="hljs-attribute">pool</span> : tensor(<span class="hljs-number">2</span>x<span class="hljs-number">256</span>x<span class="hljs-number">13</span>x<span class="hljs-number">17</span>)&#125;<br></code></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="4-RPN"><a href="#4-RPN" class="headerlink" title="4. RPN"></a>4. RPN</h2><p>RPN可谓是Faster RCNN算法的核心，所有关键内容基本上都杂糅在其中。后续的预测结构，损失也都跟RPN类似。具体来看，依次做了这几件事：</p>
<h3 id="4-1-RPN-Head"><a href="#4-1-RPN-Head" class="headerlink" title="4.1 RPN Head"></a>4.1 RPN Head</h3><p>将所有feature map的value组装为一个list，送入RPN head结构，生成两个量：</p>
<ul>
<li>针对proposal的置信度参数objectness，一个跟输入对应的list</li>
<li>针对proposal的边界框回归参数anchor_box_reg，同样是一个跟输入对应的list</li>
</ul>
<p><strong>本阶段数据转化结果</strong></p>
<ul>
<li><strong>features</strong>: dict -&gt; <strong>objectness</strong>: [tensor(2x3x200x272), tensor(2x3x100x136)，tensor(2x3x50x68)，tensor(2x3x25x34)，tensor(2x3x13x17)]<br>其中[B,C,H,W]中只有C维度的size发生改变，新值3的含义是要在这个feature map上的每一个HW cell上产生3个proposal，tensor的值表示对应proposal的置信度。</li>
<li><strong>features</strong>: dict -&gt; <strong>anchor_box_reg</strong>: [tensor(2x12x200x272), tensor(2x12x100x136)，tensor(2x12x50x68)，tensor(2x12x25x34)，tensor(2x12x13x17)]<br>其中C维度12表示每个HW cell上3个proposal的4个边界框回归参数。</li>
</ul>
<h3 id="4-2-AnchorGenerate"><a href="#4-2-AnchorGenerate" class="headerlink" title="4.2 AnchorGenerate"></a>4.2 AnchorGenerate</h3><p>为每一层feature map上的一个HW cell生成一套anchor。</p>
<p>anchor是基于规则生成的，而非输入图像的数据，因此需要指定一套包含几个anchor，每个anchor的面积以及HW比例。生成的这些anchor都用相对于某个中心点的相对坐标表示。</p>
<p>然后定位每feature map的HW cell在原图上的感受野，取感受野左上角元素为中心点，计算得到所有feature map上所有cell的所有anchor在原图上的绝对坐标，用一个list表示。</p>
<p><strong>本阶段数据转化结果</strong></p>
<ul>
<li><strong>anchor参数</strong> -&gt; <strong>anchor_list</strong> : [tensor(217413x4), tensor(217413x4)]<br>其中，2个tensor对应本batch的2张图像，而且2个tensor的值完全相同，因为anchor是按照规则生成的，只和图像的尺寸有关，与图像的数据无关。另外，$217413 = (200\times272 + 100\times136 + 50\times68 + 25\times34 + 13\times17)\times3$。</li>
</ul>
<h3 id="4-3-DecodeProposal"><a href="#4-3-DecodeProposal" class="headerlink" title="4.3 DecodeProposal"></a>4.3 DecodeProposal</h3><p>用anchor_box_reg和anchor_list进行decode操作，得到proposal，如<code>tensor(2x217413x4)</code>。decode/encode公式如下：</p>
<script type="math/tex; mode=display">
P_x=A_x + A_wd_x</script><script type="math/tex; mode=display">
P_y=A_y + A_hd_y</script><script type="math/tex; mode=display">
P_w=A_we^{d_w}</script><script type="math/tex; mode=display">
P_h=A_he^{d_h}</script><p>式中，$(A_x, A_y, A_w, A_h)$和$(d_x, d_y, d_w, d_h)$分别为anchor_list和anchor_box_reg的元素，在这里是已知。$(P_x, P_y, P_w, P_h)$为proposal的元素，在这里是未知。</p>
<p><strong>本阶段数据转化结果</strong></p>
<ul>
<li><strong>anchor_list</strong>: [tensor(217413x4), tensor(217413x4)] + <strong>anchor_box_reg</strong>: [tensor(2x12x200x272), tensor(2x12x100x136)，tensor(2x12x50x68)，tensor(2x12x25x34)，tensor(2x12x13x17)] -&gt; <strong>proposals</strong>: tensor(2x217413x4)</li>
</ul>
<h3 id="4-4-FilterProposal"><a href="#4-4-FilterProposal" class="headerlink" title="4.4 FilterProposal"></a>4.4 FilterProposal</h3><p>遍历本batch中的图片，过滤每张图片这数十万个proposal，每张图片只保留2000个/1000个（前者对应训练模式，后者对应预测模式）。筛选的规则如下</p>
<ol>
<li>将每一个feature map得到的proposal视为一个集合，取每个集合中objectness值最大的前2000个/1000个，不足则都算上。</li>
<li>将proposal中的越界坐标调整到图像边界上，然后去除H或W小于某个阈值的proposal。</li>
<li>去除对应的score小于阈值的proposal，其中score由objectness经sigmoid之后得到。</li>
<li>将所有feature map得到proposal视为一个集合，对这个集合做nms，去除与highscore box的iou大于0.7的lowscore box。其中各个feature map之间的proposal不滤除，就是说不会因为f1中的一个highscore box和f2中的一个lowscore box的iou过大，而去除这个lowscore box。</li>
<li>在nms之后的结果中，取score最大的前2000个/1000个，作为最终的proposal。</li>
</ol>
<p>最终得到proposal和score的list。</p>
<p><strong>本阶段数据转化结果</strong></p>
<ul>
<li><strong>proposals</strong>: tensor(2x217413x4) -&gt; [tensor(2000x4), tensor(2000x4)]</li>
<li><strong>objectness</strong>: [tensor(2x3x200x272), tensor(2x3x100x136)，tensor(2x3x50x68)，tensor(2x3x25x34)，tensor(2x3x13x17)] -&gt; <strong>socores</strong>: [tensor(2000x4), tensor(2000x4)]</li>
</ul>
<h3 id="4-5-ComputeLoss"><a href="#4-5-ComputeLoss" class="headerlink" title="4.5 ComputeLoss"></a>4.5 ComputeLoss</h3><p>如果是预测模式，那么到上一步RPN模块的工作就结束了。但如果是训练模式，还要继续进行RPN loss的计算。</p>
<blockquote>
<p>备注一下，pytorch中计算RPN损失不是基于Filter之后的那2000个proposal，而是在原有的217413个proposal中进行随机抽样256个box，并且尽量保证正负样本的比例为1:1，正样本不够的话就有多少都算上。</p>
</blockquote>
<p>我们知道，计算损失的目的是为了量化模型<strong>预测结果</strong>和<strong>真实信息</strong>的偏离程度。对于RPN而言，模型输出的<strong>预测结果</strong>是这些proposal，与之对比的<strong>真实信息</strong>是图片的GTbox。而对比一个proposal box和一个GTbox，其实是对比他们两个相同属性——坐标&amp;标签，那么量化偏离程度就要从两个角度出发：</p>
<script type="math/tex; mode=display">
L = \frac{1}{N}\sum_{i}^{N}{L_{cls}(p_i, p_i^*)} + \lambda \frac{1}{N}\sum_{i}^{N}p_i^*{L_{box}}</script><script type="math/tex; mode=display">
L_{cls}(p_i, p_i^*) = -[p_i^*\ln{p_i}+(1-p_i^*)\ln(1-p_i)]</script><script type="math/tex; mode=display">
L_{box} = \sum_{i = x,y,w,h} smooth_{L1}(d_i-d_i^*)</script><p>以上式中</p>
<ul>
<li>前后两个N在原论文中是不同的值，但是在pytorch源码中，就直接等同为抽样数量了。</li>
<li>$p_i$指objectness的值，$p_i^*$指proposal的真实标签。</li>
<li>$\lambda$用来平衡两个损失项，pytorch实现中直接取消了。</li>
<li>$d_i$指anchor_box_reg的值，$d_i^*$指anchor和与其匹配的GTbox解码出来的边界框回归参数。</li>
<li>$L_{cls}(p_i,p_i^*)$在原文中是softmax函数，但是因为只有两类，pytorch直接用二值交叉熵进行计算。</li>
</ul>
<h4 id="4-5-1-边界框坐标损失计算"><a href="#4-5-1-边界框坐标损失计算" class="headerlink" title="4.5.1 边界框坐标损失计算"></a>4.5.1 边界框坐标损失计算</h4><p>首先，为anchor_list中的所有anchor分配一个最佳匹配的GTbox（来自图像标注信息target）。匹配的规则是，对于一张图片的一个anchor，计算其与本图片所有GTbox的IOU，与其有最大IOU的那个GTbox，称之为该anchor的最佳匹配GTbox。获得了anchor和GTbox之间的匹配关系后，即可进行预测信息与GT信息之间的对比，从而得到偏离程度，亦即loss。现在有，</p>
<p><strong>因为</strong>：<br></p>
<ul>
<li>anchor坐标 + 真实的边界框编码参数 -&gt; GTbox坐标</li>
<li>anchor坐标 + 预测的边界框编码参数 -&gt; proposal坐标</li>
</ul>
<p><strong>因此</strong>：<br></p>
<ul>
<li>对比proposal和GTbox坐标的偏离程度等价于对比真实的和预测的边界框编码参数</li>
</ul>
<p>前者利用anchor和与之匹配的GTbox进行decode得到，后者就是RPN Head输出的anchor_box_reg。这样便得到了边界框坐标损失。</p>
<h4 id="4-5-2-前-后景分类损失计算"><a href="#4-5-2-前-后景分类损失计算" class="headerlink" title="4.5.2 前/后景分类损失计算"></a>4.5.2 前/后景分类损失计算</h4><p>前/后景分类损失反映的是一个proposal box的<strong>真实标签</strong>与<strong>预测标签</strong>的差异程度。我们已知<strong>预测标签</strong>就是每一个proposal的objectness值，那么一个proposal的<strong>真实标签</strong>是什么呢？至少我们的标注信息中是没有直接包含这一信息的。一种合适的做法是，比较同源的一对GTbox和proposal box之间的IOU。</p>
<blockquote>
<p>所谓同源是指，在5.1小节中我们建立了每一个anchor和Gtbox之间的匹配关系，而每一个anchor与RPN head输出的anchor_box_reg结合可以得到一个proposal box，这样这个anchor便将Gtbox和proposal box联系起来了。</p>
</blockquote>
<p>具体的做法如下：</p>
<ol>
<li>若它们的IOU极大，说明重合度高，应认为这个proposal是一个前景的提案，其真实标签应为“前景”；</li>
<li>若它们的IOU极小，说明重合度低，应认为这个proposal是一个背景的提案，其真实标签应为“背景”；</li>
<li>若IOU不大也不小，那么简单地将其视为无效的样本，并且不将其计入损失计算过程。</li>
</ol>
<p>获得proposal的<strong>真实标签（labels）</strong>之后，便可将labels和objectness代入交叉熵公式计算损失了。</p>
<h2 id="5-ROI-Align"><a href="#5-ROI-Align" class="headerlink" title="5. ROI Align"></a>5. ROI Align</h2><p>RPN之后，下一步操作所依赖的原理是：经过训练的RPN现在输出的proposal在一定程度上已经足够准确了，可以将一个proposal box认为是一张只包含一个目标的小图片，然后将目标检测的问题转化为图像分类的问题。具体来讲，得到proposal之后，这张小图片从原图上哪个位置截取已经知道了，但是截取下来的内容还不知道，所以要进行本段内容描述的操作。</p>
<blockquote>
<p>备注一下，跟RPN计算损失时一样，从这里往后的损失计算也不是所有217413个proposal都使用，而是只在Filter之后的2000个之中随机抽样512个，并且尽可能地保证正负样本比例为1:3。如果是预测模式则不抽样。</p>
<p>另外也不是所有feature map都使用，pooling出来的那一层数据后面也不用。</p>
</blockquote>
<p>因此，我们应该将proposal box框住的feature map区域当做下一步处理的对象（而不是原图）。这引入了3个问题：</p>
<ol>
<li>RPN得到的proposal box角点坐标都是基于原图的，如何知道一个proposal在feature map上所对应区域的角点坐标呢？</li>
<li>在FPN介入的情况下，feature map有多个，如何知道将一个proposal box映射到哪个feature map上呢？</li>
<li>proposal box有大有小，从原图到不同feature map上的映射比例也不尽相同，怎么封装成一个合适的tensor供后续处理呢？</li>
</ol>
<p>对于第一个问题，确定原图到feature map之间的比例，然后对proposal box坐标进行等比例缩放即可。</p>
<p>对于第二个问题，原论文基于FPN越低层的输入对应越大尺度对象的原则，设计了一个经验公式。</p>
<script type="math/tex; mode=display">
k = \lfloor k_0 + \log_2(\frac{\sqrt{wh}}{224}) \rfloor</script><p>通过这个经验公式，利用proposal box的HW尺寸即可选择一个合适的feature map进行映射。</p>
<blockquote>
<p>其实，原论文中的这个公式是基于Fast RCNN的，也就是不采用RPN时的RCNN。因为采用RPN时，每个proposal都是由feature map经过RPN Head直接生成的，因此天然地知道proposal和feature map的对应关系。而Fast RCNN采用Select Search算法得到proposal，缺失这层关系，所以得用这个经验公式。</p>
<p>但是pytorch实现Faster RCNN还是用了这个经验公式进行proposal与feature map的匹配，而不是用RPN自带的信息。</p>
</blockquote>
<p>对于第三个问题，采用ROI Pooling或者说ROI Align算法处理，将所有大小各异的proposal feature box缩放成一致大小的tensor。基本原理是，将每个proposal feature box等分成7x7个区域，然后取每个区域内的最大值，这样无论之前的proposal feature box的HW尺寸如何，最后的输出都是一个7x7的大小。如果7x7处理后直接对子区域坐标取整然后maxpool就是ROI Pooling，用更复杂的插值算法得到最值则是ROI Align，当然后者效果更好。</p>
<div align=center><img title="" src="/img/article/roipooling.gif" srcset="/img/loading.gif" lazyload width="60%" height="60%" align=center></div>

<p><strong>本阶段数据转化结果</strong></p>
<ul>
<li><strong>proposal</strong>:[tensor(2000x4), tensor(2000x4)] -&gt; <strong>proposal</strong>:[tensor(512x4), tensor(512x4)] + <strong>proposal_Gtbox</strong>: [tensor(512x4), tensor(512x4)] + <strong>label</strong>:[tensor(512x1), tensor(512x1)]</li>
<li><strong>proposal</strong>:[tensor(512x4), tensor(512x4)] + <strong>features</strong> : dict -&gt; <strong>proposal_features</strong>: tensor(1024x256x7x7)</li>
</ul>
<blockquote>
<p>如果是预测模式则将以上出现的512替换为1000来理解</p>
</blockquote>
<h2 id="6-TwoMLPHead"><a href="#6-TwoMLPHead" class="headerlink" title="6. TwoMLPHead"></a>6. TwoMLPHead</h2><p>这一层比较简单，就是将ROI Align之后的proposal_features第一个维度之后的数据flatten，然后通过两个串联的全连接层。</p>
<blockquote>
<p>也就是说一个batch处理1024个框，每张图像512个，每个框用一个256x7x7个标量数据组成的列向量表示。如果是预测模式则是每张图像1000个框。</p>
</blockquote>
<p>第一层256x7x7个节点，没得选，输入在那，RELU激活；第二层人为设定为1024个节点，同样是RELU激活。</p>
<p>最终得到一个1024x1024的tensor。</p>
<p><strong>本阶段数据转化结果</strong></p>
<ul>
<li><strong>proposal_features</strong>: tensor(1024x256x7x7) -&gt; tensor(1024x1024)</li>
</ul>
<blockquote>
<p>如果是预测模式，那么应该为1000x256x7x7-&gt;1000x1024</p>
</blockquote>
<h2 id="7-Predictor"><a href="#7-Predictor" class="headerlink" title="7. Predictor"></a>7. Predictor</h2><p>这一层也比较简单，就是将TwoMLPHead输出的tensor通过两个并联的全连接层。这两个全连接层上的结构以及作用与RPN Head基本相同，一个生成类别参数，一个生成边界框回归参数。类别层class_num个节点，边界框层class_num x 4个节点。</p>
<p><strong>本阶段数据转化结果</strong></p>
<ul>
<li><strong>porposal_feature</strong>: tensor(1024x1024) -&gt; <strong>class_logits</strong>: tensor(1024 x class_num) + <strong>box_regs</strong>: tensor(1024 x [class_num x 4])</li>
</ul>
<blockquote>
<p>这里的预测结果要多说一句，每张图片生成512x21个预测框，也就是说每张图像产生512个detection，每个detection包含21个预测框，每个框又有3个属性，label &amp; score &amp; box_reg。一个detection的数据结构大致如下图所示（3个detection，5个类别）：</p>
<p>另外数据转化结果中的第一个维度在预测模式下同样应该是1000而不是1024</p>
</blockquote>
<div align=center><img title="" src="/img/article/faster-rcnn-0-0.png" srcset="/img/loading.gif" lazyload width="90%" height="90%" align=center></div>

<h2 id="8A-预测结果后处理"><a href="#8A-预测结果后处理" class="headerlink" title="8A. 预测结果后处理"></a>8A. 预测结果后处理</h2><p>上一步完成后，实质意义上的模型预测就已经完成了。如果是在预测模式下工作，接下来需要将class_logits和box_regs解释到缩放前的原始图像上。</p>
<h3 id="8A-1-FilterDetection"><a href="#8A-1-FilterDetection" class="headerlink" title="8A.1 FilterDetection"></a>8A.1 FilterDetection</h3><p>对于每一张图像，具体工作如下：</p>
<ol>
<li>对class_logits做softmax，得到每一个box的score；</li>
<li>对box_reg和proposal角点坐标做decode，得到每一个final_box的角点坐标；</li>
<li>类似RPN的FilterProposal，做low score过滤；</li>
<li>类似RPN的FilterProposal，做low WH过滤；</li>
<li>类似RPN的FilterProposal，针对每一个类别做nms，并且取nms之后的前100个box；</li>
</ol>
<p><strong>本阶段数据转化结果</strong></p>
<ul>
<li><strong>box_regs</strong>: tensor(1024 x [class_num x 4]) + <strong>proposal</strong>: [tensor(512x4), tensor(512x4)] -&gt; <strong>final_boxes</strong>: [100x4, 100x4]，进行decode和filter</li>
<li><strong>class_logits</strong>: tensor(1024 x class_num) -&gt; <strong>final_scores</strong>: [100x1, 100x1]，进行sotfmax和filter</li>
<li><strong>box_labels</strong>: tensor(1024 x class_num) -&gt; <strong>final_labels</strong>: [100x1, 100x1]，进行同步filter</li>
</ul>
<blockquote>
<p>这里的BoxLabel由规则生成，final_labels指的是预测信息，根据上图中box在一个detection的box序列中的相对位置确定。这就跟以往的经验不同了，这里并没有对一个detection所有框的score取最大值，然后将21个类别退化为1，而是将detection的每一列也就是每一个预测框作为一个单独的个体。就是说最终的100个预测框中完全有可能同时存在两个产生自同一个detection。</p>
<p>数据转化结果中的第一个维度在预测模式下同样应该是1000而不是1024</p>
</blockquote>
<h3 id="8A-2-PostTransform"><a href="#8A-2-PostTransform" class="headerlink" title="8A.2 PostTransform"></a>8A.2 PostTransform</h3><p>将detection三要素中的box坐标根据原图缩放前和缩放后的比例进行等比例缩放即可。</p>
<h2 id="8B-FasterRCNN损失计算"><a href="#8B-FasterRCNN损失计算" class="headerlink" title="8B. FasterRCNN损失计算"></a>8B. FasterRCNN损失计算</h2><p>当在训练模式下工作时，需要进行FasterRCNN损失计算。与RPN损失类似，FasterRCNN损失同样分为两部分，坐标损失和分类损失。首先捋一下两部分各自的真实信息和预测信息是什么：</p>
<ol>
<li>坐标回归参数的预测信息，Predictor输出的box_regs；</li>
<li>坐标回归参数的真实信息GT_regs，用一对GTbox和proposal进行encode得到；</li>
<li>预测框类别的预测信息，Predictor输出的class_logits；</li>
<li>预测框类别的真实信息GT_labels，获取方式跟之前RPN类似，即先将proposal和GTbox进行匹配，然后用匹配之后的IOU值的大小来判定proposal是否值得拥有与之匹配的GTbox的label，若值得(IOU&gt;0.5)则proposal的真实label就是GTbox的label，否则为0；</li>
</ol>
<p>捋清楚了上述信息之后，即可将对应数据代入到类似RPN的损失函数中进行计算，得到FasterRCNN的最终损失。</p>
<p><strong>本阶段数据转化结果</strong></p>
<ul>
<li><strong>class_logits</strong>: tensor(1024 x classnum) + <strong>GT_labels</strong>: [tensor(512x1), tensor(512x1)] -&gt; $L_{cls}$</li>
<li><strong>box_regs</strong>: tensor(1024 x [classnum x 4]) + <strong>GT_regs</strong>: [tensor(512x4),tensor(512x4)] -&gt; $L_{box}$</li>
</ul>
<blockquote>
<p>可以看到真实信息和预测信息之间差了一个classnum的维度，在计算$L_{cls}$时不要紧，因为交叉熵计算用到的GT_label是one-hot的形式，pytorch的实现机制自己会进行合理的计算。</p>
<p>在计算$L_{box}$时，要增加一个classnum上的索引将其退化为1，从而与GT_regs保持一致。索引的来源是GT_label的one-hot向量中1的位置，所以也就是说将GT_reg拓展为four-hot即可。</p>
</blockquote>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E5%B7%A5%E4%BD%9C%E6%8A%80%E8%83%BD/">工作技能</a>
                    
                      <a class="hover-with-bg" href="/categories/%E5%B7%A5%E4%BD%9C%E6%8A%80%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a>
                    
                      <a class="hover-with-bg" href="/categories/%E5%B7%A5%E4%BD%9C%E6%8A%80%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a>
                    
                      <a class="hover-with-bg" href="/categories/%E5%B7%A5%E4%BD%9C%E6%8A%80%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/Faster-RCNN/">Faster RCNN</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
                    
                      <a class="hover-with-bg" href="/tags/CNN/">CNN</a>
                    
                      <a class="hover-with-bg" href="/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">卷积神经网络</a>
                    
                      <a class="hover-with-bg" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a>
                    
                      <a class="hover-with-bg" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a>
                    
                      <a class="hover-with-bg" href="/tags/Faster-RCNN/">Faster RCNN</a>
                    
                      <a class="hover-with-bg" href="/tags/RPN/">RPN</a>
                    
                      <a class="hover-with-bg" href="/tags/ROI-Align/">ROI Align</a>
                    
                      <a class="hover-with-bg" href="/tags/ROI-Pooling/">ROI Pooling</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2021/08/15/Faster-RCNN%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-1/">
                        <span class="hidden-mobile">Faster RCNN源码分析（一）—— 图像预处理</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments" lazyload>
                
                  
                
                
  <div id="twikoo"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/twikoo@1.4.1/dist/twikoo.all.min.js', function() {
        var options = Object.assign(
          {"envId":"twikoo-5gimyzvb3631ef62","region":"ap-shanghai","path":"window.location.pathname"},
          {
            el: '#twikoo',
            path: 'window.location.pathname'
          }
        )
        twikoo.init(options)
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <small><span>——————————我是有底线的——————————</span></small> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- LeanCloud 统计PV -->
        <span id="leancloud-site-pv-container" style="display: none">
            总访问量 
            <span id="leancloud-site-pv"></span>
             次
          </span>
      
      
        <!-- LeanCloud 统计UV -->
        <span id="leancloud-site-uv-container" style="display: none">
            总访客数 
            <span id="leancloud-site-uv"></span>
             人
          </span>
      

    
  </div>


  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js" ></script>



  <script  src="/js/local-search.js" ></script>




  <script defer src="/js/leancloud.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js" ></script>

  








  

  

  

  

  

  





<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"left","width":270,"height":540},"mobile":{"show":false,"scale":0.5},"log":false});</script></body>
</html>
